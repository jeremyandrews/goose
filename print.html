<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Goose Book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Goose Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-goose-book"><a class="header" href="#the-goose-book">The Goose Book</a></h1>
<p>Have you ever been attacked by a goose?</p>
<h2 id="what-is-goose"><a class="header" href="#what-is-goose">What Is Goose?</a></h2>
<p><a href="https://docs.rs/goose">Goose</a> is a <a href="https://www.rust-lang.org/">Rust</a> load testing tool inspired by <a href="https://locust.io/">Locust</a>. User behavior is defined with standard Rust code. Load tests are applications that have a dependency on the <a href="https://crates.io/crates/goose">Goose library</a>. Web requests are made with the <a href="https://docs.rs/reqwest">Reqwest</a> HTTP Client.</p>
<p><img src="what_is_goose_graph.png" alt="Request statistics report" /></p>
<h2 id="advantages"><a class="header" href="#advantages">Advantages</a></h2>
<p>Goose generates at least 11x as much traffic as Locust per-CPU-core, with even larger gains for more complex load tests (such as those using third-party libraries to scrape form content). While Locust requires you to manage a distributed load test simply to use multiple CPU cores on a single server, Goose leverages all available CPU cores with a single process, drastically simplifying the process for running larger load tests. Ongoing improvements to the codebase continue to bring new features and faster performance. Goose scales far better than Locust, efficiently using available resources to accomplish its goal. It also supports asynchronous processes enabling many more simultaneous processes to ramp up thousands of users from a single server, easily and consistently.</p>
<p>Goose’s distributed testing design is similar to Locust’s, in that it uses a one Manager to many Workers model. However, unlike Locust, you do not need to spin up a distributed load test to leverage all available cores on a single server, as a single Goose process will fully leverage all available cores. Goose distributed load tests scale near-perfectly as once started each Worker performs its load test without any direction from the Manager, and the Manager simply collects statistics from all the Workers for final reporting. In other words, one Manager controlling eight Workers on a single 8-CPU-core server generates the same amount of load as a single standalone Goose process independently leveraging all eight cores.</p>
<p>Goose has a number of unique <a href="./logging/overview.html">debugging and logging mechanisms</a> not found in other load testing tools, simplifying the writing of load tests and the analysis of results. Goose also provides more <a href="./getting-started/metrics.html">comprehensive metrics</a> with multiple simple views into the data, and makes it easy to confirm that the load test is doing what you expect it to as you scale it up or down. It exposes the algorithms used to allocate scenarios and contained transactions, giving <a href="./config/scheduler.html">more granular control</a> over the order and consistency of operations, important for easily repeatable testing.</p>
<h2 id="whats-missing"><a class="header" href="#whats-missing">What's Missing</a></h2>
<p>At this time, the biggest missing feature of Goose is a UI for controlling and monitoring load tests, but this is a work in progress. A recently completed first step toward this goal was the addition of an <a href="./getting-started/common.html#writing-an-html-formatted-report">optional HTML report</a> generated at the end of a load test.</p>
<h2 id="brought-to-you-by"><a class="header" href="#brought-to-you-by">Brought To You By</a></h2>
<p>Goose development is sponsored by <a href="https://tag1.com/">Tag1 Consulting</a>, led by Tag1's CEO, <a href="https://foundation.rust-lang.org/posts/2021-10-26-member-spotlight-tag1/">Jeremy Andrews</a>, along with many <a href="https://github.com/tag1consulting/goose/graphs/contributors">community contributions</a>. Tag1 is a <a href="https://www.tag1consulting.com/blog/tag1-joins-rust-foundation-first-silver-member">member of the Rust Foundation</a>.</p>
<h2 id="additional-documentation"><a class="header" href="#additional-documentation">Additional Documentation</a></h2>
<ul>
<li><a href="https://docs.rs/goose/">Developer documentation</a></li>
<li><a href="https://tag1.com/goose/">Blogs and more</a>
<ul>
<li><a href="https://www.tag1consulting.com/blog/jmeter-vs-locust-vs-goose">Goose vs Locust and jMeter</a></li>
<li><a href="https://www.tag1consulting.com/blog/real-life-goose-load-testing">Real-life load testing with Goose</a></li>
<li><a href="https://www.tag1consulting.com/blog/show-me-how-flock-flies-working-gaggle-goose">Gaggle: a distributed load test</a></li>
<li><a href="https://www.tag1consulting.com/blog/golden-goose-egg-compile-time-adventure">Optimizing Goose performance</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="requirements"><a class="header" href="#requirements">Requirements</a></h1>
<ul>
<li>
<p>In order to write load tests, you must first install <a href="https://www.rust-lang.org/tools/install">Rust</a>.</p>
</li>
<li>
<p>Goose load tests are managed with <a href="https://doc.rust-lang.org/cargo/">Cargo</a>, the Rust package manager.</p>
</li>
</ul>
<p>Goose requires a minimum <a href="https://doc.rust-lang.org/rustc/what-is-rustc.html"><code>rustc</code></a> version of <a href="https://blog.rust-lang.org/2023/06/01/Rust-1.70.0.html"><code>1.70.0</code></a> or later.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<h2 id="controller"><a class="header" href="#controller">Controller</a></h2>
<p>An interface that allows real-time control of a running Goose load test. Goose provides both <a href="./controller/telnet.html">Telnet</a> and <a href="./controller/websocket.html">WebSocket</a> controllers for dynamically adjusting test parameters like user count, hatch rate, and runtime during execution.</p>
<h2 id="coordinated-omission"><a class="header" href="#coordinated-omission">Coordinated Omission</a></h2>
<p>A phenomenon that occurs in load testing when the measurement system inadvertently excludes the results of requests that were affected by server slowdowns, leading to misleadingly optimistic performance metrics. Goose includes <a href="./coordinated-omission/mitigation.html">Coordinated Omission Mitigation</a> functionality to detect and correct for this.</p>
<h2 id="gaggle"><a class="header" href="#gaggle">Gaggle</a></h2>
<p>Goose's distributed load testing functionality that allows running coordinated load tests across multiple machines. A Gaggle consists of one Manager and multiple Workers. <strong>Note:</strong> Gaggle support was temporarily removed in Goose 0.17.0.</p>
<h2 id="gooseattack"><a class="header" href="#gooseattack">GooseAttack</a></h2>
<p>A load test defined by one or more <a href="glossary.html#scenario">Scenarios</a> with one or more <a href="glossary.html#transaction">Transactions</a>.</p>
<h2 id="gooseconfiguration"><a class="header" href="#gooseconfiguration">GooseConfiguration</a></h2>
<p>A structure that defines all configuration options for a Goose load test, including user count, hatch rate, runtime, host, and various other parameters. Can be set via command line arguments, configuration files, or programmatically.</p>
<h2 id="gooseerror"><a class="header" href="#gooseerror">GooseError</a></h2>
<p>A helper that defines all possible errors returned by Goose. A <a href="glossary.html#transaction">Transaction</a> returns a <a href="glossary.html#transactionresult">TransactionResult</a>, which is either <a href="https://doc.rust-lang.org/std/result/enum.Result.html#variant.Ok"><code>Ok(())</code></a> or <a href="https://doc.rust-lang.org/std/result/enum.Result.html#variant.Err"><code>Err(GooseError)</code></a>.</p>
<h2 id="gooseuser"><a class="header" href="#gooseuser">GooseUser</a></h2>
<p>A thread that repeatedly runs a single <a href="./getting-started/metrics.html#scenarios"><strong>scenario</strong></a> for the duration of the load test. For example, when Goose starts, you may use the <a href="./getting-started/common.html#how-many-users-to-simulate"><code>--users</code></a> command line option to configure how many GooseUser threads are started. This is not intended to be a 1:1 correlation between GooseUsers and real website users.</p>
<h2 id="hatch-rate"><a class="header" href="#hatch-rate">Hatch Rate</a></h2>
<p>The rate at which new <a href="glossary.html#gooseuser">GooseUsers</a> are launched during the ramp-up phase of a load test, typically specified as users per second.</p>
<h2 id="request"><a class="header" href="#request">Request</a></h2>
<p>A single <a href="./getting-started/metrics.html#requests"><strong>request</strong></a> based around HTTP verbs.</p>
<h2 id="scenario"><a class="header" href="#scenario">Scenario</a></h2>
<p>A <a href="./getting-started/metrics.html#scenarios"><strong>scenario</strong></a> is a collection of <a href="./getting-started/metrics.html#transactions"><strong>transactions</strong></a> (aka steps) a user would undertake to achieve a specific user journey.</p>
<h2 id="test-plan"><a class="header" href="#test-plan">Test Plan</a></h2>
<p>A flexible approach to scheduling load test phases, allowing you to define complex load patterns like gradual ramp-up, sustained load periods, spike testing, and graceful ramp-down. Test plans use the format <code>users,duration;users,duration</code> to specify multiple phases.</p>
<h2 id="throttle"><a class="header" href="#throttle">Throttle</a></h2>
<p>A mechanism to limit the request rate of individual <a href="glossary.html#gooseuser">GooseUsers</a>, helping simulate more realistic user behavior by introducing delays between requests rather than sending requests as fast as possible.</p>
<h2 id="transaction"><a class="header" href="#transaction">Transaction</a></h2>
<p>A <a href="./getting-started/metrics.html#transactions"><strong>transaction</strong></a> is a collection of one or more <a href="./getting-started/metrics.html#request"><strong>requests</strong></a> and any desired validation. For example, this may include loading the front page and all contained static assets, logging into the website, or adding one or more items to a shopping chart. Transactions typically include assertions or expectation validation.</p>
<h2 id="transactionresult"><a class="header" href="#transactionresult">TransactionResult</a></h2>
<p>A <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a> returned by <a href="glossary.html#transaction">Transaction</a> functions. A transaction can return <code>Ok(())</code> on success, or <code>Err(</code><a href="glossary.html#gooseerror">GooseError</a><code>)</code> on failure.</p>
<h2 id="weight"><a class="header" href="#weight">Weight</a></h2>
<p>A value that controls the frequency with which a <a href="glossary.html#transaction">Transaction</a> or <a href="glossary.html#scenario">Scenario</a> runs, relative to the other transactions in the same scenario, or scenarios in the same load test. For example, if one transaction has a weight of 3 and another transaction in the same scenario has a weight of 1, the first transaction will run 3 times as often as the second.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>This first chapter of the Goose Book provides a high-level overview of writing and running Goose load tests. If you're new to Goose, this is the place to start.</p>
<h2 id="the-importance-of-load-testing"><a class="header" href="#the-importance-of-load-testing">The Importance Of Load Testing</a></h2>
<p>Load testing can help prevent website outages, stress test code changes, and identify bottlenecks. It can also quickly perform functional regression testing. The ability to run the same test repeatedly gives critical insight into the impact of changes to the code and/or systems.</p>
<h2 id="when-to-use-goose"><a class="header" href="#when-to-use-goose">When to Use Goose</a></h2>
<p>Goose is particularly well-suited for:</p>
<ul>
<li><strong>Complex User Workflows</strong>: Testing multi-step processes like checkout flows, user registration, or content management workflows</li>
<li><strong>API Load Testing</strong>: Validating REST APIs, GraphQL endpoints, or microservice interactions under load</li>
<li><strong>Performance Regression Testing</strong>: Integrating into CI/CD pipelines to catch performance regressions before deployment</li>
<li><strong>Capacity Planning</strong>: Understanding how your infrastructure scales and where bottlenecks occur</li>
<li><strong>Coordinated Omission Detection</strong>: Identifying when server slowdowns affect more users than simple metrics suggest</li>
</ul>
<h2 id="goose-vs-other-load-testing-tools"><a class="header" href="#goose-vs-other-load-testing-tools">Goose vs Other Load Testing Tools</a></h2>
<p>Unlike tools that focus purely on HTTP request volume, Goose excels at:</p>
<ul>
<li><strong>Stateful Testing</strong>: Maintaining sessions, cookies, and authentication across requests</li>
<li><strong>Realistic Load Patterns</strong>: Simulating actual user behavior rather than just hammering endpoints</li>
<li><strong>Developer-Friendly</strong>: Written in Rust with type safety and excellent error handling</li>
<li><strong>Detailed Analysis</strong>: Advanced metrics that reveal hidden performance issues</li>
<li><strong>Flexibility</strong>: Custom logic, data-driven tests, and complex scenarios</li>
</ul>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before diving into Goose, you should have:</p>
<ul>
<li><strong>Basic Rust Knowledge</strong>: Familiarity with Rust syntax, async/await, and error handling</li>
<li><strong>HTTP Understanding</strong>: Knowledge of HTTP methods, status codes, and web application architecture</li>
<li><strong>Testing Mindset</strong>: Understanding of what you want to test and what constitutes success</li>
</ul>
<p>Don't worry if you're new to load testing - Goose's approach will guide you toward writing realistic and valuable tests.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-a-load-test"><a class="header" href="#creating-a-load-test">Creating A Load Test</a></h1>
<h2 id="cargo"><a class="header" href="#cargo">Cargo</a></h2>
<p><a href="https://doc.rust-lang.org/cargo/">Cargo</a> is the Rust package manager. To create a new load test, use Cargo to create a new application (you can name your application anything, we've generically selected <code>loadtest</code>):</p>
<pre><code class="language-bash">$ cargo new loadtest
     Created binary (application) `loadtest` package
$ cd loadtest/
</code></pre>
<p>This creates a new directory named <code>loadtest/</code> containing <code>loadtest/Cargo.toml</code> and <code>loadtest/src/main.rs</code>. Edit <code>Cargo.toml</code> and add Goose and <a href="https://tokio.rs/"><code>Tokio</code></a> under the dependencies heading:</p>
<pre><code class="language-toml">[dependencies]
goose = "^0.18"
tokio = "^1"
</code></pre>
<p>At this point it's possible to compile all dependencies, though the resulting binary only displays "Hello, world!":</p>
<pre><code class="language-bash">$ cargo run
    Updating crates.io index
  Downloaded goose v0.18.1
      ...
   Compiling goose v0.18.1
   Compiling loadtest v0.1.0 (/home/jandrews/devel/rust/loadtest)
    Finished dev [unoptimized + debuginfo] target(s) in 52.97s
     Running `target/debug/loadtest`
Hello, world!
</code></pre>
<h2 id="creating-the-load-test"><a class="header" href="#creating-the-load-test">Creating the load test</a></h2>
<p>To create an actual load test, you first have to add the following boilerplate to the top of <code>src/main.rs</code> to make Goose's functionality available to your code:</p>
<pre><code class="language-rust ignore">use goose::prelude::*;</code></pre>
<blockquote>
<p><strong>Note:</strong> Using the above prelude automatically adds the following <code>use</code> statements necessary when writing a load test, so you don't need to manually add all of them:</p>
<pre><code class="language-rust ignore">use crate::config::{GooseDefault, GooseDefaultType};
use crate::goose::{
    GooseMethod, GooseRequest, GooseUser, Scenario, Transaction, TransactionError,
    TransactionFunction, TransactionResult,
};
use crate::metrics::{GooseCoordinatedOmissionMitigation, GooseMetrics};
use crate::{scenario, transaction, GooseAttack, GooseError, GooseScheduler};</code></pre>
</blockquote>
<p>Then create a new load testing function. For our example we're simply going to load the front page of the website we're load-testing. Goose passes all load testing functions a mutable pointer to a GooseUser object, which is used to track metrics and make web requests. Thanks to the <a href="https://docs.rs/reqwest/">Reqwest</a> library, the Goose client manages things like cookies, headers, and sessions for you. Load testing functions must be declared async, ensuring that your simulated users don't become CPU-locked.</p>
<p>In load test functions you typically do not set the host, and instead configure the host at run time, so you can easily run your load test against different environments without recompiling. Relative paths (not starting with a <code>/</code>) should be used.</p>
<p>The following <code>loadtest_index</code> function simply loads the front page of our web page:</p>
<pre><code class="language-rust ignore">use goose::prelude::*;

async fn loadtest_index(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let _goose_metrics = user.get("").await?;

    Ok(())
}</code></pre>
<p>The function is declared <code>async</code> so that we don't block a CPU-core while loading web pages. All Goose load test functions are passed in a mutable reference to a <code>GooseUser</code> object, and return a <code>TransactionResult</code> which is either an empty <code>Ok(())</code> on success, or a <code>TransactionError</code> on failure. We use the <code>GooseUser</code> object to make requests, in this case we make a <code>GET</code> request for the front page, specified with an empty path <code>""</code>. The <code>.await</code> frees up the CPU-core while we wait for the web page to respond, and the trailing <code>?</code> unwraps the response, returning any unexpected errors that may be generated by this request.</p>
<p>When the GET request completes, Goose returns metrics which we store in the  <code>_goose_metrics</code> variable. The variable is prefixed with an underscore (<code>_</code>) to tell the compiler we are intentionally not using the results. Finally, after making a single successful request, we return <code>Ok(())</code> to let Goose know this transaction function completed successfully.</p>
<p>Now we have to tell Goose about our new transaction function. Edit the <code>main()</code> function, setting a return type and replacing the hello world text as follows:</p>
<pre><code class="language-rust ignore">#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    GooseAttack::initialize()?
        .register_scenario(scenario!("LoadtestTransactions")
            .register_transaction(transaction!(loadtest_index))
        )
        .execute()
        .await?;

    Ok(())
}</code></pre>
<p>The <code>#[tokio::main]</code> at the beginning of this example is a Tokio macro necessary because Goose is an asynchronous library, allowing (and requiring) us to declare the <code>main()</code> function of our load test application as <code>async</code>.</p>
<p>If you're new to Rust, <code>main()</code>'s return type of <code>Result&lt;(), GooseError&gt;</code> may look strange. It essentially says that <code>main</code> will return nothing (<code>()</code>) on success, and will return a <code>GooseError</code> on failure. This is helpful as several of <code>GooseAttack</code>'s methods can fail, returning an error. In our example, <code>initialize()</code> and <code>execute()</code> each may fail. The <code>?</code> that follows the method's name tells our program to exit and return an error on failure, otherwise continue on. Note that the <code>.execute()</code> method is asynchronous, so it must be followed with <code>.await</code>, and as it can return an error it also has a <code>?</code>. The final line, <code>Ok(())</code> returns the empty result expected on success.</p>
<p>And that's it, you've created your first load test! Read on to see how to run it and what it does.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="validating-requests"><a class="header" href="#validating-requests">Validating Requests</a></h1>
<h2 id="goose-eggs"><a class="header" href="#goose-eggs">Goose Eggs</a></h2>
<p><a href="https://github.com/tag1consulting/goose-eggs">Goose-eggs</a> are helpful in writing Goose load tests.</p>
<p>To leverage Goose Eggs when writing your load test, include the crate in the dependency section of your `Cargo.toml.</p>
<pre><code class="language-toml">[dependencies]
goose-eggs = "0.4"
</code></pre>
<p>For example, to use the Goose Eggs validation functions, bring the <code>Validate</code> structure and either the <code>validate_page</code> or the <code>validate_and_load_static_assets</code> function into scope:</p>
<pre><code class="language-rust ignore">use goose_eggs::{validate_and_load_static_assets, Validate};</code></pre>
<p>Now, it is simple to verify that we received a <code>200</code> HTTP response status code, and that the text <code>Gander</code> appeared somewhere on the page as expected:</p>
<pre><code class="language-rust ignore">let goose = user.get("/goose/").await?;

let validate = &amp;Validate::builder()
    .status(200)
    .text("Gander")
    .build();

validate_and_load_static_assets(user, goose, &amp;validate).await?;</code></pre>
<p>Whether or not validation passed or failed will be visible in the Goose metrics when the load test finishes. You can enable the <a href="https://book.goose.rs/logging/debug.html">debug log</a> to gain more insight into failures.</p>
<p>Read <a href="https://docs.rs/goose-eggs/latest/goose_eggs">the goose-eggs documentation</a> to learn about other helpful functions useful in writing load tests, as well as other validation helpers, such as <a href="https://docs.rs/goose-eggs/latest/goose_eggs/struct.ValidateBuilder.html#method.header">headers</a>, <a href="https://docs.rs/goose-eggs/latest/goose_eggs/struct.ValidateBuilder.html#method.header_value">header values</a>, <a href="https://docs.rs/goose-eggs/latest/goose_eggs/struct.ValidateBuilder.html#method.title">the page title</a>, and <a href="https://docs.rs/goose-eggs/latest/goose_eggs/struct.ValidateBuilder.html#method.redirect">whether the request was redirected</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-a-load-test"><a class="header" href="#running-a-load-test">Running A Load Test</a></h1>
<p>We will use Cargo to run our example load test application. It's best to get in the habit of setting the <code>--release</code> option whenever compiling or running load tests.</p>
<pre><code class="language-bash">$ cargo run --release
    Finished release [optimized] target(s) in 0.06s
     Running `target/release/loadtest`
07:08:43 [INFO] Output verbosity level: INFO
07:08:43 [INFO] Logfile verbosity level: WARN
07:08:43 [INFO] users defaulted to number of CPUs = 10
Error: InvalidOption { option: "--host", value: "", detail: "A host must be defined via the --host option, the GooseAttack.set_default() function, or the Scenario.set_host() function (no host defined for LoadtestTransactions)." }
</code></pre>
<p>The load test fails with an error as it hasn't been told the host you want to load test.</p>
<p>So, let's try again, this time passing in the <code>--host</code> flag. We will also add the <code>--report-file</code> flag with a <code>.html</code> file extension, <a href="getting-started/common.html#writing-an-html-formatted-report">which will generate an HTML report</a>, and <code>--no-reset-metrics</code> to preserve all information including the load test startup. The same information will also <a href="getting-started/metrics.html">be printed to the command line</a> (without graphs). After running for a few seconds, press <code>ctrl-c</code> one time to gracefully stop the load test:</p>
<pre><code class="language-bash">% cargo run --release -- --host http://umami.ddev.site --report-file=report.html --no-reset-metrics
    Finished release [optimized] target(s) in 0.06s
     Running `target/release/loadtest --host 'http://umami.ddev.site' --report-file=report.html --no-reset-metrics`
08:53:48 [INFO] Output verbosity level: INFO
08:53:48 [INFO] Logfile verbosity level: WARN
08:53:48 [INFO] users defaulted to number of CPUs = 10
08:53:48 [INFO] no_reset_metrics = true
08:53:48 [INFO] report_file = report.html
08:53:48 [INFO] global host configured: http://umami.ddev.site
08:53:48 [INFO] allocating transactions and scenarios with RoundRobin scheduler
08:53:48 [INFO] initializing 10 user states...
08:53:48 [INFO] Telnet controller listening on: 0.0.0.0:5116
08:53:48 [INFO] WebSocket controller listening on: 0.0.0.0:5117
08:53:48 [INFO] entering GooseAttack phase: Increase
08:53:48 [INFO] [user 1]: launching user from LoadtestTransactions
08:53:49 [INFO] [user 2]: launching user from LoadtestTransactions
08:53:50 [INFO] [user 3]: launching user from LoadtestTransactions
08:53:51 [INFO] [user 4]: launching user from LoadtestTransactions
08:53:52 [INFO] [user 5]: launching user from LoadtestTransactions
08:53:53 [INFO] [user 6]: launching user from LoadtestTransactions
08:53:54 [INFO] [user 7]: launching user from LoadtestTransactions
08:53:55 [INFO] [user 8]: launching user from LoadtestTransactions
08:53:56 [INFO] [user 9]: launching user from LoadtestTransactions
08:53:57 [INFO] [user 10]: launching user from LoadtestTransactions
All 10 users hatched.

08:53:58 [INFO] entering GooseAttack phase: Maintain
^C08:54:25 [WARN] caught ctrl-c, stopping...
</code></pre>
<p>As of Goose 0.16.0, by default all <code>INFO</code> and higher level log messages are displayed on the console while the load test runs. You can disable these messages with the <code>-q</code> (<code>--quiet</code>) flag. Or, you can display low-level debug with the <code>-v</code> (<code>--verbose</code>) flag.</p>
<h2 id="html-report"><a class="header" href="#html-report">HTML report</a></h2>
<p>When the load tests finishes shutting down, it will display some <a href="getting-started/metrics.html#ascii-metrics">ASCII metrics</a> on the CLI and an HTML report will be created in the local directory named <code>report.html</code> as was configured above. The graphs and tables found in the HTML report are what are demonstrated below:</p>
<p><img src="getting-started/report-header.png" alt="HTML report header section" /></p>
<p>By default, Goose will hatch 1 <code>GooseUser</code> per second, up to the number of CPU cores available on the server used for load testing. In the above example, the loadtest was run from a laptop with 10 CPU cores, so it took 10 seconds to hatch all users.</p>
<p>By default, after all users are launched Goose will flush all metrics collected during the launching process (we used the <code>--no-reset-metrics</code> flag to disable this behavior) so the summary metrics are collected with all users running. If we'd not used <code>--no-reset-metrics</code>, before flushing the metrics they would have been displayed to the console so the data is not lost.</p>
<h2 id="request-metrics"><a class="header" href="#request-metrics">Request metrics</a></h2>
<p><img src="getting-started/report-requests.png" alt="HTML report request metrics section" /></p>
<p>The per-request metrics are displayed first. Our single transaction makes a <code>GET</code> request for the empty <code>""</code> path, so it shows up in the metrics as simply <code>GET  </code>. The table in this section displays the total number of requests made (8,490), the average number of requests per second (229.46), and the average number of failed requests per second (0).</p>
<p>Additionally it shows the average time required to load a page (37.85 milliseconds), the minimum time to load a page (12 ms) and the maximum time to load a page (115 ms).</p>
<p>If our load test made multiple requests, the Aggregated line at the bottom of this section would show totals and averages of all requests together. Because we only make a single request, this row is identical to the per-request metrics.</p>
<h2 id="response-time-metrics"><a class="header" href="#response-time-metrics">Response time metrics</a></h2>
<p><img src="getting-started/report-responses.png" alt="HTML report response times metrics section" /></p>
<p>The second section displays the average time required to load a page. The table in this section is showing the slowest page load time for a range of percentiles. In our example, in the 50% fastest page loads, the slowest page loaded in 37 ms. In the 70% fastest page loads, the slowest page loaded in 42 ms, etc. The graph, on the other hand, is displaying the average response time aggregated across all requests.</p>
<h2 id="status-code-metrics"><a class="header" href="#status-code-metrics">Status code metrics</a></h2>
<p><img src="getting-started/report-status-codes.png" alt="HTML report status code metrics section" /></p>
<p>The third section is a table showing all response codes received for each request. In this simple example, all 8,490 requests received a <code>200 OK</code> response.</p>
<h2 id="transaction-metrics"><a class="header" href="#transaction-metrics">Transaction metrics</a></h2>
<p><img src="getting-started/report-transactions.png" alt="HTML report transaction metrics section" /></p>
<p>Next comes per-transaction metrics, starting with the name of our Scenario, <code>LoadtestTransactions</code>. Individual transactions in the Scenario are then listed in the order they are defined in our load test. We did not name our transaction, so it simply shows up as <code>0.0</code>. All defined transactions will be listed here, even if they did not run, so this can be useful to confirm everything in your load test is running as expected. Comparing the transaction metrics metrics collected for <code>0.0</code> to the per-request metrics collected for <code>GET /</code>, you can see that they are the same. This is because in our simple example, our single transaction only makes one request.</p>
<p>In real load tests, you'll most likely have multiple scenarios each with multiple transactions, and Goose will show you metrics for each along with an aggregate of them all together.</p>
<h2 id="scenario-metrics"><a class="header" href="#scenario-metrics">Scenario metrics</a></h2>
<p><a href="getting-started/metrics.html#scenarios">Per-scenario metrics</a> follow the per-transaction metrics. This page has has not yet been updated to include a proper example of Scenario metrics.</p>
<h2 id="user-metrics"><a class="header" href="#user-metrics">User metrics</a></h2>
<p><img src="getting-started/report-users.png" alt="HTML report user metrics section" /></p>
<p>Finally comes a chart showing how many users were running during the load test. You can clearly see the 10 users starting 1 per second at the start of the load test, as well as the final second when users quickly stopped.</p>
<p>Refer to the <a href="getting-started/../example/overview.html">examples</a> included with Goose for more complicated and useful load test examples.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="run-time-options"><a class="header" href="#run-time-options">Run-Time Options</a></h1>
<p>The <code>-h</code> flag will show all run-time configuration options available to Goose load tests. For example, you can pass the <code>-h</code> flag to our example loadtest as follows, <code>cargo run --release -- -h</code>:</p>
<pre><code class="language-ignore">Usage: target/release/loadtest [OPTIONS]

Goose is a modern, high-performance, distributed HTTP(S) load testing tool,
written in Rust. Visit https://book.goose.rs/ for more information.

The following runtime options are available when launching a Goose load test:

Optional arguments:
  -h, --help                  Displays this help
  -V, --version               Prints version information
  -l, --list                  Lists all transactions and exits

  -H, --host HOST             Defines host to load test (ie http://10.21.32.33)
  -u, --users USERS           Sets concurrent users (default: number of CPUs)
  -r, --hatch-rate RATE       Sets per-second user hatch rate (default: 1)
  -s, --startup-time TIME     Starts users for up to (30s, 20m, 3h, 1h30m, etc)
  -t, --run-time TIME         Stops load test after (30s, 20m, 3h, 1h30m, etc)
  -G, --goose-log NAME        Enables Goose log file and sets name
  -g, --log-level             Increases Goose log level (-g, -gg, etc)
  -q, --quiet                 Decreases Goose verbosity (-q, -qq, etc)
  -v, --verbose               Increases Goose verbosity (-v, -vv, etc)

Metrics:
  --running-metrics TIME      How often to optionally print running metrics
  --no-reset-metrics          Doesn't reset metrics after all users have started
  --no-metrics                Doesn't track metrics
  --no-transaction-metrics    Doesn't track transaction metrics
  --no-scenario-metrics       Doesn't track scenario metrics
  --no-print-metrics          Doesn't display metrics at end of load test
  --no-error-summary          Doesn't display an error summary
  --report-file NAME          Create reports, can be used multiple times (supports .html, .htm, .md, .json)
  --no-granular-report        Disable granular graphs in report file
  -R, --request-log NAME      Sets request log file name
  --request-format FORMAT     Sets request log format (csv, json, raw, pretty)
  --request-body              Include the request body in the request log
  -T, --transaction-log NAME  Sets transaction log file name
  --transaction-format FORMAT Sets log format (csv, json, raw, pretty)
  -S, --scenario-log NAME     Sets scenario log file name
  --scenario-format FORMAT    Sets log format (csv, json, raw, pretty)
  -E, --error-log NAME        Sets error log file name
  --error-format FORMAT       Sets error log format (csv, json, raw, pretty)
  -D, --debug-log NAME        Sets debug log file name
  --debug-format FORMAT       Sets debug log format (csv, json, raw, pretty)
  --no-debug-body             Do not include the response body in the debug log
  --no-status-codes           Do not track status code metrics

Advanced:
  --test-plan "TESTPLAN"      Defines a more complex test plan ("10,60s;0,30s")
  --iterations ITERATIONS     Sets how many times to run scenarios then exit
  --scenarios "SCENARIO"      Limits load test to only specified scenarios
  --scenarios-list            Lists all scenarios and exits
  --no-telnet                 Doesn't enable telnet Controller
  --telnet-host HOST          Sets telnet Controller host (default: 0.0.0.0)
  --telnet-port PORT          Sets telnet Controller TCP port (default: 5116)
  --no-websocket              Doesn't enable WebSocket Controller
  --websocket-host HOST       Sets WebSocket Controller host (default: 0.0.0.0)
  --websocket-port PORT       Sets WebSocket Controller TCP port (default: 5117)
  --no-autostart              Doesn't automatically start load test
  --no-gzip                   Doesn't set the gzip Accept-Encoding header
  --timeout VALUE             Sets per-request timeout, in seconds (default: 60)
  --co-mitigation STRATEGY    Sets coordinated omission mitigation strategy
  --throttle-requests VALUE   Sets maximum requests per second
  --sticky-follow             Follows base_url redirect with subsequent requests
  --accept-invalid-certs      Disables validation of https certificates
</code></pre>
<p>All of the above configuration options are <a href="https://docs.rs/goose/*/goose/config/struct.GooseConfiguration.html">defined in the developer documentation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-run-time-options"><a class="header" href="#common-run-time-options">Common Run Time Options</a></h1>
<p>As seen on the previous page, Goose has a lot of run time options which can be overwhelming. The following are a few of the more common and more important options to be familiar with. In these examples we only demonstrate one option at a time, but it's generally useful to combine many options.</p>
<h2 id="host-to-load-test"><a class="header" href="#host-to-load-test">Host to load test</a></h2>
<p>Load test plans typically contain relative paths, and so Goose must be told which host to run the load test against in order for it to start. This allows a single load test plan to be used for testing different environments, for example "http://local.example.com", "https://qa.example.com", and "https://www.example.com".</p>
<h3 id="host-example"><a class="header" href="#host-example">Host example</a></h3>
<p><em>Load test the https://www.example.com domain.</em></p>
<pre><code class="language-bash">cargo run --release -- -H https://www.example.com
</code></pre>
<h2 id="how-many-users-to-simulate"><a class="header" href="#how-many-users-to-simulate">How many users to simulate</a></h2>
<p>By default, Goose will launch one user per available CPU core. Often you will want to simulate considerably more users than this, and this can be done by setting the "--user" run time option.</p>
<p>(<em>Alternatively, you can use <a href="getting-started/./test-plan.html"><code>--test-plan</code></a> to build both simple and more complex traffic patterns that can include a varying number of users.</em>)</p>
<h3 id="users-example"><a class="header" href="#users-example">Users example</a></h3>
<p><em>Launch 1,000 GooseUsers.</em></p>
<pre><code class="language-bash">cargo run --release -- -u 1000
</code></pre>
<h2 id="controlling-how-long-it-takes-goose-to-launch-all-users"><a class="header" href="#controlling-how-long-it-takes-goose-to-launch-all-users">Controlling how long it takes Goose to launch all users</a></h2>
<p>There are several ways to configure how long Goose will take to launch all configured GooseUsers. For starters, you can user either <code>--hatch-rate</code> or <code>--startup-time</code>, but not both together. Alternatively, you can use <a href="getting-started/./test-plan.html"><code>--test-plan</code></a> to build both simple and more complex traffic patterns that can include varying launch rates.</p>
<h3 id="specifying-the-hatch-rate"><a class="header" href="#specifying-the-hatch-rate">Specifying the hatch rate</a></h3>
<p>By default, Goose starts one GooseUser per second. So if you configure <code>--users</code> to 10 it will take ten seconds to fully start the load test. If you set <code>--hatch-rate 5</code> then Goose will start 5 users every second, taking two seconds to start up. If you set <code>--hatch-rate 0.5</code> then Goose will start 1 user every 2 seconds, taking twenty seconds to start all 10 users.</p>
<p>(<em>The configured hatch rate is a best effort limit, Goose will not start users faster than this but there is no guarantee that your load test server is capable of starting users as fast as you configure.</em>)</p>
<h3 id="hatch-rate-example"><a class="header" href="#hatch-rate-example">Hatch rate example</a></h3>
<p><em>Launch one user every two seconds.</em></p>
<pre><code class="language-bash">cargo run --release -- -r .5
</code></pre>
<h3 id="specifying-the-total-startup-time"><a class="header" href="#specifying-the-total-startup-time">Specifying the total startup time</a></h3>
<p>Alternatively, you can tell Goose how long you'd like it to take to start all GooseUsers. So, if you configure <code>--users</code> to 10 and set <code>--startup-time 10</code> it will launch 1 user every second. If you set <code>--startup-time 1m</code> it will start 1 user every 6 seconds, starting all users over one minute. And if you set <code>--startup-time 2s</code> it will launch five users per second, launching all users in two seconds.</p>
<p>(<em>The configured startup time is a best effort limit, Goose will not start users faster than this but there is no guarantee that your load test server is capable of starting users as fast as you configure.</em>)</p>
<h3 id="startup-time-example"><a class="header" href="#startup-time-example">Startup time example</a></h3>
<p><em>Launch all users in 5 seconds.</em></p>
<pre><code class="language-bash">cargo run --release -- -s 5
</code></pre>
<h2 id="specifying-how-long-the-load-test-will-run"><a class="header" href="#specifying-how-long-the-load-test-will-run">Specifying how long the load test will run</a></h2>
<p>The <code>--run-time</code> option is not affected by how long Goose takes to start up. Thus, if you configure a load test with <code>--users 100 --startup-time 30m --run-time 5m</code> Goose will run for a total of 35 minutes, first ramping up for 30 minutes and then running at full load for 5 minutes. If you want Goose to exit immediately after all users start, you can set a very small run time, for example <code>--users 100 --hatch-rate .25 --run-time 1s</code>.</p>
<p>Alternatively, you can use <a href="getting-started/./test-plan.html"><code>--test-plan</code></a> to build both simple and more complex traffic patterns and can define how long the load test runs.</p>
<p>A final option is to instead use the <code>--iterations</code> option to configure how many times GooseUsers will run through their assigned Scenario before exiting.</p>
<p>If you do not configure a run time, Goose will run until it's canceled with <code>ctrl-c</code>.</p>
<h3 id="run-time-example"><a class="header" href="#run-time-example">Run time example</a></h3>
<p><em>Run the load test for 30 minutes.</em></p>
<pre><code class="language-bash">cargo run --release -- -t 30m
</code></pre>
<h3 id="iterations-example"><a class="header" href="#iterations-example">Iterations example</a></h3>
<p><em>Each GooseUser will take as long as it takes to fully run its assigned Scenario 5 times and then stop.</em></p>
<pre><code class="language-bash">cargo run --release -- --iterations 5
</code></pre>
<h2 id="writing-an-html-formatted-report"><a class="header" href="#writing-an-html-formatted-report">Writing An HTML-formatted Report</a></h2>
<p>By default, Goose displays <a href="getting-started/metrics.html">text-formatted metrics</a> when a load test finishes.</p>
<p>It can also optionally write one or more reports in HTML, Markdown, or JSON format. For that, you need to provide one or more <code>--report-file &lt;FILE&gt;</code> run-time options. All requested reports will be written.</p>
<p>The value of <code>&lt;FILE&gt;</code> is an absolute or relative path to the report file to generate. The file extension will evaluate the type of report to write. Any file that already exists at the specified path will be overwritten.</p>
<p>For more information, see <a href="getting-started/metrics.html#metrics-reports">Metrics Reports</a>.</p>
<p><img src="getting-started/rps.png" alt="Requests per second graph" /></p>
<h3 id="html-report-example"><a class="header" href="#html-report-example">HTML report example</a></h3>
<p><em>Write an HTML-formatted report to <code>report.html</code> when the load test finishes.</em></p>
<pre><code class="language-bash">cargo run --release -- --report-file report.html
</code></pre>
<h3 id="html--markdown-report-example"><a class="header" href="#html--markdown-report-example">HTML &amp; Markdown report example</a></h3>
<p><em>Write a Markdown and an HTML-formatted report when the load test finishes.</em></p>
<pre><code class="language-bash">cargo run --release -- --report-file report.md --report-file report.html
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="test-plan-1"><a class="header" href="#test-plan-1">Test Plan</a></h1>
<p>A load test that ramps up to full strength and then runs for a set amount of time can be configured by combining the <code>--startup-time</code> or <code>--hatch-rate</code> options together with the <code>--users</code> and <code>--run-time</code> options. For more complex load patterns you must instead use the <code>--test-plan</code> option.</p>
<p>A test plan is defined as a series of numerical pairs that each defines a number of users, and the amount of time to ramp to this number of users. For example, <code>10,60s</code> means "launch 10 users over 60 seconds". By stringing together multiple pairs separated by a semicolon you can define more complex test plans. For example, <code>10,1m;10,5m;0,0s</code> means "launch 10 users over 1 minute, continue with 10 users for 5 minutes, then shut down the load test as quickly as possible".</p>
<p>The amount of time can be defined in seconds (e.g. <code>10,5s</code>), minutes (e.g. <code>10,15m</code>) or hours (e.g. <code>10,1h</code>). The "s/m/h" notation is optional and seconds will be assumed if omitted. However, the explicit notation is recommended, since Goose will be able to detect any mistakes if used.</p>
<h2 id="simple-example"><a class="header" href="#simple-example">Simple Example</a></h2>
<p>The following command tells Goose to start 10 users over 60 seconds and then to run for 5 minutes before shutting down:</p>
<pre><code class="language-bash">$ cargo run --release -- -H http://local.dev/ --startup-time 1m --users 10 --run-time 5m --no-reset-metrics
</code></pre>
<p>The exact same behaviour can be defined with the following test plan:</p>
<pre><code class="language-bash">$ cargo run --release -- -H http://local.dev/ --test-plan "10,1m;10,5m;0,0s"
</code></pre>
<p><img src="getting-started/test-plan-simple.png" alt="Simple test plan" /></p>
<h2 id="ramp-down-example"><a class="header" href="#ramp-down-example">Ramp Down Example</a></h2>
<p>Goose will stop a load test as quickly as it can when the specified <code>--run-time</code> completes. To instead configure a load test to ramp down slowly you can use a test plan. In the following example, Goose starts 1000 users in 2 minutes and then slowly stops them over 500 seconds (stopping 2 users per second):</p>
<pre><code class="language-bash">$ cargo run --release -- -H http://local.dev/ --test-plan "1000,2m;0,500s"
</code></pre>
<p><img src="getting-started/test-plan-ramp-down.png" alt="Ramp down test plan" /></p>
<h2 id="load-spike-example"><a class="header" href="#load-spike-example">Load Spike Example</a></h2>
<p>Another possibility when specifying a test plan is to add load spikes into otherwise steady load. For example, in the following example Goose starts 500 users over 5 minutes and lets it run with a couple of traffic spikes to 2,500 users:</p>
<pre><code class="language-bash">$ cargo run --release -- -H http://local.dev/ --test-plan "500,5m;500,5m;2500,45s;500,45s;500,5m;2500,45s;500,45s;500,5m;0,0s"
</code></pre>
<p><img src="getting-started/test-plan-load-spike.png" alt="Load spike test plan" /></p>
<h2 id="internals"><a class="header" href="#internals">Internals</a></h2>
<p>Internally, Goose converts the test plan into a vector of usize tuples, <code>Vec&lt;(usize, usize)&gt;</code>, where the first integer reflects the number of users to be running and the second integer reflects the time in milliseconds. You can see the internal representation when you start a load test, for example:</p>
<pre><code class="language-bash">% cargo run --release --example simple -- --no-autostart --test-plan "100,30s;100,1h" | grep test_plan
13:54:35 [INFO] test_plan = GooseTestPlan { test_plan: [(100, 30000), (100, 3600000)] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="throttling-requests"><a class="header" href="#throttling-requests">Throttling Requests</a></h1>
<p>By default, Goose will generate as much load as it can. If this is not desirable, the throttle allows optionally limiting the maximum number of requests per second made during a load test. This can be helpful to ensure consistency when running a load test from multiple different servers with different available resources.</p>
<p>The throttle is specified as an integer and imposes a maximum number of requests, not a minimum number of requests.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<p>In this example, Goose will launch 100 GooseUser threads, but the throttle will prevent them from generating a combined total of more than 5 requests per second.</p>
<pre><code class="language-bash">$ cargo run --release -- -H http://local.dev/ -u100 -r20 --throttle-requests 5
</code></pre>
<p><img src="getting-started/throttle.png" alt="Throttled load test" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="limiting-which-scenarios-run"><a class="header" href="#limiting-which-scenarios-run">Limiting Which Scenarios Run</a></h1>
<p>It can often be useful to run only a subset of the <a href="getting-started/../glossary.html#scenario">Scenarios</a> defined by a load test. Instead of commenting them out in the source code and recompiling, the <code>--scenarios</code> run-time option allows you to dynamically control which Scenarios are running.</p>
<h2 id="listing-scenarios-by-machine-name"><a class="header" href="#listing-scenarios-by-machine-name">Listing Scenarios By Machine Name</a></h2>
<p>To ensure that each scenario has a unique name, you must use the machine name of the scenario when filtering which are running. For example, using the <a href="getting-started/../example/umami.html">Umami example</a> enable the <code>--scenarios-list</code> flag:</p>
<pre><code class="language-bash ignore">% cargo run --release --example umami -- --scenarios-list
    Finished release [optimized] target(s) in 0.15s
     Running `target/release/examples/umami --scenarios-list`
05:24:03 [INFO] Output verbosity level: INFO
05:24:03 [INFO] Logfile verbosity level: WARN
05:24:03 [INFO] users defaulted to number of CPUs = 10
05:24:03 [INFO] iterations = 0
Scenarios:
 - adminuser: ("Admin user")
 - anonymousenglishuser: ("Anonymous English user")
 - anonymousspanishuser: ("Anonymous Spanish user")
</code></pre>
<blockquote>
<p><strong>What Is A Machine Name:</strong> It is possible to name your Scenarios pretty much anything you want in your load test, including even using the same identical name for multiple Scenarios. A machine name ensures that you can still identify each Scenario uniquely, and without any special characters that can be difficult or insecure to pass through the command line. A machine name is made up of only the alphanumeric characters found in your Scenario's full name, and optionally with a number appended to differentiate between multiple Scenarios that would otherwise have the same name.</p>
<p>In the following example, we have three very similarly named Scenarios. One simply has an extra white space between words. The second has an airplane emoticon in the name. Both the extra space and the airplane symbol are stripped away from the machine name as they are not alphanumerics, and instead <code>_1</code> and <code>_2</code> are appended to the end to differentiate:</p>
<pre><code class="language-ignore">Scenarios:
- loadtesttransactions: ("LoadtestTransactions")
- loadtesttransactions_1: ("Loadtest Transactions")
- loadtesttransactions_2: ("LoadtestTransactions ✈️")

</code></pre>
</blockquote>
<h2 id="running-scenarios-by-machine-name"><a class="header" href="#running-scenarios-by-machine-name">Running Scenarios By Machine Name</a></h2>
<p>It is now possible to run any subset of the above scenarios by passing a comma separated list of machine names with the <code>--scenarios</code> run time option. Goose will match what you have typed against any machine name containing all or some of the typed text, so you do not have to type the full name. For example, to run only the two anonymous Scenarios, you could add <code>--scenarios anon</code>:</p>
<pre><code class="language-bash ignore">% cargo run --release --example umami -- --hatch-rate 10 --scenarios anon
    Finished release [optimized] target(s) in 0.15s
     Running `target/release/examples/umami --hatch-rate 10 --scenarios anon`
05:50:17 [INFO] Output verbosity level: INFO
05:50:17 [INFO] Logfile verbosity level: WARN
05:50:17 [INFO] users defaulted to number of CPUs = 10
05:50:17 [INFO] hatch_rate = 10
05:50:17 [INFO] iterations = 0
05:50:17 [INFO] scenarios = Scenarios { active: ["anon"] }
05:50:17 [INFO] host for Anonymous English user configured: https://drupal-9.ddev.site/
05:50:17 [INFO] host for Anonymous Spanish user configured: https://drupal-9.ddev.site/
05:50:17 [INFO] host for Admin user configured: https://drupal-9.ddev.site/
05:50:17 [INFO] allocating transactions and scenarios with RoundRobin scheduler
05:50:17 [INFO] initializing 10 user states...
05:50:17 [INFO] WebSocket controller listening on: 0.0.0.0:5117
05:50:17 [INFO] Telnet controller listening on: 0.0.0.0:5116
05:50:17 [INFO] entering GooseAttack phase: Increase
05:50:17 [INFO] launching user 1 from Anonymous Spanish user...
05:50:18 [INFO] launching user 2 from Anonymous English user...
05:50:18 [INFO] launching user 3 from Anonymous Spanish user...
05:50:18 [INFO] launching user 4 from Anonymous English user...
05:50:18 [INFO] launching user 5 from Anonymous Spanish user...
05:50:18 [INFO] launching user 6 from Anonymous English user...
05:50:18 [INFO] launching user 7 from Anonymous Spanish user...
^C05:50:18 [WARN] caught ctrl-c, stopping...
</code></pre>
<p>Or, to run only the "Anonymous Spanish user" and "Admin user" Scenarios, you could add <code>--senarios "spanish,admin"</code>:</p>
<pre><code class="language-bash ignore">% cargo run --release --example umami -- --hatch-rate 10 --scenarios "spanish,admin"
   Compiling goose v0.18.1 (/Users/jandrews/devel/goose)
    Finished release [optimized] target(s) in 11.79s
     Running `target/release/examples/umami --hatch-rate 10 --scenarios spanish,admin`
05:53:45 [INFO] Output verbosity level: INFO
05:53:45 [INFO] Logfile verbosity level: WARN
05:53:45 [INFO] users defaulted to number of CPUs = 10
05:53:45 [INFO] hatch_rate = 10
05:53:45 [INFO] iterations = 0
05:53:45 [INFO] scenarios = Scenarios { active: ["spanish", "admin"] }
05:53:45 [INFO] host for Anonymous English user configured: https://drupal-9.ddev.site/
05:53:45 [INFO] host for Anonymous Spanish user configured: https://drupal-9.ddev.site/
05:53:45 [INFO] host for Admin user configured: https://drupal-9.ddev.site/
05:53:45 [INFO] allocating transactions and scenarios with RoundRobin scheduler
05:53:45 [INFO] initializing 10 user states...
05:53:45 [INFO] Telnet controller listening on: 0.0.0.0:5116
05:53:45 [INFO] WebSocket controller listening on: 0.0.0.0:5117
05:53:45 [INFO] entering GooseAttack phase: Increase
05:53:45 [INFO] launching user 1 from Anonymous Spanish user...
05:53:45 [INFO] launching user 2 from Admin user...
05:53:45 [INFO] launching user 3 from Anonymous Spanish user...
05:53:45 [INFO] launching user 4 from Anonymous Spanish user...
05:53:45 [INFO] launching user 5 from Anonymous Spanish user...
05:53:45 [INFO] launching user 6 from Anonymous Spanish user...
05:53:45 [INFO] launching user 7 from Anonymous Spanish user...
05:53:45 [INFO] launching user 8 from Anonymous Spanish user...
05:53:45 [INFO] launching user 9 from Anonymous Spanish user...
05:53:46 [INFO] launching user 10 from Anonymous Spanish user...
^C05:53:46 [WARN] caught ctrl-c, stopping...
</code></pre>
<p>When the load test completes, you can refer to the <a href="getting-started/./metrics.html#scenarios">Scenario metrics</a> to confirm which Scenarios were enabled, and which were not.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-run-time-options"><a class="header" href="#custom-run-time-options">Custom Run Time Options</a></h1>
<p>It can sometimes be necessary to add custom run-time options to your load test. As Goose "owns" the command line, adding another option with <a href="https://docs.rs/gumdrop">gumdrop</a> (used by Goose) or another command line parser can be tricky, as Goose will throw an error if it receives an unexpected command line option. There are two alternatives here.</p>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>One option is to use environment variables. An example of this can be found in the <a href="getting-started/../example/umami.html">Umami example</a> which <a href="https://github.com/tag1consulting/goose/blob/main/examples/umami/admin.rs#L9">uses environment variables to allow the configuration of a custom username and password</a>.</p>
<p>Alternatively, you can use this method to set configurable custom defaults. The <a href="getting-started/./custom.html">earlier example</a> can be enhanced to use an environment variable to set a custom default hostname:</p>
<pre><code class="language-rust ignore">use goose::prelude::*;

async fn loadtest_index(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let _goose_metrics = user.get("").await?;

    Ok(())
}
#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    // Get optional custom default hostname from `HOST` environment variable.
    let custom_host = match std::env::var("HOST") {
        Ok(host) =&gt; host,
        Err(_) =&gt; "".to_string(),
    };

    GooseAttack::initialize()?
        .register_scenario(scenario!("LoadtestTransactions")
            .register_transaction(transaction!(loadtest_index))
        )
        // Set optional custom default hostname.
        .set_default(GooseDefault::Host, custom_host.as_str())?
        .execute()
        .await?;

    Ok(())
}</code></pre>
<p>This can now be used to set a custom default for the scenario, in this example with no <code>--host</code> set Goose will execute a load test against the hostname defined in <code>HOST</code>:</p>
<pre><code class="language-bash ignore">% HOST="https://local.dev/" cargo run --release                  
    Finished release [optimized] target(s) in 0.07s
     Running `target/release/loadtest`
07:28:20 [INFO] Output verbosity level: INFO
07:28:20 [INFO] Logfile verbosity level: WARN
07:28:20 [INFO] users defaulted to number of CPUs = 10
07:28:20 [INFO] iterations = 0
07:28:20 [INFO] host for LoadtestTransactions configured: https://local.dev/
</code></pre>
<p>It's still possible to override this custom default from the command line with standard Goose options, for example here the load test will run against the hostname configured by the <code>--host</code> option:</p>
<pre><code class="language-bash ignore">% HOST="http://local.dev/" cargo run --release -- --host https://example.com/
    Finished release [optimized] target(s) in 0.07s
     Running `target/release/loadtest --host 'https://example.com/'`
07:32:36 [INFO] Output verbosity level: INFO
07:32:36 [INFO] Logfile verbosity level: WARN
07:32:36 [INFO] users defaulted to number of CPUs = 10
07:32:36 [INFO] iterations = 0
07:32:36 [INFO] global host configured: https://example.com/
</code></pre>
<p>If the <code>HOST</code> variable and the <code>--host</code> option are not set, Goose will display the expected error:</p>
<pre><code class="language-bash ignore">% cargo run --release
     Running `target/release/loadtest`
07:07:45 [INFO] Output verbosity level: INFO
07:07:45 [INFO] Logfile verbosity level: WARN
07:07:45 [INFO] users defaulted to number of CPUs = 10
07:07:45 [INFO] iterations = 0
Error: InvalidOption { option: "--host", value: "", detail: "A host must be defined via the --host option, the GooseAttack.set_default() function, or the Scenario.set_host() function (no host defined for LoadtestTransactions)." }
</code></pre>
<h2 id="command-line-arguments"><a class="header" href="#command-line-arguments">Command Line Arguments</a></h2>
<p>If you really need to have custom command line arguments, there is a way to make Goose not throw an error due to unexpected arguments. You can do that by, instead of calling <code>GooseAttack::initialize()</code>, using <code>GooseAttack::initialize_with_config</code>. This method differs from the first one in that it does not parse arguments from the command line, but instead takes a <code>GooseConfiguration</code> value as parameter. Since this type has quite a lot of configuration options, with some private fields, currently the only way you can obtain an instance of it is via the <code>Default</code> trait: <code>GooseConfiguration::default()</code>.</p>
<p>Note that by initializing the <code>GooseAttack</code> in this way you are preventing Goose from reading command line arguments, so if you want to have the ability of passing the arguments that Goose allows, you will need to parse them and set them in the <code>GooseConfiguration</code> instance. In particular, the <code>--host</code> parameter is mandatory, so don't forget to set it in the configuration somehow.</p>
<p>The example below should illustrate these points:</p>
<pre><code class="language-rust ignore">use goose::config::GooseConfiguration;

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    // here we could be using a crate such as `clap` to parse CLI arguments:
    let opt = MyCustomConfig::parse();

    let mut config = GooseConfiguration::default();

    // we added a `host` field to our custom argument parser that matches
    // the `host` field used by Goose
    config.host = opt.host;

    // ... here you should do the same for all the other command line parameters
    // offered by Goose that you care about, otherwise they will not be taken
    // into account.

    // Initialize the `GooseAttack` using the `GooseConfiguration`:
    GooseAttack::initialize_with_config(config)?
        .register_scenario(
            scenario!("User")
                .register_transaction(transaction!(loadtest_index))
        )
        .execute()
        .await?;

    Ok(())
}</code></pre>
<p>Assuming that <code>MyCustomConfig</code> has a <code>my_custom_arg</code> field, the program above can be invoked with a command such as:</p>
<pre><code class="language-bash ignore">cargo run -- --host https://localhost:8080 --my-custom-arg 42
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metrics"><a class="header" href="#metrics">Metrics</a></h1>
<p>Here's sample output generated when running a loadtest, in this case the <a href="getting-started/../example/umami.html">Umami example</a> that comes with Goose.</p>
<p>In this case, the <a href="https://www.drupal.org/docs/umami-drupal-demonstration-installation-profile">Drupal Umami demo</a> was installed in a local container. The following command was used to configure Goose and run the load test. The <code>-u9</code> tells Goose to spin up 9 users. The <code>-r3</code> option tells Goose to hatch 3 users per second. The <code>-t1m</code> option tells Goose to run the load test for 1 minute, or 60 seconds. The <code>--no-reset-metrics</code> flag tells Goose to include all metrics, instead of the default which is to flush all metrics collected during start up. And finally, the <code>--report-file report.html</code> tells Goose to generate an HTML-formatted report named <code>report.html</code> once the load test finishes.</p>
<h2 id="ascii-metrics"><a class="header" href="#ascii-metrics">ASCII metrics</a></h2>
<pre><code class="language-bash">% cargo run --release --example umami -- --host http://umami.ddev.site/ -u9 -r3 -t1m --no-reset-metrics --report-file report.html
   Compiling goose v0.18.1 (~/goose)
    Finished release [optimized] target(s) in 11.88s
     Running `target/release/examples/umami --host 'http://umami.ddev.site/' -u9 -r3 -t1m --no-reset-metrics --report-file report.html`
05:09:05 [INFO] Output verbosity level: INFO
05:09:05 [INFO] Logfile verbosity level: WARN
05:09:05 [INFO] users = 9
05:09:05 [INFO] run_time = 60
05:09:05 [INFO] hatch_rate = 3
05:09:05 [INFO] no_reset_metrics = true
05:09:05 [INFO] report_file = report.html
05:09:05 [INFO] iterations = 0
05:09:05 [INFO] global host configured: http://umami.ddev.site/
05:09:05 [INFO] allocating transactions and scenarios with RoundRobin scheduler
05:09:05 [INFO] initializing 9 user states...
05:09:05 [INFO] Telnet controller listening on: 0.0.0.0:5116
05:09:05 [INFO] WebSocket controller listening on: 0.0.0.0:5117
05:09:05 [INFO] entering GooseAttack phase: Increase
05:09:05 [INFO] [user 1]: launching user from Anonymous Spanish user
05:09:05 [INFO] [user 2]: launching user from Anonymous English user
05:09:05 [INFO] [user 3]: launching user from Anonymous Spanish user
05:09:06 [INFO] [user 4]: launching user from Anonymous English user
05:09:06 [INFO] [user 5]: launching user from Anonymous Spanish user
05:09:06 [INFO] [user 6]: launching user from Anonymous English user
05:09:07 [INFO] [user 7]: launching user from Admin user
05:09:07 [INFO] [user 8]: launching user from Anonymous Spanish user
05:09:07 [INFO] [user 9]: launching user from Anonymous English user
All 9 users hatched.

05:09:08 [INFO] entering GooseAttack phase: Maintain
05:10:08 [INFO] entering GooseAttack phase: Decrease
05:10:08 [INFO] [user 2]: exiting user from Anonymous English user
05:10:08 [INFO] [user 3]: exiting user from Anonymous Spanish user
05:10:08 [INFO] [user 6]: exiting user from Anonymous English user
05:10:08 [INFO] [user 8]: exiting user from Anonymous Spanish user
05:10:08 [INFO] [user 4]: exiting user from Anonymous English user
05:10:08 [INFO] [user 7]: exiting user from Admin user
05:10:08 [INFO] [user 1]: exiting user from Anonymous Spanish user
05:10:08 [INFO] [user 9]: exiting user from Anonymous English user
05:10:08 [INFO] [user 5]: exiting user from Anonymous Spanish user
05:10:08 [INFO] wrote html report file to: report.html
05:10:08 [INFO] entering GooseAttack phase: Shutdown
05:10:08 [INFO] printing final metrics after 63 seconds...

 === PER SCENARIO METRICS ===
 ------------------------------------------------------------------------------
 Name                     |  # users |  # times run | scenarios/s | iterations
 ------------------------------------------------------------------------------
 1: Anonymous English u.. |        4 |            8 |        0.13 |       2.00
 2: Anonymous Spanish u.. |        4 |            8 |        0.13 |       2.00
 3: Admin user            |        1 |            1 |        0.02 |       1.00
 -------------------------+----------+--------------+-------------+------------
 Aggregated               |        9 |           17 |        0.27 |       1.89
 ------------------------------------------------------------------------------
 Name                     |    Avg (ms) |        Min |         Max |     Median
 ------------------------------------------------------------------------------
   1: Anonymous English.. |       25251 |     19,488 |      31,308 |     19,488
   2: Anonymous Spanish.. |       24394 |     20,954 |      27,821 |     20,954
   3: Admin user          |       32431 |     32,431 |      32,431 |     32,431
 -------------------------+-------------+------------+-------------+-----------
 Aggregated               |       25270 |     19,488 |      32,431 |     19,488

 === PER TRANSACTION METRICS ===
 ------------------------------------------------------------------------------
 Name                     |   # times run |        # fails |  trans/s |  fail/s
 ------------------------------------------------------------------------------
 1: Anonymous English user
   1: anon /              |            21 |         0 (0%) |     0.33 |    0.00
   2: anon /en/basicpage  |            12 |         0 (0%) |     0.19 |    0.00
   3: anon /en/articles/  |            12 |         0 (0%) |     0.19 |    0.00
   4: anon /en/articles/% |            21 |         0 (0%) |     0.33 |    0.00
   5: anon /en/recipes/   |            12 |         0 (0%) |     0.19 |    0.00
   6: anon /en/recipes/%  |            36 |         0 (0%) |     0.57 |    0.00
   7: anon /node/%nid     |            11 |         0 (0%) |     0.17 |    0.00
   8: anon /en term       |            19 |         0 (0%) |     0.30 |    0.00
   9: anon /en/search     |             9 |         0 (0%) |     0.14 |    0.00
   10: anon /en/contact   |             9 |         0 (0%) |     0.14 |    0.00
 2: Anonymous Spanish user
   1: anon /es/           |            22 |         0 (0%) |     0.35 |    0.00
   2: anon /es/basicpage  |            12 |         0 (0%) |     0.19 |    0.00
   3: anon /es/articles/  |            12 |         0 (0%) |     0.19 |    0.00
   4: anon /es/articles/% |            21 |         0 (0%) |     0.33 |    0.00
   5: anon /es/recipes/   |            12 |         0 (0%) |     0.19 |    0.00
   6: anon /es/recipes/%  |            37 |         0 (0%) |     0.59 |    0.00
   7: anon /es term       |            21 |         0 (0%) |     0.33 |    0.00
   8: anon /es/search     |            12 |         0 (0%) |     0.19 |    0.00
   9: anon /es/contact    |            10 |         0 (0%) |     0.16 |    0.00
 3: Admin user           
   1: auth /en/user/login |             1 |         0 (0%) |     0.02 |    0.00
   2: auth /              |             4 |         0 (0%) |     0.06 |    0.00
   3: auth /en/articles/  |             2 |         0 (0%) |     0.03 |    0.00
   4: auth /en/node/%/e.. |             3 |         0 (0%) |     0.05 |    0.00
 -------------------------+---------------+----------------+----------+--------
 Aggregated               |           331 |         0 (0%) |     5.25 |    0.00
 ------------------------------------------------------------------------------
 Name                     |    Avg (ms) |        Min |         Max |     Median
 ------------------------------------------------------------------------------
 1: Anonymous English user
   1: anon /              |      123.48 |         85 |         224 |        110
   2: anon /en/basicpage  |       56.08 |         44 |          75 |         50
   3: anon /en/articles/  |      147.58 |         91 |         214 |        140
   4: anon /en/articles/% |      148.14 |         72 |         257 |        160
   5: anon /en/recipes/   |      170.58 |        109 |         242 |        150
   6: anon /en/recipes/%  |       66.08 |         48 |         131 |         60
   7: anon /node/%nid     |       94.09 |         46 |         186 |         70
   8: anon /en term       |      134.37 |         52 |         194 |        130
   9: anon /en/search     |      282.33 |        190 |         339 |        270
   10: anon /en/contact   |      246.89 |        186 |         346 |        260
 2: Anonymous Spanish user
   1: anon /es/           |      141.36 |         88 |         285 |        130
   2: anon /es/basicpage  |       61.17 |         43 |          92 |         51
   3: anon /es/articles/  |      130.58 |         87 |         187 |        110
   4: anon /es/articles/% |      164.52 |         85 |         263 |        170
   5: anon /es/recipes/   |      161.25 |        108 |         274 |        120
   6: anon /es/recipes/%  |       65.24 |         47 |         107 |         61
   7: anon /es term       |      145.14 |         49 |         199 |        150
   8: anon /es/search     |      276.33 |        206 |         361 |        270
   9: anon /es/contact    |      240.20 |        204 |         297 |        230
 3: Admin user           
   1: auth /en/user/login |      262.00 |        262 |         262 |        262
   2: auth /              |      260.75 |        238 |         287 |        250
   3: auth /en/articles/  |      232.00 |        220 |         244 |        220
   4: auth /en/node/%/e.. |      745.67 |        725 |         771 |        725
 -------------------------+-------------+------------+-------------+-----------
 Aggregated               |      141.73 |         43 |         771 |        120

 === PER REQUEST METRICS ===
 ------------------------------------------------------------------------------
 Name                     |        # reqs |        # fails |    req/s |  fail/s
 ------------------------------------------------------------------------------
 GET anon /               |            21 |         0 (0%) |     0.33 |    0.00
 GET anon /en term        |            19 |         0 (0%) |     0.30 |    0.00
 GET anon /en/articles/   |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /en/articles/%  |            21 |         0 (0%) |     0.33 |    0.00
 GET anon /en/basicpage   |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /en/contact     |             9 |         0 (0%) |     0.14 |    0.00
 GET anon /en/recipes/    |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /en/recipes/%   |            36 |         0 (0%) |     0.57 |    0.00
 GET anon /en/search      |             9 |         0 (0%) |     0.14 |    0.00
 GET anon /es term        |            21 |         0 (0%) |     0.33 |    0.00
 GET anon /es/            |            22 |         0 (0%) |     0.35 |    0.00
 GET anon /es/articles/   |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /es/articles/%  |            21 |         0 (0%) |     0.33 |    0.00
 GET anon /es/basicpage   |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /es/contact     |            10 |         0 (0%) |     0.16 |    0.00
 GET anon /es/recipes/    |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /es/recipes/%   |            37 |         0 (0%) |     0.59 |    0.00
 GET anon /es/search      |            12 |         0 (0%) |     0.19 |    0.00
 GET anon /node/%nid      |            11 |         0 (0%) |     0.17 |    0.00
 GET auth /               |             4 |         0 (0%) |     0.06 |    0.00
 GET auth /en/articles/   |             2 |         0 (0%) |     0.03 |    0.00
 GET auth /en/node/%/edit |             6 |         0 (0%) |     0.10 |    0.00
 GET auth /en/user/login  |             1 |         0 (0%) |     0.02 |    0.00
 GET static asset         |         3,516 |         0 (0%) |    55.81 |    0.00
 POST anon /en/contact    |             9 |         0 (0%) |     0.14 |    0.00
 POST anon /en/search     |             9 |         0 (0%) |     0.14 |    0.00
 POST anon /es/contact    |            10 |         0 (0%) |     0.16 |    0.00
 POST anon /es/search     |            12 |         0 (0%) |     0.19 |    0.00
 POST auth /en/node/%/e.. |             3 |         0 (0%) |     0.05 |    0.00
 POST auth /en/user/login |             1 |         0 (0%) |     0.02 |    0.00
 -------------------------+---------------+----------------+----------+--------
 Aggregated               |         3,894 |         0 (0%) |    61.81 |    0.00
 ------------------------------------------------------------------------------
 Name                     |    Avg (ms) |        Min |         Max |     Median
 ------------------------------------------------------------------------------
 GET anon /               |       38.95 |         14 |         132 |         24
 GET anon /en term        |       95.63 |         22 |         159 |         98
 GET anon /en/articles/   |       61.67 |         16 |         139 |         42
 GET anon /en/articles/%  |       94.86 |         20 |         180 |        100
 GET anon /en/basicpage   |       25.67 |         17 |          40 |         24
 GET anon /en/contact     |       34.67 |         16 |          61 |         30
 GET anon /en/recipes/    |       59.83 |         17 |         130 |         45
 GET anon /en/recipes/%   |       27.86 |         16 |          56 |         22
 GET anon /en/search      |       54.33 |         20 |         101 |         30
 GET anon /es term        |      106.14 |         19 |         159 |        110
 GET anon /es/            |       51.41 |         18 |         179 |         29
 GET anon /es/articles/   |       53.42 |         17 |         110 |         27
 GET anon /es/articles/%  |      105.52 |         20 |         203 |        110
 GET anon /es/basicpage   |       27.25 |         18 |          55 |         22
 GET anon /es/contact     |       27.80 |         17 |          49 |         24
 GET anon /es/recipes/    |       59.08 |         18 |         165 |         26
 GET anon /es/recipes/%   |       28.65 |         16 |          61 |         26
 GET anon /es/search      |       46.42 |         17 |          99 |         25
 GET anon /node/%nid      |       52.73 |         17 |         133 |         38
 GET auth /               |      140.75 |        109 |         169 |        120
 GET auth /en/articles/   |      103.50 |         89 |         118 |         89
 GET auth /en/node/%/edit |      114.83 |         91 |         136 |        120
 GET auth /en/user/login  |       24.00 |         24 |          24 |         24
 GET static asset         |        5.11 |          2 |          38 |          5
 POST anon /en/contact    |      136.67 |         99 |         204 |        140
 POST anon /en/search     |      162.11 |        114 |         209 |        170
 POST anon /es/contact    |      137.70 |        111 |         174 |        130
 POST anon /es/search     |      164.08 |        118 |         235 |        140
 POST auth /en/node/%/e.. |      292.33 |        280 |         304 |        290
 POST auth /en/user/login |      143.00 |        143 |         143 |        143
 -------------------------+-------------+------------+-------------+-----------
 Aggregated               |       11.41 |          2 |         304 |          5
 ------------------------------------------------------------------------------
 Slowest page load within specified percentile of requests (in ms):
 ------------------------------------------------------------------------------
 Name                     |    50% |    75% |    98% |    99% |  99.9% | 99.99%
 ------------------------------------------------------------------------------
 GET anon /               |     24 |     29 |    130 |    130 |    130 |    130
 GET anon /en term        |     98 |    110 |    159 |    159 |    159 |    159
 GET anon /en/articles/   |     42 |     92 |    139 |    139 |    139 |    139
 GET anon /en/articles/%  |    100 |    120 |    180 |    180 |    180 |    180
 GET anon /en/basicpage   |     24 |     30 |     40 |     40 |     40 |     40
 GET anon /en/contact     |     30 |     46 |     61 |     61 |     61 |     61
 GET anon /en/recipes/    |     45 |     88 |    130 |    130 |    130 |    130
 GET anon /en/recipes/%   |     22 |     31 |     55 |     56 |     56 |     56
 GET anon /en/search      |     30 |     89 |    100 |    100 |    100 |    100
 GET anon /es term        |    110 |    130 |    159 |    159 |    159 |    159
 GET anon /es/            |     29 |     57 |    179 |    179 |    179 |    179
 GET anon /es/articles/   |     27 |     96 |    110 |    110 |    110 |    110
 GET anon /es/articles/%  |    110 |    140 |    200 |    200 |    200 |    200
 GET anon /es/basicpage   |     22 |     27 |     55 |     55 |     55 |     55
 GET anon /es/contact     |     24 |     35 |     49 |     49 |     49 |     49
 GET anon /es/recipes/    |     26 |    110 |    165 |    165 |    165 |    165
 GET anon /es/recipes/%   |     26 |     34 |     57 |     61 |     61 |     61
 GET anon /es/search      |     25 |     78 |     99 |     99 |     99 |     99
 GET anon /node/%nid      |     38 |     41 |    130 |    130 |    130 |    130
 GET auth /               |    120 |    160 |    169 |    169 |    169 |    169
 GET auth /en/articles/   |     89 |    118 |    118 |    118 |    118 |    118
 GET auth /en/node/%/edit |    120 |    130 |    136 |    136 |    136 |    136
 GET auth /en/user/login  |     24 |     24 |     24 |     24 |     24 |     24
 GET static asset         |      5 |      6 |     10 |     13 |     29 |     38
 POST anon /en/contact    |    140 |    150 |    200 |    200 |    200 |    200
 POST anon /en/search     |    170 |    180 |    209 |    209 |    209 |    209
 POST anon /es/contact    |    130 |    150 |    170 |    170 |    170 |    170
 POST anon /es/search     |    140 |    180 |    235 |    235 |    235 |    235
 POST auth /en/node/%/e.. |    290 |    290 |    300 |    300 |    300 |    300
 POST auth /en/user/login |    143 |    143 |    143 |    143 |    143 |    143
 -------------------------+--------+--------+--------+--------+--------+-------
 Aggregated               |      5 |      7 |    120 |    140 |    240 |    300
 ------------------------------------------------------------------------------
 Name                     |                                        Status codes 
 ------------------------------------------------------------------------------
 GET anon /               |                                            21 [200]
 GET anon /en term        |                                            19 [200]
 GET anon /en/articles/   |                                            12 [200]
 GET anon /en/articles/%  |                                            21 [200]
 GET anon /en/basicpage   |                                            12 [200]
 GET anon /en/contact     |                                             9 [200]
 GET anon /en/recipes/    |                                            12 [200]
 GET anon /en/recipes/%   |                                            36 [200]
 GET anon /en/search      |                                             9 [200]
 GET anon /es term        |                                            21 [200]
 GET anon /es/            |                                            22 [200]
 GET anon /es/articles/   |                                            12 [200]
 GET anon /es/articles/%  |                                            21 [200]
 GET anon /es/basicpage   |                                            12 [200]
 GET anon /es/contact     |                                            10 [200]
 GET anon /es/recipes/    |                                            12 [200]
 GET anon /es/recipes/%   |                                            37 [200]
 GET anon /es/search      |                                            12 [200]
 GET anon /node/%nid      |                                            11 [200]
 GET auth /               |                                             4 [200]
 GET auth /en/articles/   |                                             2 [200]
 GET auth /en/node/%/edit |                                             6 [200]
 GET auth /en/user/login  |                                             1 [200]
 GET static asset         |                                         3,516 [200]
 POST anon /en/contact    |                                             9 [200]
 POST anon /en/search     |                                             9 [200]
 POST anon /es/contact    |                                            10 [200]
 POST anon /es/search     |                                            12 [200]
 POST auth /en/node/%/e.. |                                             3 [200]
 POST auth /en/user/login |                                             1 [200]
 -------------------------+----------------------------------------------------
 Aggregated               |                                         3,894 [200] 

 === OVERVIEW ===
 ------------------------------------------------------------------------------
 Action       Started               Stopped             Elapsed    Users
 ------------------------------------------------------------------------------
 Increasing:  2022-05-17 07:09:05 - 2022-05-17 07:09:08 (00:00:03, 0 -&gt; 9)
 Maintaining: 2022-05-17 07:09:08 - 2022-05-17 07:10:08 (00:01:00, 9)
 Decreasing:  2022-05-17 07:10:08 - 2022-05-17 07:10:08 (00:00:00, 0 &lt;- 9)

 Target host: http://umami.ddev.site/
 goose v0.18.1
 ------------------------------------------------------------------------------
</code></pre>
<h2 id="metrics-reports"><a class="header" href="#metrics-reports">Metrics reports</a></h2>
<p>In addition to the above metrics displayed on the CLI, we've also told Goose to create reports on other formats, like Markdown, JSON, or HTML.</p>
<p>It is possible to create one or more reports at the same time, using one or more <code>--report-file</code> arguments. The type of report is chosen by the file extension. An unsupported file extension will lead to an error.</p>
<p>The following subsections describe the reports on more detail.</p>
<h3 id="html-report-1"><a class="header" href="#html-report-1">HTML report</a></h3>
<h4 id="overview"><a class="header" href="#overview">Overview</a></h4>
<p>The HTML report starts with a brief overview table, offering the same information found in the <a href="getting-started/metrics.html#ascii-metrics">ASCII overview</a> above:
<img src="getting-started/metrics-overview.jpg" alt="Metrics overview" /></p>
<p><strong>NOTE:</strong> The HTML report includes some graphs that rely on the <a href="https://echarts.apache.org">eCharts JavaScript library</a>. The HTML report loads the library via CDN, which means that the graphs won't be loaded correctly if the CDN is not accessible.</p>
<h4 id="requests"><a class="header" href="#requests">Requests</a></h4>
<p>Next the report includes a graph of all requests made during the duration of the load test. By default, the graph includes an aggregated average, as well as per-request details. It's possible to click on the request names at the top of the graph to hide/show specific requests on the graphs. In this case, the graph shows that most requests made by the load test were for static assets.</p>
<p>Below the graph is a table that shows per-request details, only partially included in this screenshot:
<img src="getting-started/metrics-requests.jpg" alt="Request metrics" /></p>
<h4 id="response-times"><a class="header" href="#response-times">Response times</a></h4>
<p>The next graph shows the response times measured for each request made. In the following graph, it's apparent that POST requests had the slowest responses, which is logical as they are not cached. As before, it's possible to click on the request names at the top of the graph to hide/show details about specific requests.</p>
<p>Below the graph is a table that shows per-request details:
<img src="getting-started/metrics-response-time.jpg" alt="Response time metrics" /></p>
<h4 id="status-codes"><a class="header" href="#status-codes">Status codes</a></h4>
<p>All status codes returned by the server are displayed in a table, per-request and in aggregate. In our simple test, we received only <code>200 OK</code> responses.
<img src="getting-started/metrics-status-codes.jpg" alt="Status code metrics" /></p>
<h4 id="transactions"><a class="header" href="#transactions">Transactions</a></h4>
<p>The next graph summarizes all Transactions run during the load test. One or more requests are grouped logically inside Transactions. For example, the Transaction named <code>0.0 anon /</code> includes an anonymous (not-logged-in) request for the front page, as well as requests for all static assets found on the front page.</p>
<p>Whereas a Request automatically fails based on the web server response code, the code that defines a Transaction must manually return an error for a Task to be considered failed. For example, the logic may be written to fail the Transaction of the html request fails, but not if one or more static asset requests fail.</p>
<p>This graph is also followed by a table showing details on all Transactions, partially shown here:
<img src="getting-started/metrics-transactions.jpg" alt="Transaction metrics" /></p>
<h4 id="scenarios"><a class="header" href="#scenarios">Scenarios</a></h4>
<p>The next graph summarizes all Scenarios run during the load test. One or more Transactions are grouped logically inside Scenarios.</p>
<p>For example, the Scenario named <code>Anonymous English user</code> includes the above <code>anon /</code> Transaction, the <code>anon /en/basicpage</code>, and all the rest of the Transactions requesting pages in English.</p>
<p>It is followed by a table, shown in entirety here because this load test only has 3 Scenarios. The <code># Users</code> column indicates how many <code>GooseUser</code> threads were assigned to run this Scenario during the load test. The <code># Times Run</code> column indicates how many times in aggregate all <code>GooseUser</code> threads ran completely through the Scenario. From there you can see how long on average it took a <code>GooseUser</code> thread to run through all Transactions and make all contained Requests to completely run the Scenario, as well as the minimum and maximum amount of time. Finally, <code>Iterations</code> is how many times each assigned <code>GooseUser</code> thread ran through the entire Scenario (Iterations times the # of Users will always equal the total # of times run).</p>
<p>As our example only ran for 60 seconds, and the <code>Admin user</code> Scenario took &gt;30 seconds to run once, the load test only ran completely through this scenario one time, also reflected in the following table:
<img src="getting-started/metrics-scenarios.jpg" alt="Scenario metrics" /></p>
<h4 id="users"><a class="header" href="#users">Users</a></h4>
<p>The final graph shows how many users were running at the various stages of the load test. As configured, Goose quickly ramped up to 9 users, then sustained that level of traffic for a minute before shutting down:
<img src="getting-started/metrics-users.jpg" alt="User metrics" /></p>
<h3 id="markdown-report"><a class="header" href="#markdown-report">Markdown report</a></h3>
<p>The Markdown report follows the structure of the <a href="getting-started/metrics.html#html-report">HTML report</a>. However, it does not include the chart elements.</p>
<h3 id="json-report"><a class="header" href="#json-report">JSON report</a></h3>
<p>The JSON report is a dump of the internal metrics collection. It is a JSON serialization of the <code>ReportData</code> structure. Mainly having a field named <code>raw_metrics</code>, carrying the content of <a href="https://docs.rs/goose/latest/goose/metrics/struct.GooseMetrics.html"><code>GooseMetrics</code></a>.</p>
<h3 id="developer-documentation"><a class="header" href="#developer-documentation">Developer documentation</a></h3>
<p>Additional details about how metrics are collected, stored, and displayed can be found <a href="https://docs.rs/goose/*/goose/metrics/index.html">in the developer documentation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tips"><a class="header" href="#tips">Tips</a></h1>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ul>
<li>When writing load tests, avoid <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.unwrap"><code>unwrap()</code></a> (and variations) in your transaction functions -- Goose generates a lot of load, and this tends to trigger errors. Embrace Rust's warnings and properly handle all possible errors, this will save you time debugging later.</li>
<li>When running your load test, use the cargo <code>--release</code> flag to generate optimized code. This can generate considerably more load test traffic. Learn more about this and other optimizations in <a href="https://www.tag1consulting.com/blog/golden-goose-egg-compile-time-adventure">"The golden Goose egg, a compile-time adventure"</a>.</li>
</ul>
<h2 id="errors"><a class="header" href="#errors">Errors</a></h2>
<h3 id="timeouts"><a class="header" href="#timeouts">Timeouts</a></h3>
<p>By default, Goose will time out requests that take longer than 60 seconds to return, and display a <code>WARN</code> level message saying, "operation timed out". For example:</p>
<pre><code class="language-ignore">11:52:17 [WARN] "/node/3672": error sending request for url (http://apache/node/3672): operation timed out
</code></pre>
<p>These will also show up in the error summary displayed with the final metrics. For example:</p>
<pre><code class="language-ignore"> === ERRORS ===
 ------------------------------------------------------------------------------
 Count       | Error
 ------------------------------------------------------------------------------
 51            GET (Auth) comment form: error sending request (Auth) comment form: operation timed out
</code></pre>
<p>To change how long before requests time out, use <code>--timeout VALUE</code> when starting a load test, for example <code>--timeout 30</code> will time out requests that take longer than 30 seconds to return. To configure the timeout programatically, use <a href="https://docs.rs/goose/*/goose/config/trait.GooseDefaultType.html#tymethod.set_default"><code>.set_default()</code></a> to set <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.Timeout">GooseDefault::Timeout</a>.</p>
<p>To completely disable timeouts, you must build a custom Reqwest Client with <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.set_client_builder"><code>GooseUser::set_client_builder</code></a>. Alternatively, you can just set a very high timeout, for example <code>--timeout 86400</code> will let a request take up to 24 hours.</p>
<h2 id="debugging-html-responses"><a class="header" href="#debugging-html-responses">Debugging HTML Responses</a></h2>
<p>Sometimes, while developing and debugging a load test we'd like to view HTML responses in a browser to actually see where each request is actually taking us. We may want to run this test with one user to avoid debug noise.</p>
<p>We can create a debug log by passing the <code>--debug-log NAME</code> command line option.</p>
<p>Each row in the debug log defaults to a JSON object and we can use <a href="https://stedolan.github.io/jq/">jq</a> for processing JSON or the faster Rust port that supports the same commands <a href="https://crates.io/crates/jaq">jaq</a></p>
<p>To extract the HTML response from the first log entry, for example, you could use the following commands:</p>
<pre><code class="language-bash ignore">cat debug.log | head -n 1 | jaq -r .body &gt; page.html
</code></pre>
<p>This HTML page can then be viewed in a web browser. You may need to disable JavaScript.</p>
<h2 id="killswitch"><a class="header" href="#killswitch">Killswitch</a></h2>
<p>Goose provides a killswitch mechanism to programmatically stop a load test when specific conditions are met. This is useful for protecting your systems and ensuring tests stop automatically when problems are detected.</p>
<h3 id="common-use-cases"><a class="header" href="#common-use-cases">Common Use Cases</a></h3>
<ul>
<li><strong>Error Rate Threshold</strong>: Stop when error rate exceeds acceptable limits</li>
<li><strong>Response Time SLA Monitoring</strong>: Halt testing when latency violates requirements</li>
<li><strong>Health Check Integration</strong>: Monitor system health endpoints and stop on failure</li>
<li><strong>Resource Exhaustion Detection</strong>: Stop when detecting connection pool or memory issues</li>
<li><strong>Sitemap Traversal Completion</strong>: Stop after fully crawling a site's pages</li>
<li><strong>Data Set Processing</strong>: Stop when all test data has been consumed</li>
<li><strong>External Signal Integration</strong>: Stop based on monitoring system alerts</li>
</ul>
<h3 id="example-service-unavailable-detection"><a class="header" href="#example-service-unavailable-detection">Example: Service Unavailable Detection</a></h3>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use goose::prelude::*;

async fn check_availability(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let mut response = user.get("/api/endpoint").await?;
    
    // Stop the test if server returns 503 Service Unavailable
    if let Ok(response) = response.response {
        if response.status() == 503 {
            goose::trigger_killswitch("Server returned 503: Service Unavailable");
        }
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p>You can also check if the killswitch has been triggered using <code>goose::is_killswitch_triggered()</code> to conditionally execute cleanup code or skip certain operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logging"><a class="header" href="#logging">Logging</a></h1>
<p>With logging, it's possible to record all Goose activity. This can be useful for debugging errors, for validating the load test, and for creating graphs.</p>
<p>When logging is enabled, a central logging thread maintains a buffer to minimize the IO overhead, and controls the writing to ensure that multiple threads don't corrupt each other's messages. All log messages are sent through a channel to the logging thread and written asynchronously, minimizing the impact on the load test.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="request-log"><a class="header" href="#request-log">Request Log</a></h1>
<p>Goose can optionally log details about all the requests made during the load test to a file. This log file contains the running metrics Goose generates as the load test runs. To enable, add the <code>--request-log &lt;request.log&gt;</code> command line option, where <code>&lt;request.log&gt;</code> is either a relative or absolute path of the log file to create. Any existing file that may already exist will be overwritten.</p>
<p>If <code>--request-body</code> is also enabled, the request log will include the entire body of any client requests.</p>
<p>Logs include the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html"><code>GooseRequestMetric</code></a> object which also includes the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRawRequest.html"><code>GooseRawRequest</code></a> object, both created for all client requests.</p>
<h2 id="log-format"><a class="header" href="#log-format">Log Format</a></h2>
<p>By default, logs are written in JSON Lines format. For example (in this case with <code>--request-body</code> also enabled):</p>
<pre><code class="language-json">{"coordinated_omission_elapsed":0,"elapsed":13219,"error":"","final_url":"http://apache/misc/jquery-extend-3.4.0.js?v=1.4.4","name":"static asset","raw":{"body":"","headers":[],"method":"Get","url":"http://apache/misc/jquery-extend-3.4.0.js?v=1.4.4"},"redirected":false,"response_time":7,"status_code":200,"success":true,"update":false,"user":4,"user_cadence":0}
{"coordinated_omission_elapsed":0,"elapsed":13055,"error":"","final_url":"http://apache/node/1786#comment-114852","name":"(Auth) comment form","raw":{"body":"subject=this+is+a+test+comment+subject&amp;comment_body%5Bund%5D%5B0%5D%5Bvalue%5D=this+is+a+test+comment+body&amp;comment_body%5Bund%5D%5B0%5D%5Bformat%5D=filtered_html&amp;form_build_id=form-U0L3wm2SsIKAhVhaHpxeL1TLUHW64DXKifmQeZsUsss&amp;form_token=VKDel_jiYzjqPrekL1FrP2_4EqHTlsaqLjMUJ6pn-sE&amp;form_id=comment_node_article_form&amp;op=Save","headers":["(\"content-type\", \"application/x-www-form-urlencoded\")"],"method":"Post","url":"http://apache/comment/reply/1786"},"redirected":true,"response_time":172,"status_code":200,"success":true,"update":false,"user":1,"user_cadence":0}
{"coordinated_omission_elapsed":0,"elapsed":13219,"error":"","final_url":"http://apache/misc/drupal.js?q9apdy","name":"static asset","raw":{"body":"","headers":[],"method":"Get","url":"http://apache/misc/drupal.js?q9apdy"},"redirected":false,"response_time":7,"status_code":200,"success":true,"update":false,"user":0,"user_cadence":0}
</code></pre>
<p>The <code>--request-format</code> option can be used to log in <code>csv</code>, <code>json</code> (default), <code>raw</code> or <code>pretty</code> format. The <code>raw</code> format is Rust's debug output of the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html"><code>GooseRequestMetric</code></a> object.</p>
<h2 id="gaggle-mode"><a class="header" href="#gaggle-mode">Gaggle Mode</a></h2>
<p>When operating in Gaggle-mode, the <code>--request-log</code> option can only be enabled on the Worker processes, configuring Goose to spread out the overhead of writing logs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transaction-log"><a class="header" href="#transaction-log">Transaction Log</a></h1>
<p>Goose can optionally log details about each time a transaction is run during a load test.  To enable, add the <code>--transaction-log &lt;transaction.log&gt;</code> command line option, where <code>&lt;transaction.log&gt;</code> is either a relative or absolute path of the log file to create. Any existing file that may already exist will be overwritten.</p>
<p>Logs include the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.TransactionMetric.html"><code>TransactionMetric</code></a> object which is created each time any transaction is run.</p>
<h2 id="log-format-1"><a class="header" href="#log-format-1">Log Format</a></h2>
<p>By default, logs are written in JSON Lines format. For example:</p>
<pre><code class="language-json">{"elapsed":22060,"name":"(Anon) front page","run_time":97,"success":true,"transaction_index":0,"scenario_index":0,"user":0}
{"elapsed":22118,"name":"(Anon) node page","run_time":41,"success":true,"transaction_index":1,"scenario_index":0,"user":5}
{"elapsed":22157,"name":"(Anon) node page","run_time":6,"success":true,"transaction_index":1,"scenario_index":0,"user":0}
{"elapsed":22078,"name":"(Auth) front page","run_time":109,"success":true,"transaction_index":1,"scenario_index":1,"user":6}
{"elapsed":22157,"name":"(Anon) user page","run_time":35,"success":true,"transaction_index":2,"scenario_index":0,"user":4}
</code></pre>
<p>In the first line of the above example, <code>GooseUser</code> thread 0 succesfully ran the <code>(Anon) front page</code> transaction in 97 milliseconds. In the second line <code>GooseUser</code> thread 5 succesfully ran the <code>(Anon) node page</code> transaction in 41 milliseconds.</p>
<p>The <code>--transaction-format</code> option can be used to log in <code>csv</code>, <code>json</code> (default), <code>raw</code> or <code>pretty</code> format. The <code>raw</code> format is Rust's debug output of the entire
<a href="https://docs.rs/goose/*/goose/metrics/struct.TransactionMetric.html"><code>TransactionMetric</code></a> object.</p>
<p>For example, <code>csv</code> output of similar transactions as those logged above would like like:</p>
<pre><code class="language-csv">elapsed,scenario_index,transaction_index,name,run_time,success,user
21936,0,0,"(Anon) front page",83,true,0
21990,1,3,"(Auth) user page",34,true,1
21954,0,0,"(Anon) front page",84,true,5
22009,0,1,"(Anon) node page",34,true,2
21952,0,0,"(Anon) front page",95,true,7
</code></pre>
<h1 id="gaggle-mode-1"><a class="header" href="#gaggle-mode-1">Gaggle Mode</a></h1>
<p>When operating in Gaggle-mode, the <code>--transaction-log</code> option can only be enabled on the Worker processes, configuring Goose to spread out the overhead of writing logs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scneario-log"><a class="header" href="#scneario-log">Scneario Log</a></h1>
<p>Goose can optionally log details about each time a scenario is run during a load test.  To enable, add the <code>--scenario-log &lt;scenario.log&gt;</code> command line option, where <code>&lt;scenario.log&gt;</code> is either a relative or absolute path of the log file to create. Any existing file that may already exist will be overwritten.</p>
<p>Logs include the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.ScenarioMetric.html"><code>ScenarioMetric</code></a> object which is created each time any scenario is run.</p>
<h2 id="log-format-2"><a class="header" href="#log-format-2">Log Format</a></h2>
<p>By default, logs are written in JSON Lines format. For example:</p>
<pre><code class="language-json">{"elapsed":15751,"index":0,"name":"AnonBrowsingUser","run_time":1287,"user":7}
{"elapsed":15756,"index":0,"name":"AnonBrowsingUser","run_time":1308,"user":4}
{"elapsed":15760,"index":0,"name":"AnonBrowsingUser","run_time":1286,"user":9}
{"elapsed":15783,"index":0,"name":"AnonBrowsingUser","run_time":1301,"user":0}
{"elapsed":22802,"index":1,"name":"AuthBrowsingUser","run_time":13056,"user":8}
</code></pre>
<p>In the first line of the above example, <code>GooseUser</code> thread 7 ran the complete <code>AnonBrowsingUser</code> scenario in 1,287 milliseconds. In the fifth line <code>GooseUser</code> thread 8 succesfully ran the <code>AuthBrowsingUser</code> transaction in 13,056 milliseconds.</p>
<p>The <code>--scenario-format</code> option can be used to log in <code>csv</code>, <code>json</code> (default), <code>raw</code> or <code>pretty</code> format. The <code>raw</code> format is Rust's debug output of the entire
<a href="https://docs.rs/goose/*/goose/metrics/struct.ScenarioMetric.html"><code>ScenarioMetric</code></a> object.</p>
<p>For example, <code>csv</code> output of similar transactions as those logged above would like like:</p>
<pre><code class="language-csv">elapsed,scenario_index,transaction_index,name,run_time,success,user
15751,AnonBrowsingUser,0,1287,7
15756,AnonBrowsingUser,0,1308,4
15760,AnonBrowsingUser,0,1286,9
15783,AnonBrowsingUser,0,1301,0
22802,AuthBrowsingUser,1,13056,8
</code></pre>
<h1 id="gaggle-mode-2"><a class="header" href="#gaggle-mode-2">Gaggle Mode</a></h1>
<p>When operating in Gaggle-mode, the <code>--scenario-log</code> option can only be enabled on the Worker processes, configuring Goose to spread out the overhead of writing logs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-log"><a class="header" href="#error-log">Error Log</a></h1>
<p>Goose can optionally log details about all load test errors to a file. To enable, add the <code>--error-log=&lt;error.log&gt;</code> command line option, where <code>&lt;error.log&gt;</code> is either a relative or absolute path of the log file to create. Any existing file that may already exist will be overwritten.</p>
<p>Logs include the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseErrorMetric.html"><code>GooseErrorMetric</code></a> object, created any time a request results in an error.</p>
<h2 id="log-format-3"><a class="header" href="#log-format-3">Log Format</a></h2>
<p>By default, logs are written in JSON Lines format. For example:</p>
<pre><code class="language-json">{"elapsed":9318,"error":"503 Service Unavailable: /","final_url":"http://apache/","name":"(Auth) front page","raw":{"body":"","headers":[],"method":"Get","url":"http://apache/"},"redirected":false,"response_time":6,"status_code":503,"user":1}
{"elapsed":9318,"error":"503 Service Unavailable: /node/8211","final_url":"http://apache/node/8211","name":"(Anon) node page","raw":{"body":"","headers":[],"method":"Get","url":"http://apache/node/8211"},"redirected":false,"response_time":6,"status_code":503,"user":3}
</code></pre>
<p>The <code>--errors-format</code> option can be used to change the log format to <code>csv</code>, <code>json</code> (default), <code>raw</code> or <code>pretty</code> format. The <code>raw</code> format is Rust's debug output of the entire <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseErrorMetric.html"><code>GooseErrorMetric</code></a> object.</p>
<h2 id="gaggle-mode-3"><a class="header" href="#gaggle-mode-3">Gaggle Mode</a></h2>
<p>When operating in Gaggle-mode, the <code>--error-log</code> option can only be enabled on the Worker processes, configuring Goose to spread out the overhead of writing logs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debug-log"><a class="header" href="#debug-log">Debug Log</a></h1>
<p>Goose can optionally and efficiently log arbitrary details, and specifics about requests and responses for debug purposes.</p>
<p>To enable, add the <code>--debug-log &lt;debug.log&gt;</code> command line option, where <code>&lt;debug.log&gt;</code> is either a relative or absolute path of the log file to create. Any existing file that may already exist will be overwritten.</p>
<p>If <code>--debug-log &lt;foo&gt;</code> is not specified at run time, nothing will be logged and there is no measurable overhead in your load test.</p>
<p>To write to the debug log, you must invoke <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.log_debug"><code>log_debug</code></a> from your load test transaction functions. The <code>tag</code> parameter allows you to record any arbitrary string: it can also identify where in the load test the log was generated, and/or why debug is being written, and/or other details such as the contents of a form the load test posts. Other paramters that can be included in the debug log are the complete Request that was made, as well as the Headers and Body of the Response.</p>
<p>(<em>Known limitations in Reqwest prevent all headers from being recorded: <a href="https://github.com/tag1consulting/goose/issues/336">https://github.com/tag1consulting/goose/issues/336</a></em>)</p>
<p>See <a href="https://github.com/tag1consulting/goose/blob/main/examples/drupal_loadtest.rs"><code>examples/drupal_loadtest</code></a> for an example of how you might invoke <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.log_debug"><code>log_debug</code></a> from a load test.</p>
<h2 id="request-failures"><a class="header" href="#request-failures">Request Failures</a></h2>
<p>Calls to <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.set_failure"><code>set_failure</code></a> can be used to tell Goose that a request failed even though the server returned a successful status code, and will automatically invoke <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.log_debug"><code>log_debug</code></a> for you. See <a href="https://github.com/tag1consulting/goose/blob/main/examples/drupal_loadtest.rs"><code>examples/drupal_loadtest</code></a> and <a href="https://github.com/tag1consulting/goose/tree/main/examples/umami"><code>examples/umami</code></a> for an example of how you might use <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.set_failure"><code>set_failure</code></a> to generate useful debug logs.</p>
<h2 id="log-format-4"><a class="header" href="#log-format-4">Log Format</a></h2>
<p>By default, logs are written in JSON Lines format. For example:</p>
<pre><code class="language-json">{"body":"&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;503 Backend fetch failed&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Error 503 Backend fetch failed&lt;/h1&gt;\n    &lt;p&gt;Backend fetch failed&lt;/p&gt;\n    &lt;h3&gt;Guru Meditation:&lt;/h3&gt;\n    &lt;p&gt;XID: 1506620&lt;/p&gt;\n    &lt;hr&gt;\n    &lt;p&gt;Varnish cache server&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n","header":"{\"date\": \"Mon, 19 Jul 2021 09:21:58 GMT\", \"server\": \"Varnish\", \"content-type\": \"text/html; charset=utf-8\", \"retry-after\": \"5\", \"x-varnish\": \"1506619\", \"age\": \"0\", \"via\": \"1.1 varnish (Varnish/6.1)\", \"x-varnish-cache\": \"MISS\", \"x-varnish-cookie\": \"SESSd7e04cba6a8ba148c966860632ef3636=Z50aRHuIzSE5a54pOi-dK_wbxYMhsMwrG0s2WM2TS20\", \"content-length\": \"284\", \"connection\": \"keep-alive\"}","request":{"coordinated_omission_elapsed":0,"elapsed":9162,"error":"503 Service Unavailable: /node/1439","final_url":"http://apache/node/1439","name":"(Auth) comment form","raw":{"body":"","headers":[],"method":"Get","url":"http://apache/node/1439"},"redirected":false,"response_time":5,"status_code":503,"success":false,"update":false,"user":1,"user_cadence":0},"tag":"post_comment: no form_build_id found on node/1439"}
</code></pre>
<p>The <code>--debug-format</code> option can be used to log in <code>csv</code>, <code>json</code> (default), <code>raw</code> or <code>pretty</code> format. The <code>raw</code> format is Rust's debug output of the entire <a href="https://docs.rs/goose/*/goose/goose/struct.GooseDebug.html"><code>GooseDebug</code></a> object.</p>
<h2 id="gaggle-mode-4"><a class="header" href="#gaggle-mode-4">Gaggle Mode</a></h2>
<p>When operating in Gaggle-mode, the <code>--debug-log</code> option can only be enabled on the Worker processes, configuring Goose to spread out the overhead of writing logs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="controlling-a-running-goose-load-test"><a class="header" href="#controlling-a-running-goose-load-test">Controlling A Running Goose Load Test</a></h1>
<p>By default, Goose will launch a telnet Controller thread that listens on <code>0.0.0.0:5116</code>, and a WebSocket Controller thread that listens on <code>0.0.0.0:5117</code>. The running Goose load test can be controlled through these Controllers. Goose can optionally be started with the <code>--no-autostart</code> run time option to prevent the load test from automatically starting, requiring instead that it be started with a Controller command. When Goose is started this way, a host is not required and can instead be configured via the Controller.</p>
<p>NOTE: The controller currently is not Gaggle-aware, and only functions correctly when running Goose as a single process in standalone mode.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="telnet-controller"><a class="header" href="#telnet-controller">Telnet Controller</a></h1>
<p>The host and port that the telnet Controller listens on can be configured at start time with <code>--telnet-host</code> and <code>--telnet-port</code>. The telnet Controller can be completely disabled with the <code>--no-telnet</code> command line option. The defaults can be changed with <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.TelnetHost"><code>GooseDefault::TelnetHost</code></a>,<a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.TelnetPort"><code>GooseDefault::TelnetPort</code></a>, and <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.NoTelnet"><code>GooseDefault::NoTelnet</code></a>.</p>
<h2 id="controller-commands"><a class="header" href="#controller-commands">Controller Commands</a></h2>
<p>To learn about all available commands, telnet into the Controller thread and enter <code>help</code> (or <code>?</code>). For example:</p>
<pre><code class="language-bash">% telnet localhost 5116
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
goose&gt; ?
goose 0.17.2 controller commands:
help               this help
exit               exit controller

start              start an idle load test
stop               stop a running load test and return to idle state
shutdown           shutdown load test and exit controller

host HOST          set host to load test, (ie https://web.site/)
hatchrate FLOAT    set per-second rate users hatch
startup-time TIME  set total time to take starting users
users INT          set number of simulated users
runtime TIME       set how long to run test, (ie 1h30m5s)
test-plan PLAN     define or replace test-plan, (ie 10,5m;10,1h;0,30s)

config             display load test configuration
config-json        display load test configuration in json format
metrics            display metrics for current load test
metrics-json       display metrics for current load test in json format
goose&gt; q
goodbye!
goose&gt; Connection closed by foreign host.
</code></pre>
<h2 id="example-1"><a class="header" href="#example-1">Example</a></h2>
<p>One possible use-case for the controller is to dynamically reconfigure the number of users being simulated by the load test. In the following example, the load test was launched with the following parameters:</p>
<pre><code class="language-bash">% cargo run --release --example umami -- --no-autostart --host https://umami.ddev.site/ --hatch-rate 50 --report-file report.html
</code></pre>
<p>Then the telnet controller is invoked as follows:</p>
<pre><code class="language-bash">% telnet loadtest 5116
Trying loadtest...
Connected to loadtest.
Escape character is '^]'.
goose&gt; start 
load test started
goose&gt; users 20
users configured
goose&gt; users 40
users configured
goose&gt; users 80
users configured
goose&gt; users 40 
users configured
goose&gt; users 20
users configured
goose&gt; users 160
users configured
goose&gt; users 20
users configured
goose&gt; hatch_rate 5
hatch_rate configured
goose&gt; users 80
users configured
goose&gt; users 20
users configured
goose&gt; shutdown
load test shut down
goose&gt; Connection closed by foreign host.
</code></pre>
<p>Initially the load test is configured with a hatch rate of 50, so goose increases and decreases the user count by 50 user threads per second. Later we reconfigure the hatch rate to 5, slowing down the rate that goose alters the number of user threads. The result is more clearly illustrated in the following graph generated at the end of the above example load test:</p>
<p><img src="controller/controller-users.png" alt="Controller dynamic users and hatch rate" /></p>
<p>The above commands are also summarized in the metrics overview:</p>
<pre><code class="language-ignore"> === OVERVIEW ===
 ------------------------------------------------------------------------------
 Action       Started               Stopped             Elapsed    Users
 ------------------------------------------------------------------------------
 Increasing:  2022-05-05 07:09:34 - 2022-05-05 07:09:34 (00:00:00, 0 -&gt; 10)
 Maintaining: 2022-05-05 07:09:34 - 2022-05-05 07:09:40 (00:00:06, 10)
 Increasing:  2022-05-05 07:09:40 - 2022-05-05 07:09:40 (00:00:00, 10 -&gt; 20)
 Maintaining: 2022-05-05 07:09:40 - 2022-05-05 07:09:46 (00:00:06, 20)
 Increasing:  2022-05-05 07:09:46 - 2022-05-05 07:09:47 (00:00:01, 20 -&gt; 40)
 Maintaining: 2022-05-05 07:09:47 - 2022-05-05 07:09:50 (00:00:03, 40)
 Increasing:  2022-05-05 07:09:50 - 2022-05-05 07:09:51 (00:00:01, 40 -&gt; 80)
 Maintaining: 2022-05-05 07:09:51 - 2022-05-05 07:09:59 (00:00:08, 80)
 Decreasing:  2022-05-05 07:09:59 - 2022-05-05 07:10:00 (00:00:01, 40 &lt;- 80)
 Maintaining: 2022-05-05 07:10:00 - 2022-05-05 07:10:05 (00:00:05, 40)
 Decreasing:  2022-05-05 07:10:05 - 2022-05-05 07:10:06 (00:00:01, 20 &lt;- 40)
 Maintaining: 2022-05-05 07:10:06 - 2022-05-05 07:10:12 (00:00:06, 20)
 Increasing:  2022-05-05 07:10:12 - 2022-05-05 07:10:15 (00:00:03, 20 -&gt; 160)
 Maintaining: 2022-05-05 07:10:15 - 2022-05-05 07:10:19 (00:00:04, 160)
 Decreasing:  2022-05-05 07:10:19 - 2022-05-05 07:10:22 (00:00:03, 20 &lt;- 160)
 Maintaining: 2022-05-05 07:10:22 - 2022-05-05 07:10:35 (00:00:13, 20)
 Increasing:  2022-05-05 07:10:35 - 2022-05-05 07:10:50 (00:00:15, 20 -&gt; 80)
 Maintaining: 2022-05-05 07:10:50 - 2022-05-05 07:10:54 (00:00:04, 80)
 Decreasing:  2022-05-05 07:10:54 - 2022-05-05 07:11:07 (00:00:13, 20 &lt;- 80)
 Maintaining: 2022-05-05 07:11:07 - 2022-05-05 07:11:13 (00:00:06, 20)
 Canceling:   2022-05-05 07:11:13 - 2022-05-05 07:11:13 (00:00:00, 0 &lt;- 20)

 Target host: https://umami.ddev.site/
 goose v0.18.1
 ------------------------------------------------------------------------------
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-controller"><a class="header" href="#websocket-controller">WebSocket Controller</a></h1>
<p>The host and port that the WebSocket Controller listens on can be configured at start time with <code>--websocket-host</code> and <code>--websocket-port</code>. The WebSocket Controller can be completely disabled with the <code>--no-websocket</code> command line option. The defaults can be changed with <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.WebSocketHost"><code>GooseDefault::WebSocketHost</code></a>,<a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.WebSocketPort"><code>GooseDefault::WebSocketPort</code></a>, and <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html#variant.NoWebSocket"><code>GooseDefault::NoWebSocket</code></a>.</p>
<h2 id="details"><a class="header" href="#details">Details</a></h2>
<p>The WebSocket Controller supports the same commands listed in the <a href="controller/telnet.html">telnet controller</a>. Requests and Responses are in JSON format.</p>
<p>Requests must be made in the following format:</p>
<pre><code class="language-json">{"request":String}
</code></pre>
<p>For example, a client should send the follow json to request the current load test metrics:</p>
<pre><code class="language-json">{"request":"metrics"}
</code></pre>
<p>Responses will always be in the following format:</p>
<pre><code class="language-json">{"response":String,"success":Boolean}
</code></pre>
<p>For example:</p>
<pre><code class="language-bash">% websocat ws://127.0.0.1:5117
foo
{"response":"invalid json, see Goose book https://book.goose.rs/controller/websocket.html","success":false}
{"request":"foo"}
{"response":"unrecognized command, see Goose book https://book.goose.rs/controller/websocket.html","success":false}
{"request":"config"}
{"response":"{\"help\":false,\"version\":false,\"list\":false,\"host\":\"\",\"users\":10,\"hatch_rate\":null,\"startup_time\":\"0\",\"run_time\":\"0\",\"goose_log\":\"\",\"log_level\":0,\"quiet\":0,\"verbose\":0,\"running_metrics\":null,\"no_reset_metrics\":false,\"no_metrics\":false,\"no_transaction_metrics\":false,\"no_print_metrics\":false,\"no_error_summary\":false,\"report_file\":\"\",\"no_granular_report\":false,\"request_log\":\"\",\"request_format\":\"Json\",\"request_body\":false,\"transaction_log\":\"\",\"transaction_format\":\"Json\",\"error_log\":\"\",\"error_format\":\"Json\",\"debug_log\":\"\",\"debug_format\":\"Json\",\"no_debug_body\":false,\"no_status_codes\":false,\"test_plan\":null,\"no_telnet\":false,\"telnet_host\":\"0.0.0.0\",\"telnet_port\":5116,\"no_websocket\":false,\"websocket_host\":\"0.0.0.0\",\"websocket_port\":5117,\"no_autostart\":true,\"no_gzip\":false,\"timeout\":null,\"co_mitigation\":\"Disabled\",\"throttle_requests\":0,\"sticky_follow\":false,\"manager\":false,\"expect_workers\":null,\"no_hash_check\":false,\"manager_bind_host\":\"\",\"manager_bind_port\":0,\"worker\":false,\"manager_host\":\"\",\"manager_port\":0}","success":true}
{"request":"stop"}
{"response":"load test not running, failed to stop","success":false}
{"request":"shutdown"}
{"response":"load test shut down","success":true}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gaggle-distributed-load-test"><a class="header" href="#gaggle-distributed-load-test">Gaggle: Distributed Load Test</a></h1>
<p><strong>NOTE: Gaggle support was temporarily removed as of Goose 0.17.0 (see https://github.com/tag1consulting/goose/pull/529). Use Goose 0.16.4 if you need the functionality described in this section.</strong></p>
<p>Goose also supports distributed load testing. A Gaggle is one Goose process running in <a href="gaggle/manager.html">Manager mode</a>, and 1 or more Goose processes running in <a href="gaggle/worker.html">Worker mode</a>. The Manager coordinates starting and stopping the Workers, and collects aggregated metrics. Gaggle support is a <a href="gaggle/technical.html#compile-time-feature">cargo feature that must be enabled at compile-time</a>. To launch a Gaggle, you must copy your load test application to all servers from which you wish to generate load.</p>
<p>It is strongly recommended that the same load test application be copied to all servers involved in a Gaggle. By default, Goose will verify that the load test is identical by comparing a hash of all load test rules. Telling it to skip this check can cause the load test to panic (for example, if a Worker defines a different number of transactions or scenarios than the Manager).</p>
<h2 id="load-testing-at-scale"><a class="header" href="#load-testing-at-scale">Load Testing At Scale</a></h2>
<p>Experimenting with running Goose load tests from AWS, Goose has proven to make fantastic use of all available system resources, so that it is only generally limited by network speeds. A smaller server instance was able to simulate 2,000 users generating over 6,500 requests per second and saturating a 2.6 Gbps uplink. As more uplink speed was added, Goose was able to scale linearly -- by distributing the test across two servers with faster uplinks, it comfortably simulated 12,000 active users generating over 41,000 requests per second and saturating 16 Gbps.</p>
<p>Generating this much traffic in and of itself is not fundamentally difficult, but with Goose each request is fully analyzed and validated. It not only confirms the response code for each response the server returns, but also inspects the returned HTML to confirm it contains all expected elements. Links to static elements such as images and CSS are extracted from each response and also loaded, with each simulated user behaving similar to how a real user would. Goose excels at providing consistent and repeatable load testing.</p>
<p>For full details and graphs, refer to the blog <a href="https://www.tag1consulting.com/blog/goose-clouds-load-testing-scale">A Goose In The Clouds: Load Testing At Scale</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gaggle-manager"><a class="header" href="#gaggle-manager">Gaggle Manager</a></h1>
<p><strong>NOTE: Gaggle support was temporarily removed as of Goose 0.17.0 (see https://github.com/tag1consulting/goose/pull/529). Use Goose 0.16.4 if you need the functionality described in this section.</strong></p>
<p>To launch a Gaggle, you first must start a Goose application in Manager mode. All configuration happens in the Manager. To start, add the <code>--manager</code> flag and <code>--expect-workers</code> option, the latter necessary to tell the Manager process how many Worker processes it will be coordinating.</p>
<h2 id="example-2"><a class="header" href="#example-2">Example</a></h2>
<p><em>Configure a Goose Manager to listen on all interfaces on the default port (0.0.0.0:5115), waiting for 2 Goose Worker processes.</em></p>
<pre><code class="language-bash">cargo run --features gaggle --example simple -- --manager --expect-workers 2 --host http://local.dev/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gaggle-worker"><a class="header" href="#gaggle-worker">Gaggle Worker</a></h1>
<p>At this time, a Goose process can be either a Manager or a Worker, not both. Therefor, it usually makes sense to launch your first Worker on the same server that the Manager is running on. If not otherwise configured, a Goose Worker will try to connect to the Manager on the localhost.</p>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>Starting a Worker that connects to a Manager running on the same server:</p>
<pre><code class="language-bash">cargo run --features gaggle --example simple -- --worker -v
</code></pre>
<p>In our <a href="gaggle/manager.html">earlier example</a>, we expected 2 Workers. The second Goose process should be started on a different server. This will require telling it the host where the Goose Manager process is running. For example:</p>
<pre><code class="language-bash">cargo run --example simple -- --worker --manager-host 192.168.1.55 -v
</code></pre>
<p>Once all expected Workers are running, the distributed load test will automatically start. We set the <code>-v</code> flag so Goose provides verbose output indicating what is happening. In our example, the load test will run until it is canceled. You can cancel the Manager or either of the Worker processes, and the test will stop on all servers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="run-time-flags"><a class="header" href="#run-time-flags">Run-time Flags</a></h1>
<p><strong>NOTE: Gaggle support was temporarily removed as of Goose 0.17.0 (see https://github.com/tag1consulting/goose/pull/529). Use Goose 0.16.4 if you need the functionality described in this section.</strong></p>
<ul>
<li><code>--manager</code>: starts a Goose process in Manager mode. There currently can only be one Manager per Gaggle.</li>
<li><code>--worker</code>: starts a Goose process in Worker mode. How many Workers are in a given Gaggle is defined by the <code>--expect-workers</code> option, documented below.</li>
<li><code>--no-hash-check</code>: tells Goose to ignore if the load test application doesn't match between Worker(s) and the Manager. This is not recommended, and can cause the application to panic.</li>
</ul>
<p>The <code>--no-metrics</code>, <code>--no-reset-metrics</code>, <code>--no-status-codes</code>, and <code>--no-hash-check</code> flags must be set on the Manager. Workers inherit these flags from the Manager</p>
<h1 id="run-time-options-1"><a class="header" href="#run-time-options-1">Run-time Options</a></h1>
<ul>
<li><code>--manager-bind-host &lt;manager-bind-host&gt;</code>: configures the host that the Manager listens on. By default Goose will listen on all interfaces, or <code>0.0.0.0</code>.</li>
<li><code>--manager-bind-port &lt;manager-bind-port&gt;</code>: configures the port that the Manager listens on. By default Goose will listen on port <code>5115</code>.</li>
<li><code>--manager-host &lt;manager-host&gt;</code>: configures the host that the Worker will talk to the Manager on. By default, a Goose Worker will connect to the localhost, or <code>127.0.0.1</code>. In a distributed load test, this must be set to the IP of the Goose Manager.</li>
<li><code>--manager-port &lt;manager-port&gt;</code>: configures the port that a Worker will talk to the Manager on. By default, a Goose Worker will connect to port <code>5115</code>.</li>
</ul>
<p>The <code>--users</code>, <code>--startup-time</code>, <code>--hatch-rate</code>, <code>--host</code>, and <code>--run-time</code> options must be set on the Manager. Workers inherit these options from the Manager.</p>
<p>The <code>--throttle-requests</code> option must be configured on each Worker, and can be set to a different value on each Worker if desired.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gaggle-technical-details"><a class="header" href="#gaggle-technical-details">Gaggle Technical Details</a></h1>
<p><strong>NOTE: Gaggle support was temporarily removed as of Goose 0.17.0 (see https://github.com/tag1consulting/goose/pull/529). Use Goose 0.16.4 if you need the functionality described in this section.</strong></p>
<p>Goose uses <a href="https://docs.rs/nng/"><code>nng</code></a> to send network messages between the Manager and all Workers. <a href="https://docs.serde.rs/serde/index.html">Serde</a> and <a href="https://github.com/pyfisch/cbor">Serde CBOR</a> are used to serialize messages into <a href="https://tools.ietf.org/html/rfc7049">Concise Binary Object Representation</a>.</p>
<p>Workers initiate all network connections, and push metrics to the Manager process.</p>
<h2 id="compile-time-feature"><a class="header" href="#compile-time-feature">Compile-time Feature</a></h2>
<p>Gaggle support is a compile-time Cargo feature that must be enabled. Goose uses the <a href="https://docs.rs/nng/"><code>nng</code></a> library to manage network connections, and compiling <code>nng</code> requires that <code>cmake</code> be available.</p>
<p>The <code>gaggle</code> feature can be enabled from the command line by adding <code>--features gaggle</code> to your cargo command.</p>
<p>When writing load test applications, you can default to compiling in the Gaggle feature in the <code>dependencies</code> section of your <code>Cargo.toml</code>, for example:</p>
<pre><code class="language-toml">[dependencies]
goose = { version = "^0.16", features = ["gaggle"] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-coordinated-omission"><a class="header" href="#what-is-coordinated-omission">What is Coordinated Omission?</a></h1>
<p>Coordinated Omission is a measurement problem that accidentally hides how many people are actually affected by server slowdowns during load testing.</p>
<h2 id="the-race-timer-problem"><a class="header" href="#the-race-timer-problem">The Race Timer Problem</a></h2>
<p>Imagine you're timing runners in a race:</p>
<ul>
<li>You're supposed to time a runner every 10 seconds</li>
<li>But sometimes a runner gets stuck in mud for 30 seconds</li>
<li>Your timer waits for that stuck runner before timing the next one</li>
<li>So instead of timing 6 runners per minute, you only time 2</li>
</ul>
<p><strong>Result</strong>: Your data says "average time: 15 seconds" when reality is most runners take 10 seconds, but some get stuck for 30+ seconds!</p>
<p><strong>The issue</strong>: You're only measuring the runners who actually finish, missing all the runners who would have started during the delay.</p>
<h2 id="how-this-affects-load-testing"><a class="header" href="#how-this-affects-load-testing">How This Affects Load Testing</a></h2>
<h3 id="the-problem-missing-the-full-impact"><a class="header" href="#the-problem-missing-the-full-impact">The Problem: Missing the Full Impact</a></h3>
<pre><code>Timeline of Goose User Thread:
Time 0s:  Send request ✅ (1 second response)
Time 1s:  Send request ✅ (1 second response)  
Time 2s:  Send request ✅ (1 second response)
Time 3s:  Send request... ⏳ (server freezes!)
Time 33s: Finally get response ❌ (30 seconds late!)
Time 34s: Send request ✅ (1 second response)
</code></pre>
<p><strong>What traditional load testing records:</strong></p>
<ul>
<li>4 requests total</li>
<li>Average response time: 8.25 seconds</li>
<li>"Looks like mostly good performance"</li>
</ul>
<p><strong>What really happened:</strong>
During that 30-second freeze, <strong>30 more requests should have been made</strong> but couldn't because the thread was stuck waiting. So instead of 4 requests, there should have been 34 requests affected by the server problem.</p>
<h2 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h2>
<p>When your server freezes for 30 seconds, <strong>EVERY user trying to access it during those 30 seconds is affected</strong>. Traditional load testing makes it look like only 1 user had problems, when really 30+ users experienced the issue.</p>
<p>This leads to dangerously optimistic reports:</p>
<ul>
<li>❌ "99% of requests were fast" (hiding the freeze)</li>
<li>✅ "Server had a 30-second outage affecting 87% of traffic" (reality)</li>
</ul>
<h2 id="how-goose-fixes-this"><a class="header" href="#how-goose-fixes-this">How Goose Fixes This</a></h2>
<h3 id="1-detects-missing-requests"><a class="header" href="#1-detects-missing-requests">1. Detects Missing Requests</a></h3>
<p>When Goose sees an abnormally long 30-second response, it recognizes: "During those 30 seconds, I should have made 30 requests but couldn't."</p>
<h3 id="2-synthetic-request-injection"><a class="header" href="#2-synthetic-request-injection">2. Synthetic Request Injection</a></h3>
<p>Goose adds "synthetic requests" to represent the requests that <strong>would have been made</strong> if the server hadn't frozen, giving you a complete picture of impact.</p>
<h3 id="3-clear-reporting"><a class="header" href="#3-clear-reporting">3. Clear Reporting</a></h3>
<pre><code>=== COORDINATED OMISSION METRICS ===
Total CO Events: 1
Actual requests: 4  
Synthetic requests: 29 (87.9%)
Severity: 1 Critical event detected
</code></pre>
<p>This tells you: "87.9% of your expected traffic was affected by server problems!"</p>
<h2 id="visual-comparison"><a class="header" href="#visual-comparison">Visual Comparison</a></h2>
<p><strong>Before (Traditional Load Testing):</strong></p>
<pre><code>Timeline: |--1s--|--1s--|--------30s--------|--1s--|
Requests:    ✅     ✅          ❌           ✅
Result: "4 requests, looks mostly fine" ❌ MISLEADING
</code></pre>
<p><strong>After (Goose with CO Mitigation):</strong></p>
<pre><code>Timeline: |--1s--|--1s--|--------30s--------|--1s--|  
Real:        ✅     ✅          ❌           ✅
Synthetic:              ❌❌❌❌❌...❌❌❌    (29 more)
Result: "34 total requests, 30-second freeze affected 87.9% of traffic" ✅ ACCURATE
</code></pre>
<h2 id="the-key-insight"><a class="header" href="#the-key-insight">The Key Insight</a></h2>
<p>Server problems don't just affect one request, they affect ALL the requests that should have happened during the problem period. Goose now captures this reality, giving you honest data about your system's behavior under load.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mitigation-strategies"><a class="header" href="#mitigation-strategies">Mitigation Strategies</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Goose provides comprehensive protection against coordinated omission through its metrics collection architecture. By recording all request timings and maintaining detailed percentile distributions, Goose ensures that slow responses are properly represented in your load test results.</p>
<h2 id="built-in-protection"><a class="header" href="#built-in-protection">Built-in Protection</a></h2>
<h3 id="complete-timing-capture"><a class="header" href="#complete-timing-capture">Complete Timing Capture</a></h3>
<p>Goose's fundamental design prevents coordinated omission by:</p>
<ol>
<li><strong>Recording Every Request</strong>: All request start and end times are captured, regardless of duration</li>
<li><strong>No Sampling</strong>: Unlike some tools, Goose doesn't sample metrics - every data point is recorded</li>
<li><strong>Async Architecture</strong>: Non-blocking request handling ensures slow responses don't prevent new requests</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: How Goose captures all timings
async fn user_function(user: &amp;mut GooseUser) -&gt; TransactionResult {
    // Start time is automatically recorded
    let _goose = user.get("/slow-endpoint").await?;
    // End time is recorded regardless of response duration
    // Even if this takes 30 seconds, it's properly tracked
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="accurate-percentile-calculation"><a class="header" href="#accurate-percentile-calculation">Accurate Percentile Calculation</a></h3>
<p>Goose uses the <a href="https://docs.rs/hdrhistogram/">hdrhistogram</a> crate to maintain high-resolution timing distributions:</p>
<ul>
<li><strong>Microsecond precision</strong>: Timings are recorded with microsecond accuracy</li>
<li><strong>Dynamic range</strong>: Handles response times from microseconds to minutes</li>
<li><strong>Memory efficient</strong>: Compressed histogram format maintains accuracy without excessive memory use</li>
</ul>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="request-timeout-settings"><a class="header" href="#request-timeout-settings">Request Timeout Settings</a></h3>
<p>Configure appropriate timeouts to ensure all responses are captured:</p>
<pre><code class="language-bash"># Set a 60-second request timeout (default is 60)
cargo run --release -- --request-timeout 60

# For extremely slow endpoints, increase further
cargo run --release -- --request-timeout 300
</code></pre>
<h3 id="coordinated-omission-mitigation-mode"><a class="header" href="#coordinated-omission-mitigation-mode">Coordinated Omission Mitigation Mode</a></h3>
<p>Enable explicit coordinated omission mitigation for traditional closed-loop testing:</p>
<pre><code class="language-bash"># Enable CO mitigation mode
cargo run --release -- --co-mitigation enabled

# With custom parameters
cargo run --release -- --co-mitigation enabled \
    --co-mitigation-expected-interval 100 \
    --co-mitigation-accuracy 2
</code></pre>
<p>When enabled, this mode:</p>
<ul>
<li>Tracks expected vs actual request intervals</li>
<li>Adjusts metrics to account for delayed requests</li>
<li>Provides warnings when significant delays are detected</li>
</ul>
<h2 id="understanding-your-results"><a class="header" href="#understanding-your-results">Understanding Your Results</a></h2>
<p>Goose provides two sets of metrics:</p>
<ul>
<li><strong>Raw Metrics</strong>: Actual measurements from completed requests</li>
<li><strong>CO-Adjusted Metrics</strong>: Include synthetic data points for requests that should have been made</li>
</ul>
<p>Significant differences between these metrics indicate CO events occurred during your test.</p>
<h2 id="choosing-your-mitigation-strategy"><a class="header" href="#choosing-your-mitigation-strategy">Choosing Your Mitigation Strategy</a></h2>
<p>Goose offers three CO mitigation modes via the <code>--co-mitigation</code> flag:</p>
<div class="table-wrapper"><table><thead><tr><th>Mode</th><th>Use Case</th><th>Behavior</th></tr></thead><tbody>
<tr><td><code>disabled</code></td><td>Custom analysis, external CO handling</td><td>No adjustment, raw data only</td></tr>
<tr><td><code>average</code> (default)</td><td>General performance testing</td><td>Uses average response time as baseline</td></tr>
<tr><td><code>minimum</code></td><td>Strict SLA compliance, microservices</td><td>Uses minimum response time as baseline</td></tr>
</tbody></table>
</div>
<h3 id="when-to-use-each-mode"><a class="header" href="#when-to-use-each-mode">When to Use Each Mode</a></h3>
<p><strong>Use <code>minimum</code> when:</strong></p>
<ul>
<li>Testing microservices with strict timing requirements</li>
<li>Validating SLA compliance</li>
<li>You need to detect ANY performance degradation</li>
<li>Testing in controlled environments</li>
</ul>
<p><strong>Use <code>average</code> when:</strong></p>
<ul>
<li>Simulating realistic user behavior</li>
<li>Testing public-facing websites</li>
<li>You want balanced synthetic data generation</li>
<li>General performance regression testing</li>
</ul>
<p><strong>Use <code>disabled</code> when:</strong></p>
<ul>
<li>Implementing custom CO mitigation</li>
<li>Performing specialized statistical analysis</li>
<li>You need only actual measurements</li>
<li>Comparing with other tools' raw output</li>
</ul>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="1-use-realistic-user-counts"><a class="header" href="#1-use-realistic-user-counts">1. Use Realistic User Counts</a></h3>
<p>Avoid overwhelming your system with too few users:</p>
<pre><code class="language-bash"># Better: More users with think time
cargo run --release -- --users 1000 --hatch-rate 10

# Worse: Few users hammering the system
cargo run --release -- --users 10 --hatch-rate 10
</code></pre>
<h3 id="2-monitor-response-time-distributions"><a class="header" href="#2-monitor-response-time-distributions">2. Monitor Response Time Distributions</a></h3>
<p>Always review the full distribution, not just averages:</p>
<pre><code class="language-text">Response Time Percentiles:
50%: 45ms      # Median looks good
95%: 127ms     # 95th percentile reasonable
99%: 894ms     # 99th shows degradation
99.9%: 5,234ms # Long tail reveals issues
</code></pre>
<h3 id="3-set-appropriate-timeouts"><a class="header" href="#3-set-appropriate-timeouts">3. Set Appropriate Timeouts</a></h3>
<p>Balance between capturing slow responses and test duration:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use goose::prelude::*;

// Configure per-request timeouts
let _goose = user.get("/endpoint")
    .set_timeout(Duration::from_secs(30))
    .await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="4-use-test-plans-for-controlled-load"><a class="header" href="#4-use-test-plans-for-controlled-load">4. Use Test Plans for Controlled Load</a></h3>
<p><a href="coordinated-omission/../getting-started/test-plan.html">Test plans</a> help maintain consistent request rates:</p>
<pre><code class="language-toml">[testplan]
# Gradual ramp-up prevents overwhelming the system
"0s" = "0"
"30s" = "100"
"1m" = "100"
"2m30s" = "200"
"5m" = "200"
"6m" = "0"
</code></pre>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<p>When using <code>average</code> mode (default when CO mitigation is enabled), Goose will trigger Coordinated Omission Mitigation if the time to loop through a <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> takes more than twice as long as the average time of all previous loops. In this case, on the next loop through the <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> when tracking the actual metrics for each subsequent request in all <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> it will also add in statistically generated "requests" with a <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html#structfield.response_time"><code>response_time</code></a> starting at the unexpectedly long request time, then again with that <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html#structfield.response_time"><code>response_time</code></a> minus the normal "cadence", continuing to generate a metric then subtract the normal "cadence" until arriving at the expected <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html#structfield.response_time"><code>response_time</code></a>. In this way, Goose is able to estimate the actual effect of a slowdown.</p>
<p>When Goose detects an abnormally slow request (one in which the individual request takes longer than the normal <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html#structfield.user_cadence"><code>user_cadence</code></a>), it will generate an INFO level message (which will be visible on the command line (unless <code>--no-print-metrics</code> is enabled), and written to the log if started with the <code>-g</code> run time flag and <code>--goose-log</code> is configured).</p>
<h2 id="verification-techniques"><a class="header" href="#verification-techniques">Verification Techniques</a></h2>
<h3 id="1-compare-with-expected-throughput"><a class="header" href="#1-compare-with-expected-throughput">1. Compare with Expected Throughput</a></h3>
<p>Calculate theoretical vs actual request rates:</p>
<pre><code class="language-python"># Expected requests per second
expected_rps = users * (1000 / avg_think_time_ms)

# Compare with actual from Goose metrics
actual_rps = total_requests / test_duration_seconds

# Large discrepancies indicate CO issues
co_factor = expected_rps / actual_rps
</code></pre>
<h3 id="2-analyze-response-time-variance"><a class="header" href="#2-analyze-response-time-variance">2. Analyze Response Time Variance</a></h3>
<p>High variance often indicates coordinated omission:</p>
<pre><code class="language-bash"># Look for these warning signs in metrics:
# - Standard deviation &gt; mean response time
# - 99th percentile &gt; 10x median
# - Maximum response time orders of magnitude higher
</code></pre>
<h3 id="3-monitor-active-transaction-counts"><a class="header" href="#3-monitor-active-transaction-counts">3. Monitor Active Transaction Counts</a></h3>
<p>Track concurrent in-flight requests:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use GooseMetrics to monitor active transactions
// Sustained high counts indicate queueing/delays
<span class="boring">}</span></code></pre></pre>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<p>An example of a request triggering Coordinate Omission mitigation:</p>
<pre><code class="language-bash">13:10:30 [INFO] 11.401s into goose attack: "GET http://apache/node/1557" [200] took abnormally long (1814 ms), transaction name: "(Anon) node page"
13:10:30 [INFO] 11.450s into goose attack: "GET http://apache/node/5016" [200] took abnormally long (1769 ms), transaction name: "(Anon) node page"
</code></pre>
<p>If the <code>--request-log</code> is enabled, you can get more details, in this case by looking for elapsed times matching the above messages, specifically 1,814 and 1,769 respectively:</p>
<pre><code class="language-json">{"coordinated_omission_elapsed":0,"elapsed":11401,"error":"","final_url":"http://apache/node/1557","method":"Get","name":"(Anon) node page","redirected":false,"response_time":1814,"status_code":200,"success":true,"update":false,"url":"http://apache/node/1557","user":2,"user_cadence":1727}
{"coordinated_omission_elapsed":0,"elapsed":11450,"error":"","final_url":"http://apache/node/5016","method":"Get","name":"(Anon) node page","redirected":false,"response_time":1769,"status_code":200,"success":true,"update":false,"url":"http://apache/node/5016","user":0,"user_cadence":1422}
</code></pre>
<p>In the requests file, you can see that two different user threads triggered Coordinated Omission Mitigation, specifically threads 2 and 0. Both <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> threads were loading the same <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> as due to transaction weighting this is the transaction loaded the most frequently. Both <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> threads loop through all <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> in a similar amount of time: thread 2 takes on average 1.727 seconds, thread 0 takes on average 1.422 seconds.</p>
<p>Also if the <code>--request-log</code> is enabled, requests back-filled by Coordinated Omission Mitigation show up in the generated log file, even though they were not actually sent to the server. Normal requests not generated by Coordinated Omission Mitigation have a <a href="https://docs.rs/goose/*/goose/metrics/struct.GooseRequestMetric.html#structfield.coordinated_omission_elapsed"><code>coordinated_omission_elapsed</code></a> of 0.</p>
<h2 id="advanced-techniques"><a class="header" href="#advanced-techniques">Advanced Techniques</a></h2>
<h3 id="custom-metrics-collection"><a class="header" href="#custom-metrics-collection">Custom Metrics Collection</a></h3>
<p>Implement additional CO detection:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use goose::prelude::*;
use std::time::Instant;

async fn monitored_request(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let intended_start = Instant::now();
    
    // Your actual request
    let result = user.get("/endpoint").await?;
    
    let actual_start = result.request.start_time;
    let schedule_delay = actual_start.duration_since(intended_start);
    
    // Log if request was significantly delayed
    if schedule_delay.as_millis() &gt; 100 {
        user.log_debug(&amp;format!(
            "Request delayed by {}ms", 
            schedule_delay.as_millis()
        ))?;
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="real-time-monitoring"><a class="header" href="#real-time-monitoring">Real-time Monitoring</a></h3>
<p>Use Goose's controllers for live detection:</p>
<pre><code class="language-bash"># Enable real-time metrics via WebSocket
cargo run --release -- --websocket-host 0.0.0.0 --websocket-port 5117

# Monitor for:
# - Sudden drops in request rate
# - Spikes in response times
# - Increasing queue depths
</code></pre>
<h2 id="statistical-analysis-note"><a class="header" href="#statistical-analysis-note">Statistical Analysis Note</a></h2>
<p>While Goose provides comprehensive data for analysis, determining statistical significance of performance changes requires additional tools and expertise. Goose produces the raw data you need, but interpretation remains your responsibility.</p>
<p>For detailed analysis, consider:</p>
<ul>
<li>Kolmogorov-Smirnov or Anderson-Darling tests for distribution comparison</li>
<li>Note that CO-adjusted data is derived from raw data (not statistically independent)</li>
<li>Export data via <code>--request-log</code> for external analysis</li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>Goose's architecture inherently protects against coordinated omission through:</p>
<ol>
<li><strong>Comprehensive data collection</strong> - Every request is tracked</li>
<li><strong>Accurate percentile calculations</strong> - Full distributions preserved</li>
<li><strong>Flexible configuration</strong> - Timeouts and modes for various scenarios</li>
<li><strong>Real-time visibility</strong> - Monitor and detect issues during tests</li>
</ol>
<p>By following these practices and utilizing Goose's built-in protections, you can ensure your load test results accurately reflect real-world system behavior under load.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metrics-1"><a class="header" href="#metrics-1">Metrics</a></h1>
<p>When Coordinated Omission Mitigation kicks in, Goose tracks both the "raw" metrics and the "adjusted" metrics. It shows both together when displaying metrics, first the "raw" (actually seen) metrics, followed by the "adjusted" metrics. As the minimum response time is never changed by Coordinated Omission Mitigation, this column is replacd with the "standard deviation" between the average "raw" response time, and the average "adjusted" response time.</p>
<p>The following example was "contrived". The <a href="coordinated-omission/../example/drupal-memcache.html"><code>drupal_memcache</code></a> example was run for 15 seconds, and after 10 seconds the upstream Apache server was manually "paused" for 3 seconds, forcing some abnormally slow queries. (More specifically, the apache web server was started by running <code>. /etc/apache2/envvars &amp;&amp; /usr/sbin/apache2 -DFOREGROUND</code>, it was "paused" by pressing <code>ctrl-z</code>, and it was resumed three seconds later by typing <code>fg</code>.) In the "PER REQUEST METRICS" Goose shows first the "raw" metrics", followed by the "adjusted" metrics:</p>
<pre><code class="language-bash"> ------------------------------------------------------------------------------
 Name                     |    Avg (ms) |        Min |         Max |     Median
 ------------------------------------------------------------------------------
 GET (Anon) front page    |       11.73 |          3 |          81 |         12
 GET (Anon) node page     |       81.76 |          5 |       3,390 |         37
 GET (Anon) user page     |       27.53 |         16 |          94 |         26
 GET (Auth) comment form  |       35.27 |         24 |          50 |         35
 GET (Auth) front page    |       30.68 |         20 |         111 |         26
 GET (Auth) node page     |       97.79 |         23 |       3,326 |         35
 GET (Auth) user page     |       25.20 |         21 |          30 |         25
 GET static asset         |        9.27 |          2 |          98 |          6
 POST (Auth) comment form |       52.47 |         43 |          59 |         52
 -------------------------+-------------+------------+-------------+-----------
 Aggregated               |       17.04 |          2 |       3,390 |          8
 ------------------------------------------------------------------------------
 Adjusted for Coordinated Omission:
 ------------------------------------------------------------------------------
 Name                     |    Avg (ms) |    Std Dev |         Max |     Median
 ------------------------------------------------------------------------------
 GET (Anon) front page    |      419.82 |     288.56 |       3,153 |         14
 GET (Anon) node page     |      464.72 |     270.80 |       3,390 |         40
 GET (Anon) user page     |      420.48 |     277.86 |       3,133 |         27
 GET (Auth) comment form  |      503.38 |     331.01 |       2,951 |         37
 GET (Auth) front page    |      489.99 |     324.78 |       2,960 |         33
 GET (Auth) node page     |      530.29 |     305.82 |       3,326 |         37
 GET (Auth) user page     |      500.67 |     336.21 |       2,959 |         27
 GET static asset         |      427.70 |     295.87 |       3,154 |          9
 POST (Auth) comment form |      512.14 |     325.04 |       2,932 |         55
 -------------------------+-------------+------------+-------------+-----------
 Aggregated               |      432.98 |     294.11 |       3,390 |         14
</code></pre>
<p>From these two tables, we can observe a notable difference between the raw and adjusted metrics. The standard deviation between the "raw" average and the "adjusted" average is considerably larger than the "raw" average, indicating that a performance event occurred that affected request timing. Whether this indicates a "valid" load test depends on your specific goals and testing context.</p>
<p><strong>Note</strong>: It is beyond the scope of Goose to test for statistically significant changes in the right-tail, or other locations, of the distribution of response times. Goose produces the raw data you need to conduct these tests. For detailed statistical analysis, consider using tools like the Kolmogorov-Smirnov or Anderson-Darling tests to compare distributions. Keep in mind that CO-adjusted data is derived from raw data and thus not statistically independent.</p>
<p>Goose also shows multiple percentile graphs, again showing first the "raw" metrics followed by the "adjusted" metrics. The "raw" graph would suggest that less than 1% of the requests for the <code>GET (Anon) node page</code> were slow, and less than 0.1% of the requests for the <code>GET (Auth) node page</code> were slow. However, through Coordinated Omission Mitigation we can see that statistically this would have actually affected all requests, and for authenticated users the impact is visible on &gt;25% of the requests.</p>
<pre><code class="language-bash"> ------------------------------------------------------------------------------
 Slowest page load within specified percentile of requests (in ms):
 ------------------------------------------------------------------------------
 Name                     |    50% |    75% |    98% |    99% |  99.9% | 99.99%
 ------------------------------------------------------------------------------
 GET (Anon) front page    |     12 |     15 |     25 |     27 |     81 |     81
 GET (Anon) node page     |     37 |     43 |     60 |  3,000 |  3,000 |  3,000
 GET (Anon) user page     |     26 |     28 |     34 |     93 |     94 |     94
 GET (Auth) comment form  |     35 |     37 |     50 |     50 |     50 |     50
 GET (Auth) front page    |     26 |     34 |     45 |     88 |    110 |    110
 GET (Auth) node page     |     35 |     38 |     58 |     58 |  3,000 |  3,000
 GET (Auth) user page     |     25 |     27 |     30 |     30 |     30 |     30
 GET static asset         |      6 |     14 |     21 |     22 |     81 |     98
 POST (Auth) comment form |     52 |     55 |     59 |     59 |     59 |     59
 -------------------------+--------+--------+--------+--------+--------+-------
 Aggregated               |      8 |     16 |     47 |     53 |  3,000 |  3,000
 ------------------------------------------------------------------------------
 Adjusted for Coordinated Omission:
 ------------------------------------------------------------------------------
 Name                     |    50% |    75% |    98% |    99% |  99.9% | 99.99%
 ------------------------------------------------------------------------------
 GET (Anon) front page    |     14 |     21 |  3,000 |  3,000 |  3,000 |  3,000
 GET (Anon) node page     |     40 |     55 |  3,000 |  3,000 |  3,000 |  3,000
 GET (Anon) user page     |     27 |     32 |  3,000 |  3,000 |  3,000 |  3,000
 GET (Auth) comment form  |     37 |    400 |  2,951 |  2,951 |  2,951 |  2,951
 GET (Auth) front page    |     33 |    410 |  2,960 |  2,960 |  2,960 |  2,960
 GET (Auth) node page     |     37 |    410 |  3,000 |  3,000 |  3,000 |  3,000
 GET (Auth) user page     |     27 |    420 |  2,959 |  2,959 |  2,959 |  2,959
 GET static asset         |      9 |     20 |  3,000 |  3,000 |  3,000 |  3,000
 POST (Auth) comment form |     55 |    390 |  2,932 |  2,932 |  2,932 |  2,932
 -------------------------+--------+--------+--------+--------+--------+-------
 Aggregated               |     14 |     42 |  3,000 |  3,000 |  3,000 |  3,000
</code></pre>
<p>The Coordinated Omission metrics will also show up in the HTML report generated when Goose is started with the <code>--report-file</code> run-time option. If Coordinated Omission mitigation kicked in, the HTML report will include both the "raw" metrics and the "adjusted" metrics.</p>
<h2 id="enhanced-co-event-tracking"><a class="header" href="#enhanced-co-event-tracking">Enhanced CO Event Tracking</a></h2>
<p>In addition to the raw and adjusted metrics, Goose now provides detailed Coordinated Omission event tracking that appears in all report formats (console, HTML, markdown, and JSON). This enhanced tracking provides comprehensive insights into when and how CO events affected your test.</p>
<h3 id="co-event-metrics-display"><a class="header" href="#co-event-metrics-display">CO Event Metrics Display</a></h3>
<p>When CO events occur during your test, you'll see a dedicated "COORDINATED OMISSION METRICS" section that appears before the overview:</p>
<pre><code class="language-bash"> === COORDINATED OMISSION METRICS ===
 Duration: 45 seconds
 Total CO Events: 12
 Events per minute: 16.00

 Request Breakdown:
   Actual requests: 2,847
   Synthetic requests: 156 (5.2%)

 Severity Distribution:
   Minor: 8
   Moderate: 3
   Severe: 1
   Critical: 0
</code></pre>
<h3 id="understanding-co-event-severity"><a class="header" href="#understanding-co-event-severity">Understanding CO Event Severity</a></h3>
<p>Goose classifies CO events based on how much longer the actual response took compared to the expected cadence:</p>
<ul>
<li><strong>Minor (2-5x)</strong>: Response took 2-5 times longer than expected</li>
<li><strong>Moderate (5-10x)</strong>: Response took 5-10 times longer than expected</li>
<li><strong>Severe (10-20x)</strong>: Response took 10-20 times longer than expected</li>
<li><strong>Critical (&gt;20x)</strong>: Response took more than 20 times longer than expected</li>
</ul>
<h3 id="interpreting-synthetic-request-percentage"><a class="header" href="#interpreting-synthetic-request-percentage">Interpreting Synthetic Request Percentage</a></h3>
<p>The synthetic request percentage tells you how much of your data comes from CO mitigation:</p>
<ul>
<li><strong>&lt;10%</strong>: High confidence in results, minimal CO impact</li>
<li><strong>10-30%</strong>: Medium confidence, some CO events occurred</li>
<li><strong>30-50%</strong>: Lower confidence, significant CO impact</li>
<li><strong>&gt;50%</strong>: Results heavily influenced by synthetic data</li>
</ul>
<h3 id="practical-example-microservice-testing"><a class="header" href="#practical-example-microservice-testing">Practical Example: Microservice Testing</a></h3>
<p>Consider testing a microservice with strict 100ms SLA requirements:</p>
<pre><code class="language-bash"># Test with minimum cadence for strict SLA validation
cargo run --example api_test -- \
    --host https://api.example.com \
    --users 50 \
    --run-time 5m \
    --co-mitigation minimum

# Results might show:
# === COORDINATED OMISSION METRICS ===
# Duration: 300 seconds
# Total CO Events: 45
# Events per minute: 9.00
# 
# Request Breakdown:
#   Actual requests: 14,523
#   Synthetic requests: 892 (5.8%)
# 
# Severity Distribution:
#   Minor: 38    # Most events were 2-5x slower than expected
#   Moderate: 6  # Some 5-10x slower
#   Severe: 1    # One event 10-20x slower
#   Critical: 0  # No critical events
</code></pre>
<p>This tells you that while most requests met the SLA, there were 45 instances where performance degraded, affecting 5.8% of your measurements. The predominance of "Minor" events suggests occasional but not severe performance issues.</p>
<h3 id="practical-example-web-application-testing"><a class="header" href="#practical-example-web-application-testing">Practical Example: Web Application Testing</a></h3>
<p>For a public-facing web application with more tolerance for variance:</p>
<pre><code class="language-bash"># Test with average cadence for realistic user simulation
cargo run --example webapp_test -- \
    --host https://webapp.example.com \
    --users 200 \
    --run-time 10m \
    --co-mitigation average

# Results might show:
# === COORDINATED OMISSION METRICS ===
# Duration: 600 seconds
# Total CO Events: 8
# Events per minute: 0.80
# 
# Request Breakdown:
#   Actual requests: 28,945
#   Synthetic requests: 67 (0.2%)
# 
# Severity Distribution:
#   Minor: 5
#   Moderate: 2
#   Severe: 1
#   Critical: 0
</code></pre>
<p>This shows a much healthier system with only occasional CO events and minimal synthetic data generation (0.2%), indicating the system handled the load well.</p>
<h3 id="when-to-be-concerned"><a class="header" href="#when-to-be-concerned">When to Be Concerned</a></h3>
<p><strong>Red flags in CO metrics:</strong></p>
<ul>
<li>Synthetic request percentage &gt;30%</li>
<li>High frequency of Severe or Critical events</li>
<li>Events per minute consistently &gt;10</li>
<li>Large gaps between raw and adjusted percentiles</li>
</ul>
<p><strong>Green flags:</strong></p>
<ul>
<li>Synthetic request percentage &lt;10%</li>
<li>Mostly Minor events with few Moderate</li>
<li>Low events per minute (&lt;5)</li>
<li>Small differences between raw and adjusted metrics</li>
</ul>
<h3 id="using-co-metrics-for-capacity-planning"><a class="header" href="#using-co-metrics-for-capacity-planning">Using CO Metrics for Capacity Planning</a></h3>
<p>CO event tracking helps with capacity planning:</p>
<ol>
<li><strong>Identify Breaking Points</strong>: Watch for sudden increases in CO events as load increases</li>
<li><strong>SLA Validation</strong>: Use minimum cadence mode to catch any SLA violations</li>
<li><strong>Performance Regression</strong>: Compare CO metrics across test runs to detect degradation</li>
<li><strong>Resource Scaling</strong>: CO events often indicate when additional resources are needed</li>
</ol>
<p>The enhanced CO metrics provide the detailed insights needed to understand not just that performance issues occurred, but their frequency, severity, and impact on your test results.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="practical-examples"><a class="header" href="#practical-examples">Practical Examples</a></h1>
<p>This chapter provides real-world examples of when and how to use different Coordinated Omission mitigation strategies. Each example includes the command to run, expected output, and interpretation guidance.</p>
<h2 id="example-1-microservice-sla-validation"><a class="header" href="#example-1-microservice-sla-validation">Example 1: Microservice SLA Validation</a></h2>
<p><strong>Scenario</strong>: You're testing a payment processing microservice that must respond within 100ms for 99% of requests.</p>
<p><strong>Goal</strong>: Detect any SLA violations, no matter how brief.</p>
<p><strong>Strategy</strong>: Use <code>minimum</code> cadence to catch even momentary slowdowns.</p>
<pre><code class="language-bash"># Test command
cargo run --example payment_service -- \
    --host https://payments.api.company.com \
    --users 20 \
    --run-time 5m \
    --co-mitigation minimum \
    --report-file payment_test.html

# Expected healthy output:
# === COORDINATED OMISSION METRICS ===
# Duration: 300 seconds
# Total CO Events: 2
# Events per minute: 0.40
# 
# Request Breakdown:
#   Actual requests: 18,450
#   Synthetic requests: 12 (0.1%)
# 
# Severity Distribution:
#   Minor: 2
#   Moderate: 0
#   Severe: 0
#   Critical: 0
</code></pre>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>✅ <strong>Excellent</strong>: Only 2 minor CO events in 5 minutes</li>
<li>✅ <strong>SLA Met</strong>: 0.1% synthetic requests indicates 99.9% of requests met timing expectations</li>
<li>✅ <strong>No Critical Issues</strong>: No severe or critical events</li>
</ul>
<p><strong>Red Flag Example</strong>:</p>
<pre><code class="language-bash"># Problematic output:
# === COORDINATED OMISSION METRICS ===
# Duration: 300 seconds
# Total CO Events: 45
# Events per minute: 9.00
# 
# Request Breakdown:
#   Actual requests: 18,450
#   Synthetic requests: 892 (4.6%)
# 
# Severity Distribution:
#   Minor: 38
#   Moderate: 6
#   Severe: 1
#   Critical: 0
</code></pre>
<p><strong>Action Required</strong>: 4.6% synthetic requests and frequent CO events indicate the service is struggling to meet SLA requirements consistently.</p>
<h2 id="example-2-e-commerce-website-load-testing"><a class="header" href="#example-2-e-commerce-website-load-testing">Example 2: E-commerce Website Load Testing</a></h2>
<p><strong>Scenario</strong>: Testing an e-commerce site during Black Friday preparation. Users can tolerate some variability, but you want to understand overall performance.</p>
<p><strong>Goal</strong>: Simulate realistic user behavior while detecting significant performance issues.</p>
<p><strong>Strategy</strong>: Use <code>average</code> cadence for balanced detection.</p>
<pre><code class="language-bash"># Test command
cargo run --example ecommerce_site -- \
    --host https://shop.company.com \
    --users 500 \
    --run-time 15m \
    --co-mitigation average \
    --report-file blackfriday_test.html

# Expected healthy output:
# === COORDINATED OMISSION METRICS ===
# Duration: 900 seconds
# Total CO Events: 12
# Events per minute: 0.80
# 
# Request Breakdown:
#   Actual requests: 145,230
#   Synthetic requests: 234 (0.2%)
# 
# Severity Distribution:
#   Minor: 8
#   Moderate: 3
#   Severe: 1
#   Critical: 0
</code></pre>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>✅ <strong>Good Performance</strong>: Low CO event rate (0.8/minute)</li>
<li>✅ <strong>Minimal Impact</strong>: Only 0.2% synthetic requests</li>
<li>⚠️ <strong>Monitor</strong>: One severe event warrants investigation</li>
</ul>
<p><strong>Concerning Example</strong>:</p>
<pre><code class="language-bash"># Problematic output:
# === COORDINATED OMISSION METRICS ===
# Duration: 900 seconds
# Total CO Events: 156
# Events per minute: 10.40
# 
# Request Breakdown:
#   Actual requests: 145,230
#   Synthetic requests: 12,450 (7.9%)
# 
# Severity Distribution:
#   Minor: 89
#   Moderate: 45
#   Severe: 18
#   Critical: 4
</code></pre>
<p><strong>Action Required</strong>: High CO event rate and 7.9% synthetic requests indicate the site will struggle under Black Friday load. Scale up resources or optimize performance.</p>
<h2 id="example-3-api-gateway-performance-testing"><a class="header" href="#example-3-api-gateway-performance-testing">Example 3: API Gateway Performance Testing</a></h2>
<p><strong>Scenario</strong>: Testing an API gateway that routes requests to multiple backend services. You want to understand how backend slowdowns affect the gateway.</p>
<p><strong>Goal</strong>: Detect when backend issues cause gateway performance degradation.</p>
<p><strong>Strategy</strong>: Use <code>average</code> cadence with longer test duration to capture intermittent issues.</p>
<pre><code class="language-bash"># Test command
cargo run --example api_gateway -- \
    --host https://gateway.api.company.com \
    --users 100 \
    --run-time 30m \
    --co-mitigation average \
    --report-file gateway_test.html

# Healthy distributed system output:
# === COORDINATED OMISSION METRICS ===
# Duration: 1800 seconds
# Total CO Events: 23
# Events per minute: 0.77
# 
# Request Breakdown:
#   Actual requests: 324,500
#   Synthetic requests: 445 (0.1%)
# 
# Severity Distribution:
#   Minor: 18
#   Moderate: 4
#   Severe: 1
#   Critical: 0
</code></pre>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>✅ <strong>Stable Gateway</strong>: Low synthetic percentage indicates good overall performance</li>
<li>✅ <strong>Resilient</strong>: Minor events suggest the gateway handles backend hiccups well</li>
<li>✅ <strong>Scalable</strong>: Consistent performance over 30 minutes</li>
</ul>
<h2 id="example-4-database-connection-pool-testing"><a class="header" href="#example-4-database-connection-pool-testing">Example 4: Database Connection Pool Testing</a></h2>
<p><strong>Scenario</strong>: Testing an application's database connection pool under load to ensure it doesn't become a bottleneck.</p>
<p><strong>Goal</strong>: Detect connection pool exhaustion or database slowdowns.</p>
<p><strong>Strategy</strong>: Use <code>minimum</code> cadence to catch any database-related delays immediately.</p>
<pre><code class="language-bash"># Test command
cargo run --example database_app -- \
    --host https://app.company.com \
    --users 200 \
    --run-time 10m \
    --co-mitigation minimum \
    --report-file db_pool_test.html

# Healthy connection pool output:
# === COORDINATED OMISSION METRICS ===
# Duration: 600 seconds
# Total CO Events: 8
# Events per minute: 0.80
# 
# Request Breakdown:
#   Actual requests: 89,450
#   Synthetic requests: 67 (0.1%)
# 
# Severity Distribution:
#   Minor: 6
#   Moderate: 2
#   Severe: 0
#   Critical: 0
</code></pre>
<p><strong>Pool Exhaustion Example</strong>:</p>
<pre><code class="language-bash"># Connection pool exhaustion:
# === COORDINATED OMISSION METRICS ===
# Duration: 600 seconds
# Total CO Events: 234
# Events per minute: 23.40
# 
# Request Breakdown:
#   Actual requests: 89,450
#   Synthetic requests: 8,920 (9.1%)
# 
# Severity Distribution:
#   Minor: 45
#   Moderate: 123
#   Severe: 56
#   Critical: 10
</code></pre>
<p><strong>Action Required</strong>: High CO event rate and 9.1% synthetic requests indicate connection pool exhaustion. Increase pool size or optimize database queries.</p>
<h2 id="example-5-cdn-performance-validation"><a class="header" href="#example-5-cdn-performance-validation">Example 5: CDN Performance Validation</a></h2>
<p><strong>Scenario</strong>: Testing how your application performs when the CDN is slow or unavailable.</p>
<p><strong>Goal</strong>: Understand the impact of CDN issues on user experience.</p>
<p><strong>Strategy</strong>: Use <code>average</code> cadence to simulate realistic user tolerance.</p>
<pre><code class="language-bash"># Test command with CDN issues simulated
cargo run --example cdn_test -- \
    --host https://app.company.com \
    --users 150 \
    --run-time 10m \
    --co-mitigation average \
    --report-file cdn_impact_test.html

# CDN issues detected:
# === COORDINATED OMISSION METRICS ===
# Duration: 600 seconds
# Total CO Events: 89
# Events per minute: 8.90
# 
# Request Breakdown:
#   Actual requests: 67,230
#   Synthetic requests: 2,340 (3.4%)
# 
# Severity Distribution:
#   Minor: 34
#   Moderate: 38
#   Severe: 15
#   Critical: 2
</code></pre>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>⚠️ <strong>CDN Impact</strong>: 3.4% synthetic requests show CDN issues affect user experience</li>
<li>⚠️ <strong>User Frustration</strong>: Moderate and severe events indicate noticeable delays</li>
<li>📊 <strong>Business Impact</strong>: Use this data to justify CDN redundancy or optimization</li>
</ul>
<h2 id="example-6-baseline-testing-no-co-expected"><a class="header" href="#example-6-baseline-testing-no-co-expected">Example 6: Baseline Testing (No CO Expected)</a></h2>
<p><strong>Scenario</strong>: Testing a well-optimized system under normal load to establish performance baselines.</p>
<p><strong>Goal</strong>: Confirm the system performs consistently without CO events.</p>
<p><strong>Strategy</strong>: Use <code>disabled</code> to get pure measurements, then compare with <code>average</code> mode.</p>
<pre><code class="language-bash"># First, test with CO disabled for baseline
cargo run --example baseline_test -- \
    --host https://optimized.company.com \
    --users 100 \
    --run-time 10m \
    --co-mitigation disabled \
    --report-file baseline_raw.html

# Then test with CO detection enabled
cargo run --example baseline_test -- \
    --host https://optimized.company.com \
    --users 100 \
    --run-time 10m \
    --co-mitigation average \
    --report-file baseline_co.html

# Expected output (CO enabled):
# === COORDINATED OMISSION METRICS ===
# Duration: 600 seconds
# Total CO Events: 0
# Events per minute: 0.00
# 
# Request Breakdown:
#   Actual requests: 45,670
#   Synthetic requests: 0 (0.0%)
</code></pre>
<p><strong>Perfect Baseline</strong>: Zero CO events and 0% synthetic requests indicate the system performs consistently under this load level.</p>
<h2 id="interpreting-results-across-examples"><a class="header" href="#interpreting-results-across-examples">Interpreting Results Across Examples</a></h2>
<h3 id="green-flags-healthy-system"><a class="header" href="#green-flags-healthy-system">Green Flags (Healthy System)</a></h3>
<ul>
<li>CO events per minute &lt; 2</li>
<li>Synthetic request percentage &lt; 1%</li>
<li>Mostly Minor severity events</li>
<li>Consistent performance across test duration</li>
</ul>
<h3 id="yellow-flags-monitor-closely"><a class="header" href="#yellow-flags-monitor-closely">Yellow Flags (Monitor Closely)</a></h3>
<ul>
<li>CO events per minute 2-10</li>
<li>Synthetic request percentage 1-5%</li>
<li>Some Moderate severity events</li>
<li>Occasional performance dips</li>
</ul>
<h3 id="red-flags-action-required"><a class="header" href="#red-flags-action-required">Red Flags (Action Required)</a></h3>
<ul>
<li>CO events per minute &gt; 10</li>
<li>Synthetic request percentage &gt; 5%</li>
<li>Frequent Severe or any Critical events</li>
<li>Degrading performance over time</li>
</ul>
<h3 id="using-co-metrics-for-capacity-planning-1"><a class="header" href="#using-co-metrics-for-capacity-planning-1">Using CO Metrics for Capacity Planning</a></h3>
<ol>
<li><strong>Find Breaking Point</strong>: Gradually increase load until CO events spike</li>
<li><strong>Set Alerts</strong>: Monitor CO metrics in production to detect issues early</li>
<li><strong>Compare Environments</strong>: Use CO metrics to validate staging vs production performance</li>
<li><strong>Track Trends</strong>: Monitor CO metrics over time to detect performance regression</li>
</ol>
<h2 id="best-practices-summary"><a class="header" href="#best-practices-summary">Best Practices Summary</a></h2>
<ol>
<li>
<p><strong>Choose the Right Mode</strong>:</p>
<ul>
<li><code>minimum</code> for strict SLA validation</li>
<li><code>average</code> for realistic user simulation</li>
<li><code>disabled</code> for baseline measurements</li>
</ul>
</li>
<li>
<p><strong>Set Appropriate Test Duration</strong>:</p>
<ul>
<li>Short tests (5-10 min) for quick validation</li>
<li>Long tests (30+ min) for stability assessment</li>
</ul>
</li>
<li>
<p><strong>Monitor Key Metrics</strong>:</p>
<ul>
<li>Events per minute rate</li>
<li>Synthetic request percentage</li>
<li>Severity distribution</li>
<li>Trends over time</li>
</ul>
</li>
<li>
<p><strong>Take Action Based on Results</strong>:</p>
<ul>
<li>&lt; 1% synthetic: System healthy</li>
<li>1-5% synthetic: Monitor and investigate</li>
<li>
<blockquote>
<p>5% synthetic: Performance issues need attention</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<p>These examples provide a foundation for understanding how CO metrics help identify and quantify performance issues in different scenarios. Use them as templates for your own testing strategies.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration"><a class="header" href="#configuration">Configuration</a></h1>
<p>Configuration of Goose load tests is done in Rust code within the load test plan. Complete documentation of all load test configuration can be found in the <a href="https://docs.rs/goose">developer documentation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="defaults"><a class="header" href="#defaults">Defaults</a></h1>
<p>All run-time options can be configured with custom defaults. For example, you may want to default to the the host name of your local development environment, only requiring that <code>--host</code> be set when running against a production environment. Assuming your local development environment is at "http://local.dev/" you can do this as follows:</p>
<pre><code class="language-rust ignore">    GooseAttack::initialize()?
        .register_scenario(scenario!("LoadtestTransactions")
            .register_transaction(transaction!(loadtest_index))
        )
        .set_default(GooseDefault::Host, "http://local.dev/")?
        .execute()
        .await?;

    Ok(())</code></pre>
<p>The following defaults can be configured with a <code>&amp;str</code>:</p>
<ul>
<li>host: <code>GooseDefault::Host</code></li>
<li>set a per-request timeout: <code>GooseDefault::Timeout</code></li>
<li>users to start per second: <code>GooseDefault::HatchRate</code></li>
<li>report file names: <code>GooseDefault::ReportFile</code></li>
<li>goose log file name: <code>GooseDefault::GooseLog</code></li>
<li>request log file name: <code>GooseDefault::RequestLog</code></li>
<li>transaction log file name: <code>GooseDefault::TransactionLog</code></li>
<li>error log file name: <code>GooseDefault::ErrorLog</code></li>
<li>debug log file name: <code>GooseDefault::DebugLog</code></li>
<li>test plan: <code>GooseDefault::TestPlan</code></li>
<li>host to bind telnet Controller to: <code>GooseDefault::TelnetHost</code></li>
<li>host to bind WebSocket Controller to: <code>GooseDefault::WebSocketHost</code></li>
<li>host to bind Manager to: <code>GooseDefault::ManagerBindHost</code></li>
<li>host for Worker to connect to: <code>GooseDefault::ManagerHost</code></li>
</ul>
<p>The following defaults can be configured with a <code>usize</code> integer:</p>
<ul>
<li>total users to start: <code>GooseDefault::Users</code></li>
<li>how quickly to start all users: <code>GooseDefault::StartupTime</code></li>
<li>how often to print running metrics: <code>GooseDefault::RunningMetrics</code></li>
<li>number of seconds for test to run: <code>GooseDefault::RunTime</code></li>
<li>log level: <code>GooseDefault::LogLevel</code></li>
<li>quiet: <code>GooseDefault::Quiet</code></li>
<li>verbosity: <code>GooseDefault::Verbose</code></li>
<li>maximum requests per second: <code>GooseDefault::ThrottleRequests</code></li>
<li>number of Workers to expect: <code>GooseDefault::ExpectWorkers</code></li>
<li>port to bind telnet Controller to: <code>GooseDefault::TelnetPort</code></li>
<li>port to bind WebSocket Controller to: <code>GooseDefault::WebSocketPort</code></li>
<li>port to bind Manager to: <code>GooseDefault::ManagerBindPort</code></li>
<li>port for Worker to connect to: <code>GooseDefault::ManagerPort</code></li>
</ul>
<p>The following defaults can be configured with a <code>bool</code>:</p>
<ul>
<li>do not reset metrics after all users start: <code>GooseDefault::NoResetMetrics</code></li>
<li>do not print metrics: <code>GooseDefault::NoPrintMetrics</code></li>
<li>do not track metrics: <code>GooseDefault::NoMetrics</code></li>
<li>do not track transaction metrics: <code>GooseDefault::NoTransactionMetrics</code></li>
<li>do not log the request body in the error log: <code>GooseDefault::NoRequestBody</code></li>
<li>do not display the error summary: <code>GooseDefault::NoErrorSummary</code></li>
<li>do not log the response body in the debug log: <code>GooseDefault::NoDebugBody</code></li>
<li>do not start telnet Controller thread: <code>GooseDefault::NoTelnet</code></li>
<li>do not start WebSocket Controller thread: <code>GooseDefault::NoWebSocket</code></li>
<li>do not autostart load test, wait instead for a Controller to start: <code>GooseDefault::NoAutoStart</code></li>
<li>do not gzip compress requests: <code>GooseDefault::NoGzip</code></li>
<li>do not track status codes: <code>GooseDefault::NoStatusCodes</code></li>
<li>follow redirect of base_url: <code>GooseDefault::StickyFollow</code></li>
<li>enable Manager mode: <code>GooseDefault::Manager</code></li>
<li>enable Worker mode: <code>GooseDefault::Worker</code></li>
<li>ignore load test checksum: <code>GooseDefault::NoHashCheck</code></li>
<li>do not collect granular data in the reports: <code>GooseDefault::NoGranularData</code></li>
</ul>
<p>The following defaults can be configured with a <code>GooseLogFormat</code>:</p>
<ul>
<li>request log file format: <code>GooseDefault::RequestFormat</code></li>
<li>transaction log file format: <code>GooseDefault::TransactionFormat</code></li>
<li>error log file format: <code>GooseDefault::ErrorFormat</code></li>
<li>debug log file format: <code>GooseDefault::DebugFormat</code></li>
</ul>
<p>The following defaults can be configured with a <code>GooseCoordinatedOmissionMitigation</code>:</p>
<ul>
<li>default Coordinated Omission Mitigation strategy: <code>GooseDefault::CoordinatedOmissionMitigation</code></li>
</ul>
<p>For example, without any run-time options the following load test would automatically run against <code>local.dev</code>, logging metrics to <code>goose-metrics.log</code> and debug to <code>goose-debug.log</code>. It will automatically launch 20 users in 4 seconds, and run the load test for 15 minutes. Metrics will be displayed every minute during the test, and the status code table will be disabled. The order the defaults are set is not important.</p>
<pre><code class="language-rust ignore">    GooseAttack::initialize()?
        .register_scenario(scenario!("LoadtestTransactions")
            .register_transaction(transaction!(loadtest_index))
        )
        .set_default(GooseDefault::Host, "local.dev")?
        .set_default(GooseDefault::RequestLog, "goose-requests.log")?
        .set_default(GooseDefault::DebugLog, "goose-debug.log")?
        .set_default(GooseDefault::Users, 20)?
        .set_default(GooseDefault::HatchRate, 4)?
        .set_default(GooseDefault::RunTime, 900)?
        .set_default(GooseDefault::RunningMetrics, 60)?
        .set_default(GooseDefault::NoStatusCodes, true)?
        .execute()
        .await?;

    Ok(())</code></pre>
<p>Find a complete list of all configuration options that can be configured with custom defaults <a href="https://docs.rs/goose/*/goose/config/enum.GooseDefault.html">in the developer documentation</a>, as well as complete details on <a href="https://docs.rs/goose/*/goose/config/trait.GooseDefaultType.html">how to configure defaults</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scheduling-scenarios-and-transactions"><a class="header" href="#scheduling-scenarios-and-transactions">Scheduling Scenarios And Transactions</a></h1>
<p>When starting a load test, Goose assigns one <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> to each <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> thread. By default, it assigns <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> (and then <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> within the scenario) in a round robin order. As new <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> threads are launched, the first will be assigned the first defined <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a>, the next will be assigned the next defined <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a>, and so on, looping through all available <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a>. Weighting is respected during this process, so if one <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> is weighted heavier than others, that <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> will get assigned to <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> more at the end of the launching process.</p>
<p>The <a href="https://docs.rs/goose/*/goose/enum.GooseScheduler.html"><code>GooseScheduler</code></a> can be configured to instead launch <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> and <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> in a <a href="https://docs.rs/goose/*/goose/enum.GooseScheduler.html#variant.Serial"><code>Serial</code></a> or a <a href="https://docs.rs/goose/*/goose/enum.GooseScheduler.html#variant.Random"><code>Random order</code></a>. When configured to allocate in a <a href="https://docs.rs/goose/*/goose/enum.GooseScheduler.html#variant.Serial"><code>Serial</code></a> order, <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> and <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> are launched in the extact order they are defined in the load test (see below for more detail on how this works). When configured to allocate in a <a href="https://docs.rs/goose/*/goose/enum.GooseScheduler.html#variant.Random"><code>Random</code></a> order, running the same load test multiple times can lead to different amounts of load being generated.</p>
<p>Prior to Goose <code>0.10.6</code> <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> were allocated in a serial order. Prior to Goose <code>0.11.1</code> <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> were allocated in a serial order. To restore the old behavior, you can use the <a href="https://docs.rs/goose/*/goose/struct.GooseAttack.html#method.set_scheduler"><code>GooseAttack::set_scheduler()</code></a> method as follows:</p>
<pre><code class="language-rust ignore">    GooseAttack::initialize()?
        .set_scheduler(GooseScheduler::Serial);</code></pre>
<p>To instead randomize the order that <a href="https://docs.rs/goose/*/goose/goose/struct.Scenario.html"><code>Scenario</code></a> and <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> are allocated, you can instead configure as follows:</p>
<pre><code class="language-rust ignore">    GooseAttack::initialize()?
        .set_scheduler(GooseScheduler::Random);</code></pre>
<p>The following configuration is possible but superfluous because it is the scheduling default, and is therefor how Goose behaves even if the <a href="https://docs.rs/goose/*/goose/struct.GooseAttack.html#method.set_scheduler"><code>.set_scheduler()</code></a> method is not called at all:</p>
<pre><code class="language-rust ignore">    GooseAttack::initialize()?
        .set_scheduler(GooseScheduler::RoundRobin);</code></pre>
<h2 id="scheduling-example"><a class="header" href="#scheduling-example">Scheduling Example</a></h2>
<p>The following simple example helps illustrate how the different schedulers work.</p>
<pre><code class="language-rust ignore">use goose::prelude::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    GooseAttack::initialize()?
        .register_scenario(scenario!("Scenario1")
            .register_transaction(transaction!(transaction1).set_weight(2)?)
            .register_transaction(transaction!(transaction2))
            .set_weight(2)?
        )
        .register_scenario(scenario!("Scenario2")
            .register_transaction(transaction!(transaction1))
            .register_transaction(transaction!(transaction2).set_weight(2)?)
        )
        .execute()
        .await?;

    Ok(())
}</code></pre>
<h2 id="round-robin-scheduler"><a class="header" href="#round-robin-scheduler">Round Robin Scheduler</a></h2>
<p>This first example assumes the default of <code>.set_scheduler(GooseScheduler::RoundRobin)</code>.</p>
<p>If Goose is told to launch only two users, the first <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> will run <code>Scenario1</code> and the second user will run <code>Scenario2</code>. Even though <code>Scenario1</code> has a weight of 2 <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> are allocated round-robin so with only two users the second instance of <code>Scenario1</code> is never launched.</p>
<p>The <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> running <code>Scenario1</code> will then launch transactions repeatedly in the following order: <code>transactions1</code>, <code>transactions2</code>, <code>transaction1</code>. If it runs through twice, then it runs all of the following transactions in the following order: <code>transaction1</code>, <code>transaction2</code>, <code>transaction1</code>, <code>transaction1</code>, <code>transaction2</code>, <code>transaction1</code>.</p>
<h2 id="serial-scheduler"><a class="header" href="#serial-scheduler">Serial Scheduler</a></h2>
<p>This second example assumes the manual configuration of <code>.set_scheduler(GooseScheduler::Serial)</code>.</p>
<p>If Goose is told to launch only two users, then both <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> will launch <code>Scenario1</code> as it has a weight of 2. <code>Scenario2</code> will not get assigned to either of the users.</p>
<p>Both <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> running <code>Scenario1</code> will then launch transactions repeatedly in the following order: <code>transaction1</code>, <code>transaction1</code>, <code>transaction2</code>. If it runs through twice, then it runs all of the following transactions in the following order: <code>transaction1</code>, <code>transaction1</code>, <code>transaction2</code>, <code>transaction1</code>, <code>transaction1</code>, <code>transaction2</code>.</p>
<h2 id="random-scheduler"><a class="header" href="#random-scheduler">Random Scheduler</a></h2>
<p>This third example assumes the manual configuration of <code>.set_scheduler(GooseScheduler::Random)</code>.</p>
<p>If Goose is told to launch only two users, the first will be randomly assigned either <code>Scenario1</code> or <code>Scenario2</code>. Regardless of which is assigned to the first user, the second will again be randomly assigned either <code>Scenario1</code> or <code>Scenario2</code>. If the load test is stopped and run again, there users are randomly re-assigned, there is no consistency between load test runs.</p>
<p>Each <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> will run transactions in a random order. The random order will be determined at start time and then will run repeatedly in this random order as long as the user runs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rustls"><a class="header" href="#rustls">RustLS</a></h1>
<p>By default Reqwest (and therefore Goose) uses the system-native transport layer security to make HTTPS requests. This means <code>schannel</code> on Windows, <code>Security-Framework</code> on macOS, and <code>OpenSSL</code> on Linux. If you'd prefer to use a <a href="https://github.com/ctz/rustls">pure Rust TLS implementation</a>, disable default features and enable <code>rustls-tls</code> in <code>Cargo.toml</code> as follows:</p>
<pre><code class="language-toml">[dependencies]
goose = { version = "^0.18", default-features = false, features = ["rustls-tls"] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples-2"><a class="header" href="#examples-2">Examples</a></h1>
<p>Goose includes several examples to demonstrate load test functionality, including:</p>
<ul>
<li><a href="example/simple.html">Simple</a> <em>(<a href="https://github.com/tag1consulting/goose/blob/main/examples/simple.rs">examples/simple.rs</a>)</em></li>
<li><a href="example/closure.html">Closure</a> <em>(<a href="https://github.com/tag1consulting/goose/blob/main/examples/closure.rs">examples/closure.rs</a>)</em></li>
<li><a href="example/session.html">Session</a> <em>(<a href="https://github.com/tag1consulting/goose/blob/main/examples/session.rs">examples/session.rs</a>)</em></li>
<li><a href="example/drupal-memcache.html">Drupal Memcache</a> <em>(<a href="https://github.com/tag1consulting/goose/blob/main/examples/drupal_memcache.rs">examples/drupal_memcache.rs</a>)</em></li>
<li><a href="example/umami.html">Umami</a> <em>(<a href="https://github.com/tag1consulting/goose/tree/main/examples/umami">examples/umami/</a>)</em></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simple-example-1"><a class="header" href="#simple-example-1">Simple Example</a></h1>
<p>The <a href="https://github.com/tag1consulting/goose/blob/main/examples/simple.rs"><code>examples/simple.rs</code></a> example copies the simple load test documented on the <a href="https://locust.io/">locust.io web page</a>, rewritten in Rust for Goose. It uses minimal advanced functionality, but demonstrates how to GET and POST pages. It defines a single Scenario which has the user log in and then loads a couple of pages.</p>
<p>Goose can make use of all available CPU cores. By default, it will launch 1 user per core, and it can be configured to launch many more. The following was configured instead to launch 1,024 users. Each user randomly pauses 5 to 15 seconds after each transaction is loaded, so it's possible to spin up a large number of users. Here is a snapshot of <code>top</code> when running this example on a 1-core VM with 10G of available RAM -- there were ample resources to launch considerably more "users", though <code>ulimit</code> had to be resized:</p>
<pre><code class="language-bash">top - 06:56:06 up 15 days,  3:13,  2 users,  load average: 0.22, 0.10, 0.04
Tasks: 116 total,   3 running, 113 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.7 us,  0.7 sy,  0.0 ni, 96.7 id,  0.0 wa,  0.0 hi,  1.0 si,  0.0 st
MiB Mem :   9994.9 total,   7836.8 free,   1101.2 used,   1056.9 buff/cache
MiB Swap:  10237.0 total,  10237.0 free,      0.0 used.   8606.9 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 1339 goose     20   0 1235480 758292   8984 R   3.0   7.4   0:06.56 simple
</code></pre>
<h2 id="complete-source-code"><a class="header" href="#complete-source-code">Complete Source Code</a></h2>
<pre><code class="language-rust ignore">//! Simple Goose load test example. Duplicates the simple example on the
//! Locust project page (&lt;https://locust.io/&gt;).
//!
//! ## License
//!
//! Copyright 2020-2022 Jeremy Andrews
//!
//! Licensed under the Apache License, Version 2.0 (the "License");
//! you may not use this file except in compliance with the License.
//! You may obtain a copy of the License at
//!
//! &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;
//!
//! Unless required by applicable law or agreed to in writing, software
//! distributed under the License is distributed on an "AS IS" BASIS,
//! WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//! See the License for the specific language governing permissions and
//! limitations under the License.

use goose::prelude::*;
use std::time::Duration;

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    GooseAttack::initialize()?
        // In this example, we only create a single scenario, named "WebsiteUser".
        .register_scenario(
            scenario!("WebsiteUser")
                // After each transactions runs, sleep randomly from 5 to 15 seconds.
                .set_wait_time(Duration::from_secs(5), Duration::from_secs(15))?
                // This transaction only runs one time when the user first starts.
                .register_transaction(transaction!(website_login).set_on_start())
                // These next two transactions run repeatedly as long as the load test is running.
                .register_transaction(transaction!(website_index))
                .register_transaction(transaction!(website_about)),
        )
        .execute()
        .await?;

    Ok(())
}

/// Demonstrates how to log in when a user starts. We flag this transaction as an
/// on_start transaction when registering it above. This means it only runs one time
/// per user, when the user thread first starts.
async fn website_login(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let params = [("username", "test_user"), ("password", "")];
    let _goose = user.post_form("/login", &amp;params).await?;

    Ok(())
}

/// A very simple transaction that simply loads the front page.
async fn website_index(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let _goose = user.get("/").await?;

    Ok(())
}

/// A very simple transaction that simply loads the about page.
async fn website_about(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let _goose = user.get("/about/").await?;

    Ok(())
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="closure-example"><a class="header" href="#closure-example">Closure Example</a></h1>
<p>The <a href="https://github.com/tag1consulting/goose/blob/main/examples/closure.rs"><code>examples/closure.rs</code></a> example loads three different pages on a web site. Instead of defining a hard coded <a href="https://docs.rs/goose/*/goose/goose/struct.Transaction.html"><code>Transaction</code></a> function for each, the paths are passed in via a <a href="https://doc.rust-lang.org/std/vec/index.html">vector</a> and the <a href="https://docs.rs/goose/*/goose/goose/type.TransactionFunction.html">TransactionFunction</a> is dynamically created in a <a href="https://doc.rust-lang.org/rust-by-example/fn/closures.html">closure</a>.</p>
<h2 id="details-1"><a class="header" href="#details-1">Details</a></h2>
<p>The paths to be loaded are first defiend in a vector:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let paths = vec!["/", "/about", "/our-team"];
<span class="boring">}</span></code></pre></pre>
<p>A transaction function for each path is then dynamically created as a closure:</p>
<pre><code class="language-rust ignore">    for request_path in paths {
        let path = request_path;

        let closure: TransactionFunction = Arc::new(move |user| {
            Box::pin(async move {
                let _goose = user.get(path).await?;

                Ok(())
            })
        });</code></pre>
<h2 id="complete-source-code-1"><a class="header" href="#complete-source-code-1">Complete Source Code</a></h2>
<pre><code class="language-rust ignore">//! Simple Goose load test example using closures.
//!
//! ## License
//!
//! Copyright 2020 Fabian Franz
//!
//! Licensed under the Apache License, Version 2.0 (the "License");
//! you may not use this file except in compliance with the License.
//! You may obtain a copy of the License at
//!
//! &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;
//!
//! Unless required by applicable law or agreed to in writing, software
//! distributed under the License is distributed on an "AS IS" BASIS,
//! WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//! See the License for the specific language governing permissions and
//! limitations under the License.

use goose::prelude::*;
use std::boxed::Box;
use std::sync::Arc;
use std::time::Duration;

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    let mut scenario = scenario!("WebsiteUser")
        // After each transaction runs, sleep randomly from 5 to 15 seconds.
        .set_wait_time(Duration::from_secs(5), Duration::from_secs(15))?;

    let paths = vec!["/", "/about", "/our-team"];
    for request_path in paths {
        let path = request_path;

        let closure: TransactionFunction = Arc::new(move |user| {
            Box::pin(async move {
                let _goose = user.get(path).await?;

                Ok(())
            })
        });

        let transaction = Transaction::new(closure);
        // We need to do the variable dance as scenario.register_transaction returns self and hence moves
        // self out of `scenario`. By storing it in a new local variable and then moving it over
        // we can avoid that error.
        let new_scenario = scenario.register_transaction(transaction);
        scenario = new_scenario;
    }

    GooseAttack::initialize()?
        // In this example, we only create a single scenario, named "WebsiteUser".
        .register_scenario(scenario)
        .execute()
        .await?;

    Ok(())
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="session-example"><a class="header" href="#session-example">Session Example</a></h1>
<p>The <a href="https://github.com/tag1consulting/goose/blob/main/examples/session.rs"><code>examples/session.rs</code></a> example demonstrates how you can add JWT authentication support to your load test, making use of the <a href="https://docs.rs/goose/*/goose/goose/trait.GooseUserData.html"><code>GooseUserData</code></a> marker trait. In this example, the session is recorded in the <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> object with <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.set_session_data"><code>set_session_data</code></a>, and retrieved with <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html#method.get_session_data_unchecked"><code>get_session_data_unchecked</code></a>.</p>
<h2 id="details-2"><a class="header" href="#details-2">Details</a></h2>
<p>In this example, the <a href="https://docs.rs/goose/*/goose/goose/trait.GooseUserData.html"><code>GooseUserData</code></a> is a simple struct containing a string:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Session {
    jwt_token: String,
}
<span class="boring">}</span></code></pre></pre>
<p>The session data structure is created from json-formatted response data returned by an authentication request, uniquely stored in each <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> instance:</p>
<pre><code class="language-rust ignore">    user.set_session_data(Session {
        jwt_token: response.jwt_token,
    });</code></pre>
<p>The session data is retrieved from the <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> object with each subsequent request. To keep the example simple no validation is done:</p>
<pre><code class="language-rust ignore">    // This will panic if the session is missing or if the session is not of the right type.
    // Use `get_session_data` to handle a missing session.
    let session = user.get_session_data_unchecked::&lt;Session&gt;();

    // Create a Reqwest RequestBuilder object and configure bearer authentication when making
    // a GET request for the index.
    let reqwest_request_builder = user
        .get_request_builder(&amp;GooseMethod::Get, "/")?
        .bearer_auth(&amp;session.jwt_token);</code></pre>
<p><em>This example will panic if you run it without setting up a proper load test environment that actually sets the expected JWT token.</em></p>
<h2 id="complete-source-code-2"><a class="header" href="#complete-source-code-2">Complete Source Code</a></h2>
<pre><code class="language-rust ignore">//! Goose load test example, leveraging the per-GooseUser `GooseUserData` field
// to store a per-user session JWT authentication token.
//!
//! ## License
//!
//! Copyright 2020-2022 Jeremy Andrews
//!
//! Licensed under the Apache License, Version 2.0 (the "License");
//! you may not use this file except in compliance with the License.
//! You may obtain a copy of the License at
//!
//! &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;
//!
//! Unless required by applicable law or agreed to in writing, software
//! distributed under the License is distributed on an "AS IS" BASIS,
//! WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//! See the License for the specific language governing permissions and
//! limitations under the License.

use goose::prelude::*;
use serde::Deserialize;
use std::time::Duration;

struct Session {
    jwt_token: String,
}

#[derive(Deserialize)]
#[serde(rename_all = "camelCase")]
struct AuthenticationResponse {
    jwt_token: String,
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    GooseAttack::initialize()?
        // In this example, we only create a single scenario, named "WebsiteUser".
        .register_scenario(
            scenario!("WebsiteUser")
                // After each transaction runs, sleep randomly from 5 to 15 seconds.
                .set_wait_time(Duration::from_secs(5), Duration::from_secs(15))?
                // This transaction only runs one time when the user first starts.
                .register_transaction(transaction!(website_signup).set_on_start())
                // These next two transactions run repeatedly as long as the load test is running.
                .register_transaction(transaction!(authenticated_index)),
        )
        .execute()
        .await?;

    Ok(())
}

/// Demonstrates how to log in and set a session when a user starts. We flag this transaction as an
/// on_start transaction when registering it above. This means it only runs one time
/// per user, when the user thread first starts.
async fn website_signup(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let params = [("username", "test_user"), ("password", "")];
    let response = match user.post_form("/signup", &amp;params).await?.response {
        Ok(r) =&gt; match r.json::&lt;AuthenticationResponse&gt;().await {
            Ok(j) =&gt; j,
            Err(e) =&gt; return Err(Box::new(e.into())),
        },
        Err(e) =&gt; return Err(Box::new(e.into())),
    };

    user.set_session_data(Session {
        jwt_token: response.jwt_token,
    });

    Ok(())
}

/// A very simple transaction that simply loads the front page.
async fn authenticated_index(user: &amp;mut GooseUser) -&gt; TransactionResult {
    // This will panic if the session is missing or if the session is not of the right type.
    // Use `get_session_data` to handle a missing session.
    let session = user.get_session_data_unchecked::&lt;Session&gt;();

    // Create a Reqwest RequestBuilder object and configure bearer authentication when making
    // a GET request for the index.
    let reqwest_request_builder = user
        .get_request_builder(&amp;GooseMethod::Get, "/")?
        .bearer_auth(&amp;session.jwt_token);

    // Add the manually created RequestBuilder and build a GooseRequest object.
    let goose_request = GooseRequest::builder()
        .set_request_builder(reqwest_request_builder)
        .build();

    // Make the actual request.
    user.request(goose_request).await?;

    Ok(())
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="drupal-memcache-example"><a class="header" href="#drupal-memcache-example">Drupal Memcache Example</a></h1>
<p>The <a href="https://github.com/tag1consulting/goose/blob/main/examples/drupal_memcache.rs"><code>examples/drupal_memcache.rs</code></a> example is used to validate the performance of each release of the <a href="https://www.drupal.org/project/memcache">Drupal Memcache Module</a>.</p>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>Prior to every release of the <a href="https://www.drupal.org/project/memcache">Drupal Memcache Module</a>, <a href="https://www.tag1.com/">Tag1 Consulting</a> has run a load test to ensure consistent performance of the module which is dependend on by <a href="https://www.drupal.org/project/usage/memcache">tens of thousands of Drupal websites</a>.</p>
<p>The load test was initially implemented as a <a href="https://github.com/tag1consulting/drupal-loadtest/tree/206716d2bd3fdd199febba34a964117e1fd0fbde">JMeter testplan</a>. It was later converted to a <a href="https://github.com/tag1consulting/drupal-loadtest">Locust testplan</a>. Most recently it was converted to a <a href="https://github.com/tag1consulting/goose/blob/main/examples/drupal_memcache.rs">Goose testplan</a>.</p>
<p>Thie testplan is maintained as a simple real-world Goose load test example.</p>
<h2 id="details-3"><a class="header" href="#details-3">Details</a></h2>
<p>The authenticated <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> is labeled as <code>AuthBrowsingUser</code> and demonstrates logging in one time at the start of the load test:</p>
<pre><code class="language-rust ignore">            scenario!("AuthBrowsingUser")
                .set_weight(1)?
                .register_transaction(
                    transaction!(drupal_memcache_login)
                        .set_on_start()
                        .set_name("(Auth) login"),
                )</code></pre>
<p>Each <a href="https://docs.rs/goose/*/goose/goose/struct.GooseUser.html"><code>GooseUser</code></a> thread logs in as a random user (depending on a properly configured test environment):</p>
<pre><code class="language-rust ignore">                    let uid: usize = rand::rng().random_range(3..5_002);
                    let username = format!("user{uid}");
                    let params = [
                        ("name", username.as_str()),
                        ("pass", "12345"),
                        ("form_build_id", &amp;form_build_id[1]),
                        ("form_id", "user_login"),
                        ("op", "Log+in"),
                    ];
                    let _goose = user.post_form("/user", &amp;params).await?;
                    // @TODO: verify that we actually logged in.
                }</code></pre>
<p>The test also includes an example of how to post a comment during a load test:</p>
<pre><code class="language-rust ignore">                .register_transaction(
                    transaction!(drupal_memcache_post_comment)
                        .set_weight(3)?
                        .set_name("(Auth) comment form"),
                ),</code></pre>
<p>Note that much of this functionality can be simplified by using the <a href="https://docs.rs/goose-eggs">Goose Eggs library</a> which includes some <a href="https://docs.rs/goose-eggs/*/goose_eggs/drupal/index.html">Drupal-specific functionality</a>.</p>
<h2 id="complete-source-code-3"><a class="header" href="#complete-source-code-3">Complete Source Code</a></h2>
<pre><code class="language-rust ignore">//! Conversion of Locust load test used for the Drupal memcache module, from
//! &lt;https://github.com/tag1consulting/drupal-loadtest/&gt;
//!
//! To run, you must set up the load test environment as described in the above
//! repository, and then run the example. You'll need to set --host and may want
//! to set other command line options as well, starting with:
//!      cargo run --release --example drupal_memcache --
//!
//! ## License
//!
//! Copyright 2020-2022 Jeremy Andrews
//!
//! Licensed under the Apache License, Version 2.0 (the "License");
//! you may not use this file except in compliance with the License.
//! You may obtain a copy of the License at
//!
//! &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;
//!
//! Unless required by applicable law or agreed to in writing, software
//! distributed under the License is distributed on an "AS IS" BASIS,
//! WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//! See the License for the specific language governing permissions and
//! limitations under the License.

use goose::prelude::*;

use rand::Rng;
use regex::Regex;

#[tokio::main]
async fn main() -&gt; Result&lt;(), GooseError&gt; {
    GooseAttack::initialize()?
        .register_scenario(
            scenario!("AnonBrowsingUser")
                .set_weight(4)?
                .register_transaction(
                    transaction!(drupal_memcache_front_page)
                        .set_weight(15)?
                        .set_name("(Anon) front page"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_node_page)
                        .set_weight(10)?
                        .set_name("(Anon) node page"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_profile_page)
                        .set_weight(3)?
                        .set_name("(Anon) user page"),
                ),
        )
        .register_scenario(
            scenario!("AuthBrowsingUser")
                .set_weight(1)?
                .register_transaction(
                    transaction!(drupal_memcache_login)
                        .set_on_start()
                        .set_name("(Auth) login"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_front_page)
                        .set_weight(15)?
                        .set_name("(Auth) front page"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_node_page)
                        .set_weight(10)?
                        .set_name("(Auth) node page"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_profile_page)
                        .set_weight(3)?
                        .set_name("(Auth) user page"),
                )
                .register_transaction(
                    transaction!(drupal_memcache_post_comment)
                        .set_weight(3)?
                        .set_name("(Auth) comment form"),
                ),
        )
        .execute()
        .await?;

    Ok(())
}

/// View the front page.
async fn drupal_memcache_front_page(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let mut goose = user.get("/").await?;

    match goose.response {
        Ok(response) =&gt; {
            // Copy the headers so we have them for logging if there are errors.
            let headers = &amp;response.headers().clone();
            match response.text().await {
                Ok(t) =&gt; {
                    let re = Regex::new(r#"src="(.*?)""#).unwrap();
                    // Collect copy of URLs to run them async
                    let mut urls = Vec::new();
                    for url in re.captures_iter(&amp;t) {
                        if url[1].contains("/misc") || url[1].contains("/themes") {
                            urls.push(url[1].to_string());
                        }
                    }
                    for asset in &amp;urls {
                        let _ = user.get_named(asset, "static asset").await;
                    }
                }
                Err(e) =&gt; {
                    // This will automatically get written to the error log if enabled, and will
                    // be displayed to stdout if `-v` is enabled when running the load test.
                    return user.set_failure(
                        &amp;format!("front_page: failed to parse page: {e}"),
                        &amp;mut goose.request,
                        Some(headers),
                        None,
                    );
                }
            }
        }
        Err(e) =&gt; {
            // This will automatically get written to the error log if enabled, and will
            // be displayed to stdout if `-v` is enabled when running the load test.
            return user.set_failure(
                &amp;format!("front_page: no response from server: {e}"),
                &amp;mut goose.request,
                None,
                None,
            );
        }
    }

    Ok(())
}

/// View a node from 1 to 10,000, created by preptest.sh.
async fn drupal_memcache_node_page(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let nid = rand::rng().random_range(1..10_000);
    let _goose = user.get(format!("/node/{}", &amp;nid).as_str()).await?;

    Ok(())
}

/// View a profile from 2 to 5,001, created by preptest.sh.
async fn drupal_memcache_profile_page(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let uid = rand::rng().random_range(2..5_001);
    let _goose = user.get(format!("/user/{}", &amp;uid).as_str()).await?;

    Ok(())
}

/// Log in.
async fn drupal_memcache_login(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let mut goose = user.get("/user").await?;

    match goose.response {
        Ok(response) =&gt; {
            // Copy the headers so we have them for logging if there are errors.
            let headers = &amp;response.headers().clone();
            match response.text().await {
                Ok(html) =&gt; {
                    let re = Regex::new(r#"name="form_build_id" value=['"](.*?)['"]"#).unwrap();
                    let form_build_id = match re.captures(&amp;html) {
                        Some(f) =&gt; f,
                        None =&gt; {
                            // This will automatically get written to the error log if enabled, and will
                            // be displayed to stdout if `-v` is enabled when running the load test.
                            return user.set_failure(
                                "login: no form_build_id on page: /user page",
                                &amp;mut goose.request,
                                Some(headers),
                                Some(&amp;html),
                            );
                        }
                    };

                    // Log the user in.
                    let uid: usize = rand::rng().random_range(3..5_002);
                    let username = format!("user{uid}");
                    let params = [
                        ("name", username.as_str()),
                        ("pass", "12345"),
                        ("form_build_id", &amp;form_build_id[1]),
                        ("form_id", "user_login"),
                        ("op", "Log+in"),
                    ];
                    let _goose = user.post_form("/user", &amp;params).await?;
                    // @TODO: verify that we actually logged in.
                }
                Err(e) =&gt; {
                    // This will automatically get written to the error log if enabled, and will
                    // be displayed to stdout if `-v` is enabled when running the load test.
                    return user.set_failure(
                        &amp;format!("login: unexpected error when loading /user page: {e}"),
                        &amp;mut goose.request,
                        Some(headers),
                        None,
                    );
                }
            }
        }
        // Goose will catch this error.
        Err(e) =&gt; {
            // This will automatically get written to the error log if enabled, and will
            // be displayed to stdout if `-v` is enabled when running the load test.
            return user.set_failure(
                &amp;format!("login: no response from server: {e}"),
                &amp;mut goose.request,
                None,
                None,
            );
        }
    }

    Ok(())
}

/// Post a comment.
async fn drupal_memcache_post_comment(user: &amp;mut GooseUser) -&gt; TransactionResult {
    let nid: i32 = rand::rng().random_range(1..10_000);
    let node_path = format!("node/{}", &amp;nid);
    let comment_path = format!("/comment/reply/{}", &amp;nid);

    let mut goose = user.get(&amp;node_path).await?;

    match goose.response {
        Ok(response) =&gt; {
            // Copy the headers so we have them for logging if there are errors.
            let headers = &amp;response.headers().clone();
            match response.text().await {
                Ok(html) =&gt; {
                    // Extract the form_build_id from the user login form.
                    let re = Regex::new(r#"name="form_build_id" value=['"](.*?)['"]"#).unwrap();
                    let form_build_id = match re.captures(&amp;html) {
                        Some(f) =&gt; f,
                        None =&gt; {
                            // This will automatically get written to the error log if enabled, and will
                            // be displayed to stdout if `-v` is enabled when running the load test.
                            return user.set_failure(
                                &amp;format!("post_comment: no form_build_id found on {}", &amp;node_path),
                                &amp;mut goose.request,
                                Some(headers),
                                Some(&amp;html),
                            );
                        }
                    };

                    let re = Regex::new(r#"name="form_token" value=['"](.*?)['"]"#).unwrap();
                    let form_token = match re.captures(&amp;html) {
                        Some(f) =&gt; f,
                        None =&gt; {
                            // This will automatically get written to the error log if enabled, and will
                            // be displayed to stdout if `-v` is enabled when running the load test.
                            return user.set_failure(
                                &amp;format!("post_comment: no form_token found on {}", &amp;node_path),
                                &amp;mut goose.request,
                                Some(headers),
                                Some(&amp;html),
                            );
                        }
                    };

                    let re = Regex::new(r#"name="form_id" value=['"](.*?)['"]"#).unwrap();
                    let form_id = match re.captures(&amp;html) {
                        Some(f) =&gt; f,
                        None =&gt; {
                            // This will automatically get written to the error log if enabled, and will
                            // be displayed to stdout if `-v` is enabled when running the load test.
                            return user.set_failure(
                                &amp;format!("post_comment: no form_id found on {}", &amp;node_path),
                                &amp;mut goose.request,
                                Some(headers),
                                Some(&amp;html),
                            );
                        }
                    };
                    // Optionally uncomment to log form_id, form_build_id, and form_token, together with
                    // the full body of the page. This is useful when modifying the load test.
                    /*
                    user.log_debug(
                        &amp;format!(
                            "form_id: {}, form_build_id: {}, form_token: {}",
                            &amp;form_id[1], &amp;form_build_id[1], &amp;form_token[1]
                        ),
                        Some(&amp;goose.request),
                        Some(headers),
                        Some(&amp;html),
                    );
                    */

                    let comment_body = "this is a test comment body";
                    let params = [
                        ("subject", "this is a test comment subject"),
                        ("comment_body[und][0][value]", comment_body),
                        ("comment_body[und][0][format]", "filtered_html"),
                        ("form_build_id", &amp;form_build_id[1]),
                        ("form_token", &amp;form_token[1]),
                        ("form_id", &amp;form_id[1]),
                        ("op", "Save"),
                    ];

                    // Post the comment.
                    let mut goose = user.post_form(&amp;comment_path, &amp;params).await?;

                    // Verify that the comment posted.
                    match goose.response {
                        Ok(response) =&gt; {
                            // Copy the headers so we have them for logging if there are errors.
                            let headers = &amp;response.headers().clone();
                            match response.text().await {
                                Ok(html) =&gt; {
                                    if !html.contains(comment_body) {
                                        // This will automatically get written to the error log if enabled, and will
                                        // be displayed to stdout if `-v` is enabled when running the load test.
                                        return user.set_failure(
                                            &amp;format!("post_comment: no comment showed up after posting to {}", &amp;comment_path),
                                            &amp;mut goose.request,
                                            Some(headers),
                                            Some(&amp;html),
                                        );
                                    }
                                }
                                Err(e) =&gt; {
                                    // This will automatically get written to the error log if enabled, and will
                                    // be displayed to stdout if `-v` is enabled when running the load test.
                                    return user.set_failure(
                                        &amp;format!(
                                            "post_comment: unexpected error when posting to {}: {}",
                                            &amp;comment_path, e
                                        ),
                                        &amp;mut goose.request,
                                        Some(headers),
                                        None,
                                    );
                                }
                            }
                        }
                        Err(e) =&gt; {
                            // This will automatically get written to the error log if enabled, and will
                            // be displayed to stdout if `-v` is enabled when running the load test.
                            return user.set_failure(
                                &amp;format!(
                                    "post_comment: no response when posting to {}: {}",
                                    &amp;comment_path, e
                                ),
                                &amp;mut goose.request,
                                None,
                                None,
                            );
                        }
                    }
                }
                Err(e) =&gt; {
                    // This will automatically get written to the error log if enabled, and will
                    // be displayed to stdout if `-v` is enabled when running the load test.
                    return user.set_failure(
                        &amp;format!("post_comment: no text when loading {}: {}", &amp;node_path, e),
                        &amp;mut goose.request,
                        None,
                        None,
                    );
                }
            }
        }
        Err(e) =&gt; {
            // This will automatically get written to the error log if enabled, and will
            // be displayed to stdout if `-v` is enabled when running the load test.
            return user.set_failure(
                &amp;format!(
                    "post_comment: no response when loading {}: {}",
                    &amp;node_path, e
                ),
                &amp;mut goose.request,
                None,
                None,
            );
        }
    }

    Ok(())
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="umami-example"><a class="header" href="#umami-example">Umami Example</a></h1>
<p>The <a href="https://github.com/tag1consulting/goose/tree/main/examples/umami"><code>examples/umami</code></a> example load tests the <a href="https://www.drupal.org/docs/umami-drupal-demonstration-installation-profile">Umami demonstration profile</a> included with <a href="https://www.drupal.org/blog/drupal-9-released">Drupal 9</a>.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>The Drupal Umami demonstration profile generates an attractive and realistic website simulating a food magazine, offering a practical example of what Drupal is capable of. The demo site is multi-lingual and has quite a bit of content, multiple taxonomies, and much of the rich functionality you'd expect from a real website, making it a good load test target.</p>
<p>The included example simulates three different types of users: an anonymous user browsing the site in English, an anonymous user browsing the site in Spanish, and an administrative user that logs into the site. The two anonymous users visit every page on the site. For example, the anonymous user browsing the site in English loads the front page, browses all the articles and the article listings, views all the recipes and recipe listings, accesses all nodes directly by node id, performs searches using terms pulled from actual site content, and fills out the site's contact form. With each action performed, Goose validates the HTTP response code and inspects the HTML returned to confirm that it contains the elements we expect.</p>
<p>Read the blog <a href="https://www.tag1consulting.com/blog/goose-clouds-load-testing-scale">A Goose In The Clouds: Load Testing At Scale</a> for a demonstration of using this example, and learn more about the testplan from the <a href="https://github.com/tag1consulting/goose/blob/main/examples/umami/README.md">README</a>.</p>
<h2 id="alternative"><a class="header" href="#alternative">Alternative</a></h2>
<p>The <a href="https://docs.rs/goose-eggs/">Goose Eggs library</a> contains <a href="https://github.com/tag1consulting/goose-eggs/tree/main/examples/umami">a variation of the Umami example</a>.</p>
<h2 id="complete-source-code-4"><a class="header" href="#complete-source-code-4">Complete Source Code</a></h2>
<p>This example is more complex than the other examples, and is split into multiple files, all of which can be found within <a href="https://github.com/tag1consulting/goose/tree/main/examples/umami"><code>examples/umami</code></a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
